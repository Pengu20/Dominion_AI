 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.94412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.3491160571575165
desired expected reward: -9.633204460144043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[286.9401 ]
 [301.07272]
 [294.64478]
 [255.46829]
 [308.47104]
 [297.17142]
 [292.8596 ]
 [311.46368]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.905023574829102
desired expected reward: 300.6070861816406



buy possibilites: [-1] 
expected returns: [[283.80237]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -22.03786277770996
desired expected reward: 233.43043518066406






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[286.73538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.378427505493164
desired expected reward: 275.4239501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[263.01263]
 [277.9243 ]
 [271.00757]
 [233.75104]
 [268.9039 ]
 [284.6783 ]
 [273.36697]
 [274.0316 ]
 [247.74245]
 [268.1502 ]
 [262.56708]
 [285.6693 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.921923637390137
desired expected reward: 278.26434326171875



buy possibilites: [-1] 
expected returns: [[260.4715]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 19 

action type: buy - action 29.0
Learning step: -6.890972137451172
desired expected reward: 267.1406555175781






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[297.11673]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  8.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.977950572967529
desired expected reward: 253.49354553222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[270.4995 ]
 [286.4304 ]
 [278.1933 ]
 [237.96591]
 [276.89792]
 [292.69516]
 [282.2098 ]
 [282.83606]
 [253.26935]
 [275.58823]
 [269.429  ]
 [293.40475]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  8.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.274321556091309
desired expected reward: 288.3089904785156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  8.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  6.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  6.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  6.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3. 29.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[310.83325]
 [299.52576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  6.  0.  3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -8.4043550491333
desired expected reward: 285.0003967285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[290.94037]
 [254.01492]
 [315.176  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6.  0.  3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.71402645111084
desired expected reward: 302.69744873046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 16  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[301.90298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 16  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -9.07498550415039
desired expected reward: 306.1010437011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[282.24185]
 [290.28052]
 [243.20804]
 [295.67667]
 [305.3096 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 16  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -8.879572868347168
desired expected reward: 294.8455810546875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [16.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.  0.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 16  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [0. 8. 0. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 15  8 16  0  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0. 8. 0. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 15  8 16  0  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0. 8. 0. 3. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 15  8 16  0  8  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[225.86716]
 [216.55022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [6. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 16  0  8  3] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -10.871265411376953
desired expected reward: 294.43829345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[208.41092]
 [221.99571]
 [214.8929 ]
 [180.55833]
 [227.69707]
 [218.40887]
 [212.78287]
 [228.3348 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [6. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 16  0  8  3] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.181189060211182
desired expected reward: 220.85658264160156



buy possibilites: [-1] 
expected returns: [[310.9932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [6. 3. 3. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 16  0  8  3] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 1.0
Learning step: -3.852440595626831
desired expected reward: 218.14329528808594






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 16  0  8  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  8 16  0  8  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  8 16  0  8  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  8 16  0  8  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [29.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[283.46085]
 [271.48322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [14. 15.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  8 16  0  8  3 14] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -9.89759349822998
desired expected reward: 301.0956115722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[255.3151 ]
 [263.2804 ]
 [220.90056]
 [266.44635]
 [279.24023]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [14. 15.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  8 16  0  8  3 14] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.039016723632812
desired expected reward: 276.0545654296875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [14. 15.  3. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  8 16  0  8  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [29.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [14. 15.  3. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [29.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [14. 15.  3. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [29.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [14. 15.  3. 16.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [29.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[219.26093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [29.  3.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -8.166168212890625
desired expected reward: 250.107666015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[197.9935 ]
 [212.1098 ]
 [189.77203]
 [204.93602]
 [179.8403 ]
 [169.99524]
 [203.62204]
 [217.57465]
 [208.17163]
 [229.26726]
 [208.57692]
 [182.64911]
 [191.1489 ]
 [202.41066]
 [176.27138]
 [196.88432]
 [217.60072]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [29.  3.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -6.437203884124756
desired expected reward: 211.2305145263672



buy possibilites: [-1] 
expected returns: [[208.40492]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [29.  3.  6.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 5.0 

action type: buy - action 15.0
Learning step: -4.9051055908203125
desired expected reward: 191.97921752929688






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15] -> size -> 14 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15] -> size -> 14 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [3. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[252.81195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0. 14. 16.] 
adversary cards in discard: [0. 3. 0. 8. 8. 3.] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -4.860389232635498
desired expected reward: 203.54454040527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[222.53558]
 [236.942  ]
 [230.39641]
 [194.30844]
 [243.21632]
 [232.40887]
 [227.33487]
 [243.90063]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0. 14. 16.] 
adversary cards in discard: [0. 3. 0. 8. 8. 3.] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -7.633061408996582
desired expected reward: 246.13836669921875



buy possibilites: [-1] 
expected returns: [[251.42351]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0. 14. 16.] 
adversary cards in discard: [0. 3. 0. 8. 8. 3.] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 10.0 

action type: buy - action 3.0
Learning step: -5.362790107727051
desired expected reward: 225.03358459472656






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [15.  0.  0. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 14. 16.] 
cards in discard: [0. 3. 0. 8. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [3. 3. 1. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 14. 16.] 
cards in discard: [0. 3. 0. 8. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [3. 3. 1. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 14. 16.] 
cards in discard: [0. 3. 0. 8. 8. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [3. 3. 1. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[291.60843]
 [264.44107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [3. 3. 1. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 16.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -5.835704803466797
desired expected reward: 245.58779907226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[259.29016]
 [278.14017]
 [269.70084]
 [223.79619]
 [266.7279 ]
 [285.4883 ]
 [272.30463]
 [272.93765]
 [239.90292]
 [265.6927 ]
 [258.46042]
 [286.84   ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [3. 3. 1. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 16.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.206721305847168
desired expected reward: 284.7750549316406



buy possibilites: [-1] 
expected returns: [[288.91452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [ 3.  3.  1.  3.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 16.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 12.5 

action type: buy - action 11.0
Learning step: -7.148838996887207
desired expected reward: 278.3394775390625






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 16  0  8  3 14  8  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 29.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 29.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 29.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [6. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 29.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 29.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[207.01324]
 [197.16492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  8. 15.  8.] 
adversary cards in discard: [ 6.  0. 16.  8.  0.  8.] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -8.986983299255371
desired expected reward: 279.92755126953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[182.67935]
 [189.95763]
 [152.93669]
 [193.66693]
 [204.0068 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  8. 15.  8.] 
adversary cards in discard: [ 6.  0. 16.  8.  0.  8.] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -5.2097697257995605
desired expected reward: 201.5135955810547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [14.  3.  8. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8. 15.  8.] 
cards in discard: [ 6.  0. 16.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 15.  0. 11.] 
adversary cards in discard: [ 3. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8. 15.  8.] 
cards in discard: [ 6.  0. 16.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 15.  0. 11.] 
adversary cards in discard: [ 3. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  1. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[150.94095]
 [131.4735 ]
 [151.41245]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  0. 11.] 
cards in discard: [ 3. 29.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -6.0489301681518555
desired expected reward: 197.9578857421875



action possibilites: [-1] 
expected returns: [[226.63632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  0.] 
cards in discard: [ 3. 29.  6.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 47 

action type: gain_card_n - action 9
Learning step: -0.6421195864677429
desired expected reward: 161.18661499023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[204.3107 ]
 [222.40012]
 [213.78323]
 [167.63132]
 [228.67024]
 [217.0586 ]
 [209.4945 ]
 [227.16983]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15.  0.] 
cards in discard: [ 3. 29.  6.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  9.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -4.6128716468811035
desired expected reward: 222.02345275878906



buy possibilites: [-1] 
expected returns: [[198.53784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15.  0.] 
cards in discard: [ 3. 29.  6.  0.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 56 

action type: buy - action 11.0
Learning step: -4.009545803070068
desired expected reward: 224.66070556640625






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 29.  6.  0.  0. 10. 11. 11.  3.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 29.  6.  0.  0. 10. 11. 11.  3.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  0.  3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  5. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 29.  6.  0.  0. 10. 11. 11.  3.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[140.22946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3. 29.  6.  0.  0. 10. 11. 11.  3.  1. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  5. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [14. 16.  8.  0.  8.] 
adversary cards in discard: [ 8.  8. 15.  0.  0.  3.] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -5.845611572265625
desired expected reward: 192.69223022460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[122.69465 ]
 [133.08029 ]
 [129.10724 ]
 [102.29995 ]
 [126.80481 ]
 [138.55542 ]
 [129.61899 ]
 [130.09784 ]
 [112.496185]
 [127.098526]
 [123.11887 ]
 [140.54478 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3. 29.  6.  0.  0. 10. 11. 11.  3.  1. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  5. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [14. 16.  8.  0.  8.] 
adversary cards in discard: [ 8.  8. 15.  0.  0.  3.] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -3.275066375732422
desired expected reward: 138.1151885986328



buy possibilites: [-1] 
expected returns: [[153.8286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3. 29.  6.  0.  0. 10. 11. 11.  3.  1. 15.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14. 16.  8.  0.  8.] 
adversary cards in discard: [ 8.  8. 15.  0.  0.  3.] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 50 

action type: buy - action 14.0
Learning step: 0.33633384108543396
desired expected reward: 112.83252716064453






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [14. 16.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  8.  0.  8.] 
cards in discard: [ 8.  8. 15.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16.  8.  0.  8.] 
cards in discard: [ 8.  8. 15.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14] -> size -> 19 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[188.56773]
 [187.92358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 8. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -2.5817959308624268
desired expected reward: 151.24679565429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[168.47891]
 [182.01115]
 [175.7228 ]
 [141.5397 ]
 [187.5755 ]
 [177.83667]
 [172.96094]
 [188.21965]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 8. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -4.4925336837768555
desired expected reward: 182.82296752929688



buy possibilites: [-1] 
expected returns: [[188.20245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 8. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -17.492429733276367
desired expected reward: 124.04727172851562






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 16  0  8  3 14  8  0  8  6  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29. 14. 10.  3.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29. 14. 10.  3.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29. 14. 10.  3.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29. 14. 10.  3.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [29. 14. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 10.] 
expected returns: [[123.63349 ]
 [115.845795]
 [ 93.4389  ]
 [110.27488 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14. 10.  3.  0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 15.  8.] 
adversary cards in discard: [0. 8. 0. 6. 3.] 
adversary owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -6.536774635314941
desired expected reward: 181.66567993164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[107.201355]
 [ 82.55091 ]
 [124.917725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14. 10.  3.  0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 15.  8.] 
adversary cards in discard: [0. 8. 0. 6. 3.] 
adversary owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -3.381782293319702
desired expected reward: 119.93978881835938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 15.  8.] 
cards in discard: [0. 8. 0. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  6.  3.  0. 15.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3. 29. 14. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 15.  8.] 
cards in discard: [0. 8. 0. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  6.  3.  0. 15.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3. 29. 14. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 15.  8.] 
cards in discard: [0. 8. 0. 6. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  6.  3.  0. 15.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3. 29. 14. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 1.  6.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[166.57942]
 [147.61307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  3.  0. 15.] 
cards in discard: [ 6. 11.  0.  0.  0.  3. 29. 14. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14. 16.  3.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  0.  8.  0.  0. 15.  8.] 
adversary owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -2.387709140777588
desired expected reward: 122.52998352050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[141.60881 ]
 [153.58434 ]
 [148.89622 ]
 [120.250175]
 [159.64595 ]
 [149.42459 ]
 [146.28244 ]
 [161.54391 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  3.  0. 15.] 
cards in discard: [ 6. 11.  0.  0.  0.  3. 29. 14. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14. 16.  3.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  0.  8.  0.  0. 15.  8.] 
adversary owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -4.461668014526367
desired expected reward: 159.24639892578125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [14. 16.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  3.  8.  0.] 
cards in discard: [ 0.  8.  0.  6.  3.  0.  8.  0.  0. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 16  0  8  3 14  8  0  8  6  0  8  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 0.  8.  0.  6.  3.  0.  8.  0.  0. 15.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 15 16  0  8  3  8  0  8  6  0  8  0  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 0.  8.  0.  6.  3.  0.  8.  0.  0. 15.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 15 16  0  8  3  8  0  8  6  0  8  0  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[140.10356]
 [140.89034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15 16  0  8  3  8  0  8  6  0  8  0  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -4.591943264007568
desired expected reward: 156.95196533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[119.608536]
 [134.26985 ]
 [126.65561 ]
 [ 91.30242 ]
 [139.3387  ]
 [130.19902 ]
 [123.65949 ]
 [138.59247 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15 16  0  8  3  8  0  8  6  0  8  0  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -3.722059726715088
desired expected reward: 135.2029571533203



buy possibilites: [-1] 
expected returns: [[184.21156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15 16  0  8  3  8  0  8  6  0  8  0  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -23.0 

action type: buy - action 0.0
Learning step: -2.985668897628784
desired expected reward: 116.6229019165039






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 16  0  8  3  8  0  8  6  0  8  0  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 14.  0. 29.  3.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 14.  0. 29.  3.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 14.  0. 29.  3.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0. 14.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[144.42703]
 [111.93788]
 [133.4225 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 29.  3.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  8.  6.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -5.950557231903076
desired expected reward: 178.26100158691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[124.89519]
 [132.05357]
 [100.7247 ]
 [133.09639]
 [144.47441]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 29.  3.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  8.  6.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -3.801776170730591
desired expected reward: 137.6981658935547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8.  6.] 
cards in discard: [8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  6. 15.  1. 11.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  8.  6.] 
cards in discard: [8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  6. 15.  1. 11.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  8.  6.] 
cards in discard: [8. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  6. 15.  1. 11.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10.  6. 15.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[129.29663 ]
 [111.77355 ]
 [106.82077 ]
 [126.634445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 15.  1. 11.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  8.  8.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 15.  8.  6.] 
adversary owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -4.666066646575928
desired expected reward: 139.80833435058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[105.8157 ]
 [113.59656]
 [ 82.85017]
 [113.51526]
 [126.39893]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 15.  1. 11.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  7.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  8.  8.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 15.  8.  6.] 
adversary owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -3.9049441814422607
desired expected reward: 121.32217407226562



buy possibilites: [-1] 
expected returns: [[84.64481]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 15.  1. 11.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  8.  8.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 15.  8.  6.] 
adversary owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -17.93800163269043
desired expected reward: 64.91216278076172






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  8.  8.] 
cards in discard: [ 8.  3.  3.  0.  0. 15.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.  6. 10.  6. 15.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [ 8.  3.  3.  0.  0. 15.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.  6. 10.  6. 15.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [ 8.  3.  3.  0.  0. 15.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.  6. 10.  6. 15.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [3. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[142.33087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.  6. 10.  6. 15.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -1.7519282102584839
desired expected reward: 82.89288330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[122.8113 ]
 [128.19714]
 [101.84065]
 [129.96744]
 [138.87003]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.  6. 10.  6. 15.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -4.9158782958984375
desired expected reward: 136.4313507080078



buy possibilites: [-1] 
expected returns: [[133.07584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0. 14.  0. 29.  3.  6. 10.  6. 15.  1. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -18.34782600402832
desired expected reward: 83.4928207397461






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8  3  8  0  8  6  0  8  0  0 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  0  8  6  0  8  0  0 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  0  8  6  0  8  0  0 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [15.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[107.46063]
 [ 88.51871]
 [100.68326]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  8. 15. 10.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [15  8  8  0  8  6  0  8  0  0 10  3] -> size -> 12 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -4.68550443649292
desired expected reward: 128.3903350830078



action possibilites: [-1] 
expected returns: [[135.27136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  8. 15. 10.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [15  8  8  0  8  6  0  8  0  0 10  3] -> size -> 12 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.5396243929862976
desired expected reward: 86.1249771118164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[120.26224 ]
 [131.74234 ]
 [125.38033 ]
 [ 97.69836 ]
 [124.9233  ]
 [134.702   ]
 [128.6531  ]
 [128.75323 ]
 [107.00905 ]
 [123.314476]
 [118.61767 ]
 [133.12216 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  8. 15. 10.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [15  8  8  0  8  6  0  8  0  0 10  3] -> size -> 12 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -3.2055249214172363
desired expected reward: 132.0658416748047



buy possibilites: [-1] 
expected returns: [[68.34384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  8. 15. 10.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [15  8  8  0  8  6  0  8  0  0 10  3] -> size -> 12 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: -2.5499253273010254
desired expected reward: 126.20330810546875






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 15. 10.] 
cards in discard: [8. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  8  6  0  8  0  0 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [29. 15.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 15.  8.] 
cards in discard: [8. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [15  8  8  0  8  6  0  8  0  0 10  3] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [29. 15.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.] 
cards in discard: [8. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8  8  6  0  8  0  0 10  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [29. 15.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [8. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8. 15.] 
owned cards: [15  8  8  6  0  8  0  0 10  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [29. 15.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [8. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8. 15.] 
owned cards: [15  8  8  6  0  8  0  0 10  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [29. 15.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[60.52754]
 [61.30429]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  3.] 
cards in discard: [29. 15.  3. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  0  8  0  0 10  3] -> size -> 10 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -2.3341293334960938
desired expected reward: 66.00971221923828



action possibilites: [-1] 
expected returns: [[36.96254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [29. 15.  3. 29.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  0  8  0  0 10  3] -> size -> 10 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: -1.1258426904678345
desired expected reward: 62.02415084838867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.12391  ]
 [32.4637   ]
 [14.4188385]
 [33.584805 ]
 [38.269444 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [29. 15.  3. 29.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  0  8  0  0 10  3] -> size -> 10 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.40425872802734375
desired expected reward: 36.55828094482422



buy possibilites: [-1] 
expected returns: [[64.43779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [29. 15.  3. 29.  0. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  0  8  0  0 10  3] -> size -> 10 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 34 

action type: buy - action 3.0
Learning step: 1.5266647338867188
desired expected reward: 33.99037551879883






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  0  8  0  0 10  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  0.  6.] 
adversary cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  8  6  8  0  0 10  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  0.  6.] 
adversary cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  8  6  8  0  0 10  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  0.  6.] 
adversary cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  8  6  8  0  0 10  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  0.  6.] 
adversary cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 6. 14.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[42.352135]
 [22.33029 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  0.  6.] 
cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  8.  8. 10.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.] 
adversary owned cards: [15  8  8  6  8  0  0 10  3  0] -> size -> 10 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -2.231038808822632
desired expected reward: 62.20675277709961



action possibilites: [-1] 
expected returns: [[55.366737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  8.  3.] 
adversary owned cards: [15  8  8  6  8  0  0 10  3  0] -> size -> 10 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action 14.0
Learning step: 1.6112489700317383
desired expected reward: 21.11371612548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[47.148224]
 [53.497517]
 [51.499752]
 [35.83991 ]
 [49.631855]
 [56.536777]
 [50.936737]
 [51.106377]
 [41.224472]
 [49.6192  ]
 [47.24523 ]
 [57.336685]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.  8.  3.] 
adversary owned cards: [15  8  8  6  8  0  0 10  3  0] -> size -> 10 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -0.32924768328666687
desired expected reward: 55.03749084472656






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [ 0. 15.  6.  0.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  8  0  0 10  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3. 14.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0. 15.  6.  0.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  6  8  0  0 10  3  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3. 14.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0. 15.  6.  0.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  6  8  0  0 10  3  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3. 14.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [0. 1. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[84.84157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3. 14.  6.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0  0 10  3  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -0.6981897354125977
desired expected reward: 56.638511657714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[75.87024 ]
 [84.14094 ]
 [79.64826 ]
 [62.250687]
 [78.872375]
 [87.1537  ]
 [81.34432 ]
 [81.41997 ]
 [68.0297  ]
 [77.79317 ]
 [74.82173 ]
 [86.59706 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3. 14.  6.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0  0 10  3  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -2.0605580806732178
desired expected reward: 80.99034881591797



buy possibilites: [-1] 
expected returns: [[127.31119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [29. 15.  3. 29.  0. 10.  3. 11.  0.  6.  0.  3. 14.  6.  0.  0.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0  0 10  3  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 10.5 

action type: buy - action 1.0
Learning step: -0.8175449371337891
desired expected reward: 83.3233871459961






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  6  8  0  0 10  3  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [14.  3.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  6  8  0 10  3  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [14.  3.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  6  8  0 10  3  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [14.  3.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [14.  3.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [14.  3.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11.] 
expected returns: [[54.883453]
 [47.12648 ]
 [51.899105]
 [55.240295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -4.926525115966797
desired expected reward: 122.38465881347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.736374]
 [41.683693]
 [52.702614]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -1.2389253377914429
desired expected reward: 51.37845993041992



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8. 15.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  0. 15.  0.  3.] 
adversary cards in discard: [14.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8. 15.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  0. 15.  0.  3.] 
adversary cards in discard: [14.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[54.748146]
 [48.443993]
 [42.340313]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15.  0.  3.] 
cards in discard: [14.  3.  3. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10
  3  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -1.2333555221557617
desired expected reward: 51.46925354003906



action possibilites: [-1] 
expected returns: [[75.82657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.] 
cards in discard: [14.  3.  3. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action 15.0
Learning step: 0.9134847521781921
desired expected reward: 42.7657470703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[66.32358 ]
 [74.52703 ]
 [70.31022 ]
 [50.49359 ]
 [69.62209 ]
 [76.65508 ]
 [71.78294 ]
 [71.93058 ]
 [57.596924]
 [68.531975]
 [65.42185 ]
 [76.15068 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.] 
cards in discard: [14.  3.  3. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  8.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -0.9239910244941711
desired expected reward: 74.90258026123047



buy possibilites: [-1] 
expected returns: [[30.333923]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.] 
cards in discard: [14.  3.  3. 10. 11. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 30.5 

action type: buy - action 11.0
Learning step: -1.6252402067184448
desired expected reward: 75.02983093261719






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  0.  6.  6.  3.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  6  8  0 10  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 26. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  0.  6.  6.  3.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11] -> size -> 26 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  6  8  0 10  3  0  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 25. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  0.  6.  6.  3.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11] -> size -> 26 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[79.22815]
 [73.57756]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  6.  3.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -0.02815551869571209
desired expected reward: 30.305767059326172



action possibilites: [-1.] 
expected returns: [[55.999966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 3.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 25. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 29.0
Learning step: -1.5277661085128784
desired expected reward: 70.2275390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[50.37059 ]
 [54.233692]
 [36.072315]
 [55.177048]
 [61.203384]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 3.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 25. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -0.806928813457489
desired expected reward: 55.19303512573242



buy possibilites: [-1] 
expected returns: [[55.73838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 3.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  6  8  0 10  3  0  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 35 

action type: buy - action 3.0
Learning step: 0.29242879152297974
desired expected reward: 54.526119232177734






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  8. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  6  8  0 10  3  0  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  6.  0. 11.  0.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 15.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [15  8  6  8  0 10  3  0  0  3] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  6.  0. 11.  0.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  6  8 10  3  0  0  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  6.  0. 11.  0.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  6  8 10  3  0  0  3] -> size -> 8 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  6.  0. 11.  0.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  6  8 10  3  0  0  3  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  6.  0. 11.  0.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3] -> size -> 27 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[69.97738 ]
 [61.379005]
 [71.06925 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0. 11.  0.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0] -> size -> 9 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -0.9407985806465149
desired expected reward: 54.79758071899414



action possibilites: [-1] 
expected returns: [[7.189564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  0.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0] -> size -> 9 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 36 

action type: gain_card_n - action 1
Learning step: -1.2517948150634766
desired expected reward: 63.0194091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 4.4984603]
 [ 5.578138 ]
 [-4.6015005]
 [ 6.404595 ]
 [ 6.259335 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  5. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0] -> size -> 9 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 1.0824450254440308
desired expected reward: 8.272008895874023



buy possibilites: [-1] 
expected returns: [[18.286016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0] -> size -> 9 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 35 

action type: buy - action 8.0
Learning step: 1.8412052392959595
desired expected reward: 8.245808601379395






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.
  8. 11. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8] -> size -> 29 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.
  8. 11. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8] -> size -> 29 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.
  8. 11. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8] -> size -> 29 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [1. 0. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[48.240723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.
  8. 11. 10.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.021115398034453392
desired expected reward: 18.307132720947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.469727]
 [46.89501 ]
 [33.576466]
 [42.161613]
 [28.22023 ]
 [23.149181]
 [40.454998]
 [50.950905]
 [42.96468 ]
 [59.235085]
 [43.09293 ]
 [29.511896]
 [34.17375 ]
 [39.487694]
 [26.382257]
 [36.583878]
 [50.832745]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.
  8. 11. 10.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -1.6071265935897827
desired expected reward: 46.63359451293945



buy possibilites: [-1] 
expected returns: [[25.446198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [14.  3.  3. 10. 11. 11. 15. 29.  0.  3.  3. 29.  0.  6.  6.  3.  3.  1.
  8. 11. 10.  6.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.   0.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 1.5 

action type: buy - action 10.0
Learning step: -1.3268458843231201
desired expected reward: 38.160858154296875






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10] -> size -> 30 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10] -> size -> 30 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  8.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0  3  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10] -> size -> 30 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 6. 14.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[49.810535]
 [33.098972]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 3. 6. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.  8.] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -0.5331143736839294
desired expected reward: 24.913084030151367



action possibilites: [-1] 
expected returns: [[67.32081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.  8.  8.  0.] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 14.0
Learning step: 0.8746033906936646
desired expected reward: 30.67690086364746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[51.13087 ]
 [63.714928]
 [57.848484]
 [34.8084  ]
 [69.347885]
 [59.454914]
 [55.0095  ]
 [70.04339 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.  8.  8.  0.] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -1.1725832223892212
desired expected reward: 66.14822387695312



buy possibilites: [-1] 
expected returns: [[43.456676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.  8.  8.  0.] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -2.2287681102752686
desired expected reward: 48.902099609375






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0  3  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 29.  0. 10.  1.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0] -> size -> 31 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0  3  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 29.  0. 10.  1.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0] -> size -> 31 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.  8.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0  3  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 29.  0. 10.  1.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0] -> size -> 31 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 3. 29.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[12.626526]
 [ 8.708868]
 [ 6.713947]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 10.  1.] 
cards in discard: [ 0. 14.  6.  0.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -2.1125924587249756
desired expected reward: 41.344085693359375



action possibilites: [-1. 10.] 
expected returns: [[64.69456 ]
 [57.485584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  1.  3.] 
cards in discard: [ 0. 14.  6.  0.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 29.0
Learning step: 1.829522728919983
desired expected reward: 9.996940612792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[59.084118]
 [66.206184]
 [62.61406 ]
 [45.179253]
 [61.86544 ]
 [68.93067 ]
 [64.20754 ]
 [64.28693 ]
 [51.535587]
 [61.30165 ]
 [58.461376]
 [68.510605]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  1.  3.] 
cards in discard: [ 0. 14.  6.  0.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 23. 30.  8.  5.  9.  7.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.9825302362442017
desired expected reward: 63.71202850341797



buy possibilites: [-1] 
expected returns: [[72.71775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  1.  3.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 23. 30.  8.  5.  9.  6.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8 10  3  0  0  3  0  3  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.   0.   2.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 21.5 

action type: buy - action 11.0
Learning step: -0.7353845834732056
desired expected reward: 68.19529724121094






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8 10  3  0  0  3  0  3  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  5.  9.  6.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11] -> size -> 32 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 8 3 0 3 0 3 0 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  5.  9.  6.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11] -> size -> 32 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 8 3 0 3 0 3 0 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 23. 30.  8.  5.  9.  6.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11] -> size -> 32 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  6.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11] -> size -> 32 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[102.63921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  6.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 3.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -1.4991731643676758
desired expected reward: 71.21857452392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 88.73847 ]
 [ 96.527916]
 [ 93.86972 ]
 [ 75.52796 ]
 [100.060875]
 [ 93.528595]
 [ 91.703575]
 [100.91011 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  6.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 3.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -3.117112159729004
desired expected reward: 98.51464080810547



buy possibilites: [-1] 
expected returns: [[72.844826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 3.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 15 

action type: buy - action 11.0
Learning step: -2.4347007274627686
desired expected reward: 94.03948211669922






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [3. 8. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 3. 3.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15. 11. 10. 10.  8.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 3. 3.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15. 11. 10. 10.  8.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15. 11. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10. 10.  8.] 
expected returns: [[78.53132 ]
 [71.22109 ]
 [80.05582 ]
 [73.570335]
 [73.570335]
 [76.84664 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10. 10.  8.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -2.0741047859191895
desired expected reward: 70.77072143554688



action possibilites: [-1. 15. 11. 10.  8.] 
expected returns: [[92.83782 ]
 [81.95612 ]
 [93.53638 ]
 [85.10605 ]
 [88.395134]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10.  8.  6.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 10.0
Learning step: -0.8211017847061157
desired expected reward: 72.74922943115234



action possibilites: [-1. 15. 11.  8.] 
expected returns: [[59.459415]
 [46.879208]
 [61.31858 ]
 [54.673714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  8.  6.  6.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
action values: 3 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action 10.0
Learning step: -1.133419394493103
desired expected reward: 83.97261047363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.83207 ]
 [31.925173]
 [59.371883]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  8.  6.  6.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
action values: 3 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: -0.03130855783820152
desired expected reward: 59.42809295654297






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3.  0.  1.  1.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0. 10. 10. 15. 11.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3.  0.  1.  1.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0. 10. 10. 15. 11.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3.  0.  1.  1.] 
adversary cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0. 10. 10. 15. 11.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  0.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[43.63596 ]
 [43.549667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  1.  1.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0. 10. 10. 15. 11.  8.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [1. 3. 0. 8. 0. 0.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -2.1375958919525146
desired expected reward: 57.234283447265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.61037 ]
 [41.484966]
 [38.86897 ]
 [28.500633]
 [24.923687]
 [37.80009 ]
 [44.180973]
 [39.387196]
 [50.301353]
 [39.42611 ]
 [29.660284]
 [33.22677 ]
 [37.418297]
 [27.283794]
 [35.209972]
 [44.059578]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  1.  1.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0. 10. 10. 15. 11.  8.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [1. 3. 0. 8. 0. 0.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -1.4554409980773926
desired expected reward: 42.18053436279297



buy possibilites: [-1] 
expected returns: [[46.522724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  1.  1.] 
cards in discard: [ 0. 14.  6.  0.  3.  6. 11. 29.  3.  0. 10.  1.  3. 11.  0.  3.  0.  3.
  0. 10. 10. 15. 11.  8.  6.  6. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [1. 3. 0. 8. 0. 0.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 47 

action type: buy - action 22.0
Learning step: 2.0325710773468018
desired expected reward: 29.316375732421875






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [1. 3. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0. 29. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22] -> size -> 34 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [1. 3. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0. 29. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22] -> size -> 34 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [1. 3. 0. 8. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0. 29. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22] -> size -> 34 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10.  0. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 29.] 
expected returns: [[68.329254]
 [64.473175]
 [66.46242 ]
 [68.60645 ]
 [66.46242 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 11. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 1. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -1.03731107711792
desired expected reward: 45.48541259765625



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[51.35749 ]
 [46.24769 ]
 [50.919838]
 [48.113518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 1. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 29.0
Learning step: -1.203182578086853
desired expected reward: 62.14531326293945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[46.004993]
 [48.27409 ]
 [38.854362]
 [49.250885]
 [52.67237 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 29.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 23. 30.  8.  5.  9.  5.  4. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 1. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.6391262412071228
desired expected reward: 50.7183723449707



buy possibilites: [-1] 
expected returns: [[17.929995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 29.  6.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  5.  9.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 1. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 25 

action type: buy - action 8.0
Learning step: -0.8091196417808533
desired expected reward: 48.441768646240234






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 1. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  5.  9.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8] -> size -> 35 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 23. 30.  8.  5.  9.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8] -> size -> 35 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 3.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 22. 30.  8.  5.  9.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8] -> size -> 35 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.07241]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  5.  9.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 1. 8. 3. 3.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -0.25504931807518005
desired expected reward: 17.674945831298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[49.622375]
 [56.360317]
 [53.41262 ]
 [37.440403]
 [52.23314 ]
 [59.106842]
 [54.059612]
 [54.077454]
 [42.494434]
 [51.676567]
 [49.04415 ]
 [58.693577]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 30. 22. 30.  8.  5.  9.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 1. 8. 3. 3.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -2.3325836658477783
desired expected reward: 55.06521224975586



buy possibilites: [-1] 
expected returns: [[48.801086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  5.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 1. 8. 3. 3.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0  -1   0   0  32   0] 
sum of rewards: 18 

action type: buy - action 16.0
Learning step: -0.6136326193809509
desired expected reward: 51.6195068359375






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 1. 8. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  5.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11. 10.  6.  0.  1.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16] -> size -> 36 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 1. 8. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 30. 22. 30.  8.  5.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [11. 10.  6.  0.  1.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16] -> size -> 36 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[45.56853 ]
 [45.965992]
 [39.45705 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  6.  0.  1.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  5.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 8. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -2.0990803241729736
desired expected reward: 46.70200729370117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.717197]
 [45.453903]
 [43.305252]
 [30.77499 ]
 [48.206272]
 [43.055782]
 [41.56666 ]
 [48.462727]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  6.  0.  1.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  5.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 8. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -1.8056097030639648
desired expected reward: 40.899330139160156



buy possibilites: [-1] 
expected returns: [[5.8059664]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  6.  0.  1.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 8. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -326.0 

action type: buy - action 6.0
Learning step: -17.708114624023438
desired expected reward: 13.066864013671875






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10.  0.  6. 11.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10.  0.  6. 11.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 6.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10.  0.  6. 11.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 8. 10.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[39.50112 ]
 [33.185238]
 [30.334663]
 [40.60056 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  6. 11.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  6.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 8. 0. 8. 6.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -0.6650151610374451
desired expected reward: 5.140951156616211



action possibilites: [-1] 
expected returns: [[2.0325296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  6.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 8. 0. 8. 6.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0  -3   0   0   9   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: -2.022102117538452
desired expected reward: 41.33457565307617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -4.6815243 ]
 [-10.091592  ]
 [  0.05305886]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  6.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 8. 0. 8. 6.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.39363399147987366
desired expected reward: 1.6388956308364868



buy possibilites: [-1] 
expected returns: [[14.913841]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  6.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 8. 0. 8. 6.] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  20. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: -38.0 

action type: buy - action 0.0
Learning step: -1.3303622007369995
desired expected reward: -6.011889934539795






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 8. 0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 6.  3.  3.  3. 11.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 8. 0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 6.  3.  3.  3. 11.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 8. 0. 8. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 6.  3.  3.  3. 11.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 6.  3.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[66.812294]
 [67.5878  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  3. 11.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 22. 30.  8.  4.  8.  5.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -0.4322531819343567
desired expected reward: 14.481588363647461



action possibilites: [-1] 
expected returns: [[-11.119444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 22. 30.  8.  4.  8.  4.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0  -5   0   0   9   0] 
sum of rewards: 0 

action type: gain_card_n - action 5
Learning step: -3.118685483932495
desired expected reward: 54.25127029418945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.332332]
 [ -9.119795]
 [-11.119452]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 22. 30.  8.  4.  8.  4.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: 0.13065610826015472
desired expected reward: -10.988787651062012



buy possibilites: [-1] 
expected returns: [[41.930847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 22. 30.  8.  4.  8.  4.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20 -30   0   0   0  -6   0   0   0   0] 
sum of rewards: -40 

action type: buy - action 0.0
Learning step: -0.5399395823478699
desired expected reward: -10.872267723083496






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 22. 30.  8.  4.  8.  4.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  3. 14. 22. 15.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.  0. 11.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0] -> size -> 41 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8 3 0 3 0 3 0 0 0 1 0 3 0 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 22. 30.  8.  4.  8.  4.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  3. 14. 22. 15.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.  0. 11.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0] -> size -> 41 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 22. 30.  8.  4.  8.  3.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  3. 14. 22. 15.] 
adversary cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.  0. 11.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0] -> size -> 41 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3. 14. 22. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22. 15.] 
expected returns: [[37.394085]
 [25.610577]
 [23.708393]
 [30.133297]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 22. 15.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.  0. 11.  6.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 22. 30.  8.  4.  8.  3.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -2.6089375019073486
desired expected reward: 39.3219108581543



action possibilites: [-1] 
expected returns: [[5.4937325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 15.  1.  0. 11.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.  0. 11.  6.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 22. 30.  8.  4.  8.  3.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   3] 
sum of rewards: -1 

action type: take_action - action 22.0
Learning step: -1.111810326576233
desired expected reward: 22.596574783325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 1.8005736 ]
 [ 3.5393298 ]
 [ 2.529627  ]
 [-1.6053991 ]
 [ 2.4313848 ]
 [ 4.487646  ]
 [ 3.0572655 ]
 [ 3.0915124 ]
 [-0.08511829]
 [ 2.1709855 ]
 [ 1.5324385 ]
 [ 5.493724  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 15.  1.  0. 11.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.  0. 11.  6.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 22. 30.  8.  4.  8.  3.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.40977126359939575
desired expected reward: 5.083961009979248



buy possibilites: [-1] 
expected returns: [[-3.100449]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 15.  1.  0. 11.] 
cards in discard: [ 8. 29. 10.  0. 11. 29.  6. 16.  3.  0.  3.  1.  0.  6. 11. 10.  6.  0.
  1. 10.  0. 11.  8. 10.  0.  6. 11.  0. 11.  6.  3.  3.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 25. 30. 22. 30.  8.  4.  8.  3.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.   -7.
   0.    0.    4.5   0. ] 
sum of rewards: -6.5 

action type: buy - action 1.0
Learning step: -0.5799214243888855
desired expected reward: 2.959413528442383






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [11.  6.  0.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 22. 30.  8.  4.  8.  3.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  1.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1] -> size -> 42 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [11.  6.  0.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 25. 30. 22. 30.  8.  4.  8.  3.  3. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  1.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1] -> size -> 42 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [11.  6.  0.  3.  1.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 25. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  1.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1] -> size -> 42 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  1.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[49.560806]
 [46.591614]
 [48.799637]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: 0.04677412658929825
desired expected reward: -3.0536749362945557



action possibilites: [-1. 11. 11.] 
expected returns: [[57.11625 ]
 [57.495876]
 [57.495876]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  5.  9.  8.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 10.0
Learning step: -1.2383021116256714
desired expected reward: 45.35332489013672



action possibilites: [-1. 11.] 
expected returns: [[49.12227 ]
 [50.091236]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [10.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  40   0   0   0   0  -8   0   0   9   0] 
sum of rewards: 17 

action type: gain_card_n - action 9
Learning step: -0.9692535400390625
desired expected reward: 57.77478790283203



action possibilites: [-1] 
expected returns: [[51.106792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [10.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  60   0   0   0   0  -9   0   0   9   0] 
sum of rewards: 36 

action type: gain_card_n - action 1
Learning step: 0.5000276565551758
desired expected reward: 49.497528076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[41.19596 ]
 [48.32983 ]
 [44.956898]
 [27.422195]
 [43.958347]
 [51.317863]
 [46.069233]
 [46.233635]
 [34.375458]
 [43.478756]
 [40.758907]
 [51.686985]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [10.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: 0.25030118227005005
desired expected reward: 51.357093811035156



buy possibilites: [-1] 
expected returns: [[47.219494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [10.  1.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 4 
card supply: [11. 24. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  60. -30.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: -4.0 

action type: buy - action 0.0
Learning step: -1.1973599195480347
desired expected reward: 39.99860763549805






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  0  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  3.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0] -> size -> 45 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  3.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0] -> size -> 45 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 30. 22. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  3.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0] -> size -> 45 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  6.  0.  3.  1.  3.  8.  8.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 21. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  3.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0] -> size -> 45 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[30.767776]
 [17.00243 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  3.  0.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 21. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.4980359077453613
desired expected reward: 43.721458435058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.784716]
 [12.92812 ]
 [33.37491 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  3.  0.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 24. 30. 21. 30.  8.  4.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -2.6881284713745117
desired expected reward: 28.07965087890625



buy possibilites: [-1] 
expected returns: [[103.76849]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  3.  0.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 30. 21. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.  -11.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -16.111616134643555
desired expected reward: -3.1834850311279297






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 21. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11. 10. 10.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0  6] -> size -> 46 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 30. 21. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11. 10. 10.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0  6] -> size -> 46 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 20. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11. 10. 10.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0  6] -> size -> 46 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 8. 11. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 10.] 
expected returns: [[10.158274 ]
 [ 8.095564 ]
 [ 9.92874  ]
 [ 7.5778575]
 [ 7.5778575]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 10.  0.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 20. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -7.737874507904053
desired expected reward: 96.0306167602539



action possibilites: [-1.  8. 11. 10. 22.] 
expected returns: [[12.377518 ]
 [10.549147 ]
 [12.12249  ]
 [ 9.933369 ]
 [ 6.1556783]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  0. 22.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0  6] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 20. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -1.8907982110977173
desired expected reward: 5.687056541442871



action possibilites: [-1.  8. 10. 22.] 
expected returns: [[40.166958]
 [35.411446]
 [34.329525]
 [25.849764]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 22.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 29  1 15  3 11 10 11 14  6  0  6  6 29 10  3
  1 11  3  1  8 10  0 11 11 22  8 16  6 10  0 11  0  1 10  1  0  6  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 20. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  40   0   0   0   0 -12   0   0   9   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: -0.6714543700218201
desired expected reward: 10.492260932922363



action possibilites: [-1] 
expected returns: [[27.684555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11
  3  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 20. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 6
Learning step: -0.18079224228858948
desired expected reward: 20.893102645874023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.3326845]
 [ 3.4725914]
 [25.333939 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11
  3  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 23. 30. 20. 30.  8.  3.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -0.770060658454895
desired expected reward: 26.914493560791016



buy possibilites: [-1] 
expected returns: [[-5.8479795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11
  3  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 20. 30.  8.  2.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -60    0    0   60    0    0    0    0  -10    0 -300
    0    0] 
sum of rewards: -316 

action type: buy - action 6.0
Learning step: -16.105209350585938
desired expected reward: -12.63261604309082






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [3. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [ 3.  8. 11.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 20. 30.  8.  2.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [15.  6.  1. 10.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11
  3  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6] -> size -> 45 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [ 3.  8. 11.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 20. 30.  8.  2.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [15.  6.  1. 10.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11
  3  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6] -> size -> 45 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [ 3.  8. 11.  0.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [15.  6.  1. 10.  0.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11
  3  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6] -> size -> 45 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [15.  6.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[-11.877257]
 [ -8.431465]
 [ -9.630761]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  1. 10.  0.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11
  3  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.  3.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3] -> size -> 20 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -3.726405382156372
desired expected reward: -9.574384689331055



action possibilites: [-1] 
expected returns: [[-3.1832144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 10.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 23. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.  3.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3] -> size -> 20 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action 15.0
Learning step: -2.4500491619110107
desired expected reward: -10.881514549255371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-12.203042  ]
 [ -5.7319336 ]
 [ -5.168263  ]
 [-18.739452  ]
 [-20.551575  ]
 [ -9.85854   ]
 [ -2.2038977 ]
 [ -9.703681  ]
 [ -0.02333951]
 [ -9.684882  ]
 [-16.028236  ]
 [-11.273482  ]
 [ -8.544474  ]
 [-17.510422  ]
 [-10.790546  ]
 [ -3.8263094 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 10.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 23. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.  3.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3] -> size -> 20 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1
Learning step: -2.8310048580169678
desired expected reward: -6.014219284057617



buy possibilites: [-1] 
expected returns: [[18.702076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 10.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  0.  3.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3] -> size -> 20 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0 -10   0   0  50   0] 
sum of rewards: -16 

action type: buy - action 23.0
Learning step: 0.18447080254554749
desired expected reward: -11.089011192321777






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [ 3.  8. 11.  0.  3.  0.  3.  3.  6.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  6.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23] -> size -> 45 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [ 3.  8. 11.  0.  3.  0.  3.  3.  6.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 23. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  6.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23] -> size -> 45 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [ 3.  8. 11.  0.  3.  0.  3.  3.  6.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  6.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23] -> size -> 45 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [ 6.  0. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-16.21708 ]
 [-15.412084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  3.  6.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -5.089439392089844
desired expected reward: 13.61263656616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-15.016632]
 [-17.442978]
 [-16.21708 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  3.  6.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 30. 19. 30.  8.  2.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -3.3497376441955566
desired expected reward: -19.566822052001953



buy possibilites: [-1] 
expected returns: [[-12.6966305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  3.  6.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 21 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.    0.    0.    0.    0.    0.  -11.
    0. -300.    0.    0.] 
sum of rewards: -398.0 

action type: buy - action 6.0
Learning step: -19.31352424621582
desired expected reward: -36.75652313232422






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [3. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  1.  0.  3. 29.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6] -> size -> 46 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  1.  0.  3. 29.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6] -> size -> 46 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  1.  0.  3. 29.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6] -> size -> 46 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [11.  1.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 0.3270502]
 [-1.3664194]
 [-6.1586113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  3. 29.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -3.259042739868164
desired expected reward: -15.955673217773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -8.086376 ]
 [ -3.9921494]
 [ -3.9934976]
 [-14.259879 ]
 [ -1.3664197]
 [ -6.3619485]
 [ -5.6367445]
 [  0.3270502]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  3. 29.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  2. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -3.967013120651245
desired expected reward: -3.639963150024414



buy possibilites: [-1] 
expected returns: [[-13.380902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  3. 29.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.   0.   0.   0.   0.   0. -12.   0.   0.
   2.   0.] 
sum of rewards: -87.0 

action type: buy - action 8.0
Learning step: -4.332973003387451
desired expected reward: -10.694923400878906






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 11.  1.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8] -> size -> 47 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 19. 30.  8.  1.  8.  3.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 11.  1.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8] -> size -> 47 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  3.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 11.  1.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8] -> size -> 47 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 11.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[41.902092]
 [41.2596  ]
 [41.2596  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 11.  1.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  3.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 3. 1. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -2.7462069988250732
desired expected reward: -16.12710952758789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.23627 ]
 [38.806732]
 [36.928814]
 [22.982548]
 [41.2596  ]
 [36.53363 ]
 [35.20341 ]
 [41.902092]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 11.  1.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  3.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 3. 1. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.61591100692749
desired expected reward: 36.28618240356445



buy possibilites: [-1] 
expected returns: [[30.869883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 11.  1.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  2.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 3. 1. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0 -13   0   0  18   0] 
sum of rewards: -82 

action type: buy - action 11.0
Learning step: -5.381402015686035
desired expected reward: 35.87821578979492






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 1. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  2.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  0.  3. 29.  8.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29. 11.  6. 11.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11] -> size -> 48 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  2.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  0.  3. 29.  8.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29. 11.  6. 11.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11] -> size -> 48 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1. 0.] 
cards in discard: [ 8.  0.  0.  3.  0.  3.  3.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  0.  3. 29.  8.] 
adversary cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29. 11.  6. 11.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11] -> size -> 48 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 6.  0.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[21.201063]
 [16.94582 ]
 [16.986658]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 29.  8.] 
cards in discard: [10.  1.  0. 10. 11. 11.  0.  1.  0.  6.  3.  3. 14.  3.  0.  1.  6. 10.
 11.  8. 23. 15.  6.  1. 10.  6.  6.  0. 16.  3.  6.  8. 11.  1.  0.  3.
 29. 11.  6. 11.  0. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  3.  0.  3.  3.  0.  0. 11.  3.  3.  3.  1.  0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11] -> size -> 21 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.469522953033447
desired expected reward: 25.400360107421875



action possibilites: [-1.  8.] 
expected returns: [[18.592354]
 [16.124178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 6.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  3.  0.  3.  3.  0.  0. 11.  3.  3.  3.  1.  0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11] -> size -> 21 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 29.0
Learning step: -3.8021531105041504
desired expected reward: 13.143659591674805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.836763]
 [15.898943]
 [13.51446 ]
 [15.48085 ]
 [17.921844]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 6.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 18. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  3.  0.  3.  3.  0.  0. 11.  3.  3.  3.  1.  0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11] -> size -> 21 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.921311140060425
desired expected reward: 14.671027183532715



buy possibilites: [-1] 
expected returns: [[24.45775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 6.] 
cards in discard: [3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  3.  0.  3.  3.  0.  0. 11.  3.  3.  3.  1.  0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0 -14   0   0   8   0] 
sum of rewards: -62 

action type: buy - action 3.0
Learning step: -3.3446476459503174
desired expected reward: 12.554287910461426






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  1.  0. 11.] 
cards in discard: [ 8.  0.  0.  3.  0.  3.  3.  0.  0. 11.  3.  3.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  0. 11.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3] -> size -> 49 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1. 0.] 
cards in discard: [ 8.  0.  0.  3.  0.  3.  3.  0.  0. 11.  3.  3.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  0. 11.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3] -> size -> 49 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 0.] 
cards in discard: [ 8.  0.  0.  3.  0.  3.  3.  0.  0. 11.  3.  3.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 16. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 11.  6.  0. 11.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3] -> size -> 49 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [ 0. 11.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[4.6328416]
 [3.4296904]
 [3.4296904]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 11.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3] -> size -> 22 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -5.43372106552124
desired expected reward: 19.024028778076172



action possibilites: [-1] 
expected returns: [[-8.032246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 16. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3] -> size -> 22 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0 -15   0   0   9   0] 
sum of rewards: -72 

action type: gain_card_n - action 1
Learning step: -3.8800430297851562
desired expected reward: -1.893691062927246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-15.6721325]
 [-12.260948 ]
 [-21.603659 ]
 [-16.173319 ]
 [-11.51049  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 21. 30. 16. 30.  8.  1.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3] -> size -> 22 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -3.231292724609375
desired expected reward: -11.263538360595703



buy possibilites: [-1] 
expected returns: [[25.612686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30. 16. 30.  8.  0.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3] -> size -> 22 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -90.    0.    0.   20.    0.    0.    0.    0.  -16.
    0. -300.    0.    0.] 
sum of rewards: -393.0 

action type: buy - action 6.0
Learning step: -17.993532180786133
desired expected reward: -39.59719467163086






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 16. 30.  8.  0.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  1. 14.  1. 10.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6] -> size -> 51 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 21. 30. 16. 30.  8.  0.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  1. 14.  1. 10.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6] -> size -> 51 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 8.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  1. 14.  1. 10.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6] -> size -> 51 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 6.  1. 14.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[ -9.938732]
 [-11.965654]
 [ -8.881687]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 14.  1. 10.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 3. 0. 6.] 
adversary cards in discard: [0. 3. 3. 0. 3. 8.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -6.356410980224609
desired expected reward: 19.256275177001953



action possibilites: [-1] 
expected returns: [[-12.896303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  1. 10.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 6.] 
adversary cards in discard: [0. 3. 3. 0. 3. 8. 3. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action 14.0
Learning step: -3.541883945465088
desired expected reward: -15.507543563842773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-11.834496]
 [-13.073647]
 [-10.105887]
 [-11.265598]
 [-10.159605]
 [-12.491739]
 [-12.699623]
 [-13.517309]
 [-15.083441]
 [-13.599152]
 [ -9.956806]
 [-10.448025]
 [-11.826992]
 [ -8.755917]
 [-11.610386]
 [-12.63212 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  1. 10.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 6.] 
adversary cards in discard: [0. 3. 3. 0. 3. 8. 3. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -3.459702253341675
desired expected reward: -16.35600471496582



buy possibilites: [-1] 
expected returns: [[-13.222895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  1. 10.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 6.] 
adversary cards in discard: [0. 3. 3. 0. 3. 8. 3. 0.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -90.    0.    0.   20.    0.    0.    0.    0.  -17.
   0.    0.   12.5   0. ] 
sum of rewards: -81.5 

action type: buy - action 25.0
Learning step: -3.6183433532714844
desired expected reward: -18.7017822265625






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [0. 3. 3. 0. 3. 8. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [10. 10.  3.  1.  1.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25] -> size -> 52 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [0. 3. 3. 0. 3. 8. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [10. 10.  3.  1.  1.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25] -> size -> 52 
adversary victory points: -2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 10.  3.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-7.0766573]
 [-9.09403  ]
 [-9.09403  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  1.  1.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  1.  0.  3. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 8. 3. 0. 3. 3. 6.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -4.373353481292725
desired expected reward: -17.596248626708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.357906 ]
 [ -8.533587 ]
 [ -7.208168 ]
 [-10.156336 ]
 [ -6.598144 ]
 [-10.7004795]
 [-10.624449 ]
 [-10.015415 ]
 [ -9.09403  ]
 [-10.026621 ]
 [ -7.0766573]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  1.  1.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 21. 30. 16. 30.  8.  0.  8.  1.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  1.  0.  3. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 8. 3. 0. 3. 3. 6.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.692137241363525
desired expected reward: -11.76880168914795



buy possibilites: [-1] 
expected returns: [[-13.320423]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  1.  1.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 21. 30. 15. 30.  8.  0.  8.  1.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  1.  0.  3. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 8. 3. 0. 3. 3. 6.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.   0.   0.   0.   0.   0. -18.   0.   0.
   2.   0.] 
sum of rewards: -102.0 

action type: buy - action 3.0
Learning step: -5.030802249908447
desired expected reward: -12.238972663879395






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  3. 11.] 
cards in discard: [0. 3. 3. 0. 3. 8. 3. 0. 3. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 30.  8.  0.  8.  1.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 15. 11. 23.  3.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3] -> size -> 53 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  3. 11.] 
cards in discard: [0. 3. 3. 0. 3. 8. 3. 0. 3. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 21. 30. 15. 30.  8.  0.  8.  1.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 15. 11. 23.  3.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3] -> size -> 53 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  3. 11.] 
cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 15. 30.  8.  0.  8.  0.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 15. 11. 23.  3.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3] -> size -> 53 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [11. 15. 11. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 23.] 
expected returns: [[ 0.92630816]
 [-0.3828416 ]
 [-3.044317  ]
 [-0.3828416 ]
 [-3.7380037 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11. 23.  3.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 30.  8.  0.  8.  0.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.  0.  1.  0.  3. 11.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -3.6554298400878906
desired expected reward: -16.975852966308594



action possibilites: [-1. 11. 15. 11. 11.] 
expected returns: [[-0.45499372]
 [-1.0236158 ]
 [-2.4341335 ]
 [-1.0236158 ]
 [-1.0236158 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11.  3. 11.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3] -> size -> 53 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 21. 30. 15. 30.  8.  0.  8.  0.  1.  9.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.  0.  1.  0.  3. 11.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 23.0
Learning step: -3.1371865272521973
desired expected reward: -6.875195026397705



action possibilites: [-1] 
expected returns: [[-42.779533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3. 11.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 21. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.  0.  1.  0.  3. 11.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0 -19   0   0  16   0] 
sum of rewards: -49 

action type: gain_card_n - action 5
Learning step: -3.277165651321411
desired expected reward: -5.984645366668701





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-68.83006 ]
 [-42.779552]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  3. 11.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29] -> size -> 54 
action values: 0 
buys: 2 
player value: 1 
card supply: [10. 21. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.  0.  1.  0.  3. 11.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -1.3683280944824219
desired expected reward: -44.14786148071289



buy possibilites: [ 0. -1.] 
expected returns: [[-34.064056]
 [-27.79059 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  3. 11.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 21. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.  0.  1.  0.  3. 11.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40 -30   0   0   0 -20   0   0   0   0] 
sum of rewards: -96 

action type: buy - action 0.0
Learning step: -2.042731523513794
desired expected reward: -70.87274932861328






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 1.] 
cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.  0.  1.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 8. 6. 1. 8.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 1.] 
cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.  0.  1.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 21. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 8. 6. 1. 8.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 1.] 
cards in discard: [ 0.  3.  3.  0.  3.  8.  3.  0.  3.  3.  6. 11.  0.  1.  0.  3. 11.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 20. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 8. 6. 1. 8.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [0. 8. 6. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-11.206894]
 [-11.837549]
 [-11.837549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 1. 8.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -3.1705265045166016
desired expected reward: -30.96111297607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-11.163069]
 [-11.382368]
 [-10.16165 ]
 [-11.837549]
 [-10.757343]
 [-11.206894]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1. 8.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 20. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -3.985640048980713
desired expected reward: -15.19253158569336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 15. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  0.  3.  0.  6.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.  0.  8.
  6.  1.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 14. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  0.  3.  0.  6.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.  0.  8.
  6.  1.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 20. 30. 14. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  0.  3.  0.  6.] 
adversary cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.  0.  8.
  6.  1.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [16.  0.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-13.114422]
 [ -9.767028]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0.  6.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.  0.  8.
  6.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3
  1  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11
  3  1  6 25  3 29  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 14. 30.  8.  0.  8.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1  3] -> size -> 26 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -4.490865230560303
desired expected reward: -15.697757720947266



action possibilites: [-1] 
expected returns: [[-17.519945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.  0.  8.
  6.  1.  8. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3  1
  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11  3
  1  6 25  3 29  0 16] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 14. 30.  8.  0.  7.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1  3] -> size -> 26 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0  -20    0    0
   16    0] 
sum of rewards: -91 

action type: gain_card_n - action 3
Learning step: -4.4509429931640625
desired expected reward: -14.316058158874512





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-14.102531]
 [-14.32535 ]
 [-16.074883]
 [-17.519947]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.  0.  8.
  6.  1.  8. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3  1
  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11  3
  1  6 25  3 29  0 16] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 20. 30. 14. 30.  8.  0.  7.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1  3] -> size -> 26 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action -1
Learning step: -3.8176770210266113
desired expected reward: -21.337621688842773



Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 3 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 6 
Chapel: 4 
Witch: 1 
Poacher: 2 
Militia: 1 
Market: 1 
Village: 1 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 0. 6.] 
cards in discard: [ 3. 29.  6.  0.  3.  8.  6.  1.  6. 11.  0.  6.  0. 11. 25. 14.  6.  1.
  1. 10.  3. 10. 10.  3.  1.  1. 29.  0. 23. 11. 15. 11.  3. 11.  0.  8.
  6.  1.  8. 16.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  6 29  1 15  3 11 11 14  6  0  6  6 29 10  3  1 11  3  1
  8 10  0 11 11  8 16  6 10  0 11  0  1 10  1  0  6  1  6 23  6  8 11  3
  1  6 25  3 29  0 16  8] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 14. 30.  8.  0.  7.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 6  8  3  0  3  0  0  0  1  0  3  0  0 11  8  3  3  3  1  3 11  3  0 11
  1  3] -> size -> 26 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2 -100    0    0   20    0    0    0    0  -21    0    0
    4    0] 
sum of rewards: -604 

action type: buy - action 8.0
Learning step: -29.396255493164062
desired expected reward: -45.47114181518555



