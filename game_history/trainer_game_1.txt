 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[338.29752]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -20 -1000    -2  -150     0     0     0     0     0     0     0     0
     0     0     0     0] 
sum of rewards: -1172 

action type: buy - action -1.0
Learning step: [-155.93883]
desired expected reward: 231.44947814941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[338.63504]
 [339.07098]
 [339.29596]
 [338.70923]
 [338.93423]
 [338.81985]
 [339.38162]
 [338.72064]
 [339.3415 ]
 [339.41574]
 [339.01993]
 [339.5551 ]
 [338.94565]
 [339.11914]
 [339.4559 ]
 [339.8124 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-14.006248]
desired expected reward: 325.8902587890625



buy possibilites: [-1] 
expected returns: [[346.7839]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -9.0 

action type: buy - action 15.0
Learning step: [-12.7935]
desired expected reward: 326.66241455078125






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[358.42844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1
Learning step: [-13.774852]
desired expected reward: 333.0090637207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[357.1391 ]
 [357.80008]
 [357.43832]
 [357.22476]
 [358.31656]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-15.102244]
desired expected reward: 344.74969482421875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [15.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[342.1699]
 [341.8133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1.0
Learning step: [-15.161944]
desired expected reward: 343.15460205078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[341.9792 ]
 [342.64017]
 [342.27847]
 [342.06485]
 [343.15668]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-13.737348]
desired expected reward: 330.1264953613281



buy possibilites: [-1] 
expected returns: [[340.07178]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: 2 

action type: buy - action 3.0
Learning step: [-11.567142]
desired expected reward: 331.0730285644531






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[362.41238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 15.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: buy - action -1
Learning step: [-10.843475]
desired expected reward: 329.2283020019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[362.48853]
 [362.92453]
 [363.14954]
 [362.5628 ]
 [362.78778]
 [362.6734 ]
 [363.23514]
 [362.57422]
 [363.19504]
 [363.26926]
 [362.87344]
 [363.4086 ]
 [362.7992 ]
 [362.9727 ]
 [363.30942]
 [363.666  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 15.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: [-13.192075]
desired expected reward: 350.6084289550781



buy possibilites: [-1] 
expected returns: [[359.75107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 15.  0.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20.   0.   4.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 4.0 

action type: buy - action 0.0
Learning step: [-13.127029]
desired expected reward: 349.36151123046875






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [6. 0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [6. 0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[338.35153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: buy - action -1
Learning step: [-13.315851]
desired expected reward: 346.4352111816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[340.524  ]
 [340.95996]
 [341.185  ]
 [340.8233 ]
 [341.27063]
 [340.60962]
 [340.83463]
 [341.70148]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: [-11.315463]
desired expected reward: 328.8670654296875



buy possibilites: [-1] 
expected returns: [[345.85672]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20.   0.   4.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 6.0 

action type: buy - action 8.0
Learning step: [-11.050488]
desired expected reward: 329.5591735839844






Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[355.07736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: buy - action -1
Learning step: [-11.497733]
desired expected reward: 334.3589782714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[356.09204]
 [356.528  ]
 [356.75302]
 [356.39133]
 [356.83868]
 [356.17767]
 [356.40268]
 [357.26956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: [-12.4650545]
desired expected reward: 343.52142333984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[347.90945]
 [347.5529 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: buy - action -1.0
Learning step: [-12.551645]
desired expected reward: 344.7178649902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[330.74744]
 [331.16046]
 [331.37228]
 [331.02795]
 [331.45142]
 [330.8265 ]
 [331.03836]
 [331.84946]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: [-10.012908]
desired expected reward: 321.78167724609375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[344.3069]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  3.  0. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: buy - action -1.0
Learning step: [-9.613586]
desired expected reward: 322.23583984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[345.24606]
 [345.6592 ]
 [345.871  ]
 [345.52664]
 [345.95007]
 [345.3252 ]
 [345.5371 ]
 [346.34814]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  3.  0. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: [-10.931984]
desired expected reward: 334.428466796875



buy possibilites: [-1] 
expected returns: [[338.57623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  3.  0. 15.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 22 

action type: buy - action 11.0
Learning step: [-9.341188]
desired expected reward: 336.6089172363281






Player: 1 
cards in hand: [0. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11] -> size -> 15 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11] -> size -> 15 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11] -> size -> 15 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [15.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[331.84805]
 [331.5187 ]
 [330.82516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: buy - action -1
Learning step: [-10.380754]
desired expected reward: 328.1954650878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[331.10315]
 [331.728  ]
 [331.38364]
 [331.18222]
 [332.20517]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-20   0   4  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: [-9.847289]
desired expected reward: 323.1935729980469



buy possibilites: [-1] 
expected returns: [[345.56445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -20.    0.    3.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -307.0 

action type: buy - action 6.0
Learning step: [-40.56659]
desired expected reward: 290.8170471191406






Player: 1 
cards in hand: [ 0.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 6. 15.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 6. 15.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[358.43765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6. 15.  8.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: buy - action -1
Learning step: [-11.88165]
desired expected reward: 333.68280029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[358.98035]
 [359.39337]
 [359.60526]
 [359.2609 ]
 [359.68436]
 [359.05945]
 [359.27127]
 [360.08237]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6. 15.  8.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: [-13.201018]
desired expected reward: 345.8996887207031



buy possibilites: [-1] 
expected returns: [[360.24487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6. 15.  8.  0.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 11 

action type: buy - action 1.0
Learning step: [-11.349843]
desired expected reward: 348.0435485839844






Player: 1 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 6. 15.  8.  0.  3.  0.  1.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 6. 15.  8.  0.  3.  0.  1.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1] -> size -> 17 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[345.2431]
 [344.8451]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [ 6. 15.  8.  0.  3.  0.  1.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: buy - action -1
Learning step: [-13.320264]
desired expected reward: 346.92462158203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[345.55624]
 [345.96927]
 [346.18115]
 [345.83676]
 [346.26028]
 [345.6353 ]
 [345.8472 ]
 [346.65826]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [ 6. 15.  8.  0.  3.  0.  1.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: [-11.821937]
desired expected reward: 333.9237976074219



buy possibilites: [-1] 
expected returns: [[353.84497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [ 6. 15.  8.  0.  3.  0.  1.  0.  3.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20.   0.   3.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -5.0 

action type: buy - action 8.0
Learning step: [-11.210876]
desired expected reward: 334.4244689941406






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[342.71658]
 [341.69363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: buy - action -1
Learning step: [-12.858815]
desired expected reward: 340.98614501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[342.43454]
 [342.8476 ]
 [343.05945]
 [342.71506]
 [343.1386 ]
 [342.51367]
 [342.72552]
 [343.5366 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: [-11.839091]
desired expected reward: 331.7428283691406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [ 0.  0.  0.  3.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[349.70523]
 [349.30722]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3.] 
cards in discard: [0. 3. 0. 8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: buy - action -1.0
Learning step: [-11.547467]
desired expected reward: 331.9891357421875



action possibilites: [-1] 
expected returns: [[347.5694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  8.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 29 

action type: gain_card_n - action 8
Learning step: [-6.47016]
desired expected reward: 330.4592590332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[346.98126]
 [347.57492]
 [347.2455 ]
 [347.05505]
 [348.0195 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  8.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-20   0   3  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 13 

action type: take_action - action -1
Learning step: [-9.109949]
desired expected reward: 338.4594421386719






Player: 1 
cards in hand: [0. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  0. 14. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  0. 14. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  0. 14. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14] -> size -> 19 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[340.22437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [ 0.  3.  0.  8.  0. 14. 11.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [6. 0. 3. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: buy - action -1.0
Learning step: [-10.176665]
desired expected reward: 337.8428649902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[340.69025]
 [341.08344]
 [341.28387]
 [340.95447]
 [340.85397]
 [341.35764]
 [340.76398]
 [341.3847 ]
 [341.0282 ]
 [340.96445]
 [341.4214 ]
 [341.7285 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [ 0.  3.  0.  8.  0. 14. 11.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 29. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [6. 0. 3. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: take_action - action -1.0
Learning step: [-9.399814]
desired expected reward: 331.4427795410156



buy possibilites: [-1] 
expected returns: [[336.57153]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [ 0.  3.  0.  8.  0. 14. 11.  3.  0.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [6. 0. 3. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20.    0.    3.   20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 7.5 

action type: buy - action 1.0
Learning step: [-9.265773]
desired expected reward: 331.81768798828125






Player: 1 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [6. 0. 3. 0. 6. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [6. 0. 3. 0. 6. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [6. 0. 3. 0. 6. 3. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[336.2194 ]
 [335.2549 ]
 [335.91232]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  0. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 6.  0.  3.  0.  6.  3.  8.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: buy - action -1
Learning step: [-9.129071]
desired expected reward: 327.4424743652344



action possibilites: [-1] 
expected returns: [[340.54303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 6.  0.  3.  0.  6.  3.  8.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: take_action - action 15.0
Learning step: [-7.3672943]
desired expected reward: 329.27911376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[338.8688 ]
 [339.26202]
 [339.46246]
 [339.13303]
 [339.53625]
 [338.9426 ]
 [339.143  ]
 [339.907  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 6.  0.  3.  0.  6.  3.  8.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: take_action - action -1
Learning step: [-7.797095]
desired expected reward: 332.7459411621094






Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 6.  0.  3.  0.  6.  3.  8.  8.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  6.] 
adversary cards in discard: [15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 6.  0.  3.  0.  6.  3.  8.  8.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  6.] 
adversary cards in discard: [15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[345.0893 ]
 [344.38904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0.  6.] 
cards in discard: [15.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: buy - action -1.0
Learning step: [-9.429834]
desired expected reward: 330.4772033691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[345.28467]
 [345.67786]
 [345.8783 ]
 [345.54883]
 [345.4484 ]
 [345.9521 ]
 [345.3584 ]
 [345.97913]
 [345.6226 ]
 [345.55884]
 [346.0158 ]
 [346.32288]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.  6.] 
cards in discard: [15.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: take_action - action -1.0
Learning step: [-9.962813]
desired expected reward: 335.8658447265625



buy possibilites: [-1] 
expected returns: [[354.1546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.  6.] 
cards in discard: [15.  3.  3.  8. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 35 

action type: buy - action 16.0
Learning step: [-5.9567933]
desired expected reward: 339.49163818359375






Player: 1 
cards in hand: [ 0.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  3.  0.  3.] 
adversary cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  3.  0.  3.] 
adversary cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  3.  0.  3.] 
adversary cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16] -> size -> 20 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[348.19846]
 [347.82767]
 [347.23404]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  0.  3.] 
cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: buy - action -1
Learning step: [-10.090207]
desired expected reward: 344.06439208984375



action possibilites: [-1] 
expected returns: [[359.85907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 39 

action type: gain_card_n - action 8
Learning step: [-4.8528476]
desired expected reward: 342.64013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[359.02774]
 [359.29193]
 [360.06598]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: take_action - action -1
Learning step: [-7.686649]
desired expected reward: 352.17242431640625






Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 0.  0.  6.  3. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6  8  0  0 11  6  8  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6. 14. 11.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14] -> size -> 21 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0.  6.  3. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6. 14. 11.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14] -> size -> 21 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0.  6.  3. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6. 14. 11.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14] -> size -> 21 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[341.47015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6. 14. 11.  8.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  6.  3. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-20   0   3  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 13 

action type: buy - action -1.0
Learning step: [-7.989334]
desired expected reward: 337.25634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[342.47992]
 [342.8578 ]
 [342.67157]
 [343.04947]
 [342.5401 ]
 [342.73175]
 [342.63666]
 [343.1194 ]
 [342.5498 ]
 [343.0844 ]
 [343.14462]
 [342.8017 ]
 [343.2664 ]
 [342.7415 ]
 [342.88852]
 [343.17957]
 [343.47183]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6. 14. 11.  8.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  6.  3. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-20   0   3  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 13 

action type: take_action - action -1.0
Learning step: [-7.5369782]
desired expected reward: 334.0341491699219



buy possibilites: [-1] 
expected returns: [[345.90952]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [15.  3.  3.  8. 16.  0.  1. 14.  0.  6. 14. 11.  8.  3.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  6.  3. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-20.   0.   3.  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: 21.0 

action type: buy - action 14.0
Learning step: [-6.639203]
desired expected reward: 336.1625061035156






Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 0.  0.  6.  3. 10.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  6.  3. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 0.  0.  6.  3. 10.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  6. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  6.  3. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 0.  0.  6.  3. 10.  0.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  6.  3. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [14.  6.  3. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 14.] 
expected returns: [[339.16006]
 [338.4899 ]
 [338.80756]
 [338.4899 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3. 11. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  8.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-20   0   3  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 13 

action type: buy - action -1
Learning step: [-7.839725]
desired expected reward: 338.0697937011719



action possibilites: [-1] 
expected returns: [[331.04712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3. 14.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  8.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -20    0    2   20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -278 

action type: gain_card_n - action 3
Learning step: [-36.4003]
desired expected reward: 303.0097351074219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[329.65585]
 [329.9077 ]
 [330.64783]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  3. 14.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  8.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action -1
Learning step: [-5.595758]
desired expected reward: 325.45135498046875






Player: 1 
cards in hand: [ 3.  8.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  6  8  0  0 11  6  8  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14. 15.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14. 15.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14. 15.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14. 15.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[352.4641 ]
 [351.79388]
 [352.17175]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 15.  3.  0.] 
cards in discard: [ 6. 11. 14.  6.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-20   0   2  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: buy - action -1.0
Learning step: [-5.136856]
desired expected reward: 325.510986328125



action possibilites: [-1] 
expected returns: [[365.46576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.] 
cards in discard: [ 6. 11. 14.  6.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-20   0   2  40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 42 

action type: take_action - action 14.0
Learning step: [-4.8003387]
desired expected reward: 347.5631103515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[365.3136 ]
 [365.69147]
 [365.8831 ]
 [365.56543]
 [365.47034]
 [365.953  ]
 [365.38345]
 [365.9783 ]
 [365.63535]
 [365.57513]
 [366.0132 ]
 [366.30554]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.] 
cards in discard: [ 6. 11. 14.  6.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-20   0   2  40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 42 

action type: take_action - action -1
Learning step: [-6.0613465]
desired expected reward: 359.4044189453125



buy possibilites: [-1] 
expected returns: [[366.42682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.] 
cards in discard: [ 6. 11. 14.  6.  3. 14. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-20   0   2  40   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 74 

action type: buy - action 14.0
Learning step: [-2.6400726]
desired expected reward: 362.99530029296875






Player: 1 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [6. 8. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6. 8. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[353.1851]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [6. 8. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-20   0   2  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: buy - action -1
Learning step: [-8.625476]
desired expected reward: 357.80133056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[352.5771 ]
 [352.95493]
 [353.14658]
 [352.82898]
 [353.2165 ]
 [352.64694]
 [352.8386 ]
 [353.56903]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [6. 8. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-20   0   2  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action -1.0
Learning step: [-7.3121185]
desired expected reward: 346.1436767578125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [6. 8. 6. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [6. 8. 6. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  6  0  0  6  8  0  8  6] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6. 8. 6. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10  0  0  6  8  0  8  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 8. 6. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10  0  0  6  8  0  8  6] -> size -> 9 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 16.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
expected returns: [[351.19385]
 [350.2718 ]
 [350.3586 ]
 [350.2718 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  8.  1.] 
cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  0  0  6  8  0  8  6] -> size -> 9 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 12 

action type: buy - action -1.0
Learning step: [-8.542193]
desired expected reward: 345.0268249511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[350.98145]
 [351.35938]
 [351.55106]
 [351.2334 ]
 [351.62094]
 [351.05142]
 [351.24307]
 [351.97345]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  8.  1.] 
cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  0  0  6  8  0  8  6] -> size -> 9 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 12 

action type: take_action - action -1.0
Learning step: [-8.297541]
desired expected reward: 342.9951477050781



buy possibilites: [-1] 
expected returns: [[338.07397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  8.  1.] 
cards in discard: [ 6. 11. 14.  6.  3. 14. 14. 14.  0. 15.  3.  0.  3.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  0  0  6  8  0  8  6] -> size -> 9 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-20.   0.   3.  40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 25.0 

action type: buy - action 3.0
Learning step: [-6.949405]
desired expected reward: 344.60162353515625






Player: 1 
cards in hand: [10.  8.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  0  0  6  8  0  8  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 0 0 8 0 8 6] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 0 0 8 0 8 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  5.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 0 0 8 0 8 6 6] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[301.82587]
 [300.9364 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  0  8 11  6  1  8 14  1 16 14 14  6 14
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6] -> size -> 8 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: buy - action -1
Learning step: [-7.758014]
desired expected reward: 330.3159484863281



action possibilites: [-1] 
expected returns: [[292.82715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8 14  1 16 14 14  6 14  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6] -> size -> 8 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 43 

action type: trash_cards_n_from_hand - action 2
Learning step: [-2.6401336]
desired expected reward: 299.5294494628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[293.06766]
 [293.61853]
 [293.3098 ]
 [293.135  ]
 [294.02444]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8 14  1 16 14 14  6 14  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6] -> size -> 8 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 43 

action type: take_action - action -1
Learning step: [-1.6395692]
desired expected reward: 291.1875915527344



buy possibilites: [-1] 
expected returns: [[298.85846]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8 14  1 16 14 14  6 14  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  4.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6] -> size -> 8 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-20.   0.   3.  40.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 43.0 

action type: buy - action 0.0
Learning step: [-1.6093048]
desired expected reward: 291.4583435058594






Player: 1 
cards in hand: [6. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  3. 11. 14.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8 14  1 16 14 14  6 14  3  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  4.  9.  8.  5. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  3. 11. 14.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8 14  1 16 14 14  6 14  3  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  3. 11. 14.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8 14  1 16 14 14  6 14  3  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [16.  0.  3. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 14.] 
expected returns: [[329.16736]
 [328.36215]
 [328.8288 ]
 [328.52008]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3. 11. 14.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8 14  1 16 14 14  6 14  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: buy - action -1
Learning step: [-2.5896363]
desired expected reward: 296.2688293457031



action possibilites: [-1] 
expected returns: [[320.70233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [0. 8. 0. 0. 4.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: 101 

action type: gain_card_n - action 4
Learning step: [3.6197815]
desired expected reward: 312.0731506347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[319.92065]
 [320.16278]
 [320.87744]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [0. 8. 0. 0. 4.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 76 

action type: take_action - action -1
Learning step: [-0.08080139]
desired expected reward: 320.62152099609375



buy possibilites: [-1] 
expected returns: [[324.3421]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [0. 8. 0. 0. 4. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  70.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 76.0 

action type: buy - action 0.0
Learning step: [0.07602539]
desired expected reward: 319.9966735839844






Player: 1 
cards in hand: [6. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  6.  1. 14. 14.] 
adversary cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0] -> size -> 25 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  6.  1. 14. 14.] 
adversary cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0] -> size -> 25 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 8.  6.  1. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 14.] 
expected returns: [[336.6458 ]
 [335.75635]
 [335.99854]
 [335.99854]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  1. 14. 14.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: buy - action -1
Learning step: [-1.3733491]
desired expected reward: 322.96875



action possibilites: [-1] 
expected returns: [[327.499]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  1. 14.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 76 

action type: take_action - action 14.0
Learning step: [-0.7757599]
desired expected reward: 335.7384338378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[327.56598]
 [327.93216]
 [328.11685]
 [327.80807]
 [327.71756]
 [328.1842 ]
 [327.6333 ]
 [328.20853]
 [327.8755 ]
 [327.81796]
 [328.24164]
 [328.52274]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  1. 14.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 76 

action type: take_action - action -1
Learning step: [0.17269897]
desired expected reward: 327.67169189453125



buy possibilites: [-1] 
expected returns: [[324.99045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  1. 14.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  70.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 76.0 

action type: buy - action 0.0
Learning step: [0.15947266]
desired expected reward: 327.7254638671875






Player: 1 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6. 14.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6. 14.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[342.8411]
 [342.1938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14.  3.  3.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: buy - action -1
Learning step: [-1.2212342]
desired expected reward: 323.76922607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[340.8128 ]
 [341.05566]
 [341.77112]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  3.  3.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: take_action - action -1.0
Learning step: [-2.9378052]
desired expected reward: 339.0135803222656



buy possibilites: [-1] 
expected returns: [[337.56375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  3.  3.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 56.0 

action type: buy - action 0.0
Learning step: [-3.1809814]
desired expected reward: 337.6318359375






Player: 1 
cards in hand: [0. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.  0.  0.
  6. 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0  0] -> size -> 27 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.  0.  0.
  6. 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0  0] -> size -> 27 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.  0.  0.
  6. 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0  0] -> size -> 27 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[333.899  ]
 [333.61707]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  3.  0.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.  0.  0.
  6. 14.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: buy - action -1
Learning step: [-2.7322176]
desired expected reward: 334.83154296875



action possibilites: [-1] 
expected returns: [[315.34076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.  0.  0.
  6. 14.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 76 

action type: take_action - action 15.0
Learning step: [-0.77890015]
desired expected reward: 332.838134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[314.77335]
 [315.13904]
 [315.32358]
 [315.01617]
 [314.9247 ]
 [315.3914 ]
 [314.8412 ]
 [315.41663]
 [315.08405]
 [315.02567]
 [315.4497 ]
 [315.73166]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  8.  0.  0.  4.  0. 16.  0.  3. 11.  0. 14.  8.  6.  1. 14.  0.  0.
  6. 14.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 76 

action type: take_action - action -1
Learning step: [1.0922486]
desired expected reward: 316.4330139160156






Player: 1 
cards in hand: [3. 0. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11.  8.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
expected returns: [[315.28592]
 [314.94565]
 [314.39548]
 [314.47897]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10. 10.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [3. 0. 8. 6. 8.] 
adversary owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: buy - action -1.0
Learning step: [-2.1103485]
desired expected reward: 313.621337890625



action possibilites: [-1] 
expected returns: [[328.65564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  3.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [3. 0. 8. 6. 8.] 
adversary owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 92 

action type: gain_card_n - action 7
Learning step: [2.6461701]
desired expected reward: 316.4011535644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[327.83524]
 [328.0781 ]
 [328.79355]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  3.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 29.  8.  4.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [3. 0. 8. 6. 8.] 
adversary owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 76 

action type: take_action - action -1
Learning step: [-0.4475586]
desired expected reward: 328.20806884765625



buy possibilites: [-1] 
expected returns: [[326.21417]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  3.] 
cards in discard: [29.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 28. 29.  8.  3.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [3. 0. 8. 6. 8.] 
adversary owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -20.    0.    5.   60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -235.0 

action type: buy - action 6.0
Learning step: [-30.890766]
desired expected reward: 297.1872863769531






Player: 1 
cards in hand: [0. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [3. 0. 8. 6. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 0 8 0 8 6 6 8 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  3.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 14.  0.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6] -> size -> 28 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [3. 0. 8. 6. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 0 8 6 6 8 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  3.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 14.  0.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6] -> size -> 28 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [3. 0. 8. 6. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 0 8 6 6 8 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 29.  8.  3.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 14.  0.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6] -> size -> 28 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [3. 0. 8. 6. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 0 8 6 6 8 0 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 14.  0.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6] -> size -> 28 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[339.2113 ]
 [338.56366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 14.  0.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0 8 6 6 8 0 6] -> size -> 9 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-20   0   5  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: [-1.446521]
desired expected reward: 324.76763916015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[339.53204]
 [340.0822 ]
 [339.7749 ]
 [339.59988]
 [340.4904 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 14.  0.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  4. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0 8 6 6 8 0 6] -> size -> 9 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-20   0   5  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: [-2.7758424]
desired expected reward: 336.9513854980469



buy possibilites: [-1] 
expected returns: [[353.4575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 14.  0.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0 8 6 6 8 0 6] -> size -> 9 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-20   0   5  70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: 63 

action type: buy - action 8.0
Learning step: [-1.3317627]
desired expected reward: 338.26812744140625






Player: 1 
cards in hand: [6. 8. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 8 6 6 8 0 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8] -> size -> 29 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 6 8 0 6] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8] -> size -> 29 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 6 8 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8] -> size -> 29 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[345.39774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-20   0   5  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: [-4.033011]
desired expected reward: 349.4244689941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[345.08496]
 [345.45068]
 [345.63513]
 [345.32782]
 [345.703  ]
 [345.15283]
 [345.3373 ]
 [346.04333]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 28. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-20   0   5  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: [-3.239084]
desired expected reward: 342.42047119140625



buy possibilites: [-1] 
expected returns: [[344.88333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6] -> size -> 7 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 68.0 

action type: buy - action 3.0
Learning step: [-2.078943]
desired expected reward: 343.55621337890625






Player: 1 
cards in hand: [8. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 14.  1.  8.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  3. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 14.  1.  8.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 8. 0.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 14.  1.  8.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [14.  0. 14.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
expected returns: [[332.59317]
 [331.94385]
 [331.94385]
 [331.69937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 14.  1.  8.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8] -> size -> 8 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-20   0   6  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 66 

action type: buy - action -1
Learning step: [-2.102188]
desired expected reward: 342.7811279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[331.38525]
 [331.7514 ]
 [331.93634]
 [331.62976]
 [332.0047 ]
 [331.45364]
 [331.63858]
 [332.34744]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 14.  1.  8.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8] -> size -> 8 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-20   0   6  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 66 

action type: take_action - action -1.0
Learning step: [-0.8477112]
desired expected reward: 331.7138671875



buy possibilites: [-1] 
expected returns: [[330.08566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 14.  1.  8.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8] -> size -> 8 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-20   0   6  80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 84 

action type: buy - action 10.0
Learning step: [1.2491974]
desired expected reward: 332.88775634765625






Player: 1 
cards in hand: [8. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 15.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4. 10. 14.  0. 14.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10] -> size -> 31 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 15.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4. 10. 14.  0. 14.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10] -> size -> 31 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 8. 6.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 15.] 
adversary cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4. 10. 14.  0. 14.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10] -> size -> 31 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[340.81464]
 [340.5315 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  3. 15.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4. 10. 14.  0. 14.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8 0] -> size -> 9 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-20   0   6  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 66 

action type: buy - action -1
Learning step: [-0.31228638]
desired expected reward: 329.77337646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[339.82974]
 [340.07425]
 [340.79193]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  3. 15.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4. 10. 14.  0. 14.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 27. 29.  8.  2.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8 0] -> size -> 9 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-20   0   6  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 66 

action type: take_action - action -1.0
Learning step: [-1.3745667]
desired expected reward: 339.4400634765625



buy possibilites: [-1] 
expected returns: [[344.00635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  3. 15.] 
cards in discard: [29.  6. 11.  8.  0. 16.  3.  8.  0.  3.  6. 14.  0.  3.  3.  0.  0.  0.
  4. 10. 14.  0. 14.  1.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 27. 29.  8.  1.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8 0] -> size -> 9 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -20.    0.    5.   70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -245.0 

action type: buy - action 6.0
Learning step: [-32.10313]
desired expected reward: 307.97113037109375






Player: 1 
cards in hand: [6. 6. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 29.  8.  1.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10  6] -> size -> 32 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 27. 29.  8.  1.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10  6] -> size -> 32 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 8.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8 0 6] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 27. 29.  8.  0.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10  6] -> size -> 32 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6. 16.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[319.30472]
 [318.49396]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8  1 16 14 14  6 14  3  0  4  0
  0  0 29  6  8  3 10  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 29.  8.  0.  9.  8.  2. 10.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8 0 6] -> size -> 10 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-20   0   5  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: buy - action -1
Learning step: [-3.3322327]
desired expected reward: 340.6741027832031



action possibilites: [-1] 
expected returns: [[353.4889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8 0 6] -> size -> 10 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-20   0   5  80   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: 110 

action type: gain_card_n - action 7
Learning step: [5.2603974]
desired expected reward: 327.9085388183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[353.37006]
 [354.33224]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 27. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 6 8 0 6 8 0 6] -> size -> 10 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-20   0   5  80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: [-0.27158815]
desired expected reward: 353.2173156738281






Player: 1 
cards in hand: [6. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8 0 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  8.  0.  0.] 
adversary cards in discard: [25. 16.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8 0 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 27. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  8.  0.  0.] 
adversary cards in discard: [25. 16.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 8.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8 0 6 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  8.  0.  0.] 
adversary cards in discard: [25. 16.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[350.5682 ]
 [350.25156]
 [349.67438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8.  0.  0.] 
cards in discard: [25. 16.  6.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [8. 6. 6. 8. 0.] 
adversary cards in discard: [3. 6. 0. 8. 0. 8.] 
adversary owned cards: [8 0 8 6 8 0 6 8 0 6 3] -> size -> 11 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-20   0   5  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: [-2.8245575]
desired expected reward: 351.5076904296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[350.22772]
 [350.7788 ]
 [350.29614]
 [351.1899 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  8.  0.  0.] 
cards in discard: [25. 16.  6.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [8. 6. 6. 8. 0.] 
adversary cards in discard: [3. 6. 0. 8. 0. 8.] 
adversary owned cards: [8 0 8 6 8 0 6 8 0 6 3] -> size -> 11 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[-20   0   5  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: [-2.4984987]
desired expected reward: 348.39166259765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 8. 0.] 
cards in discard: [3. 6. 0. 8. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 6 8 0 6 8 0 6 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 4.  3.  6. 14. 10.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [3. 6. 0. 8. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 8 0 8 0 6 3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 4.  3.  6. 14. 10.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [3. 6. 0. 8. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 8 0 8 0 6 3] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 4.  3.  6. 14. 10.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [3. 6. 0. 8. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 8 0 8 0 6 3 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 4.  3.  6. 14. 10.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 4.  3.  6. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[386.18338]
 [385.5341 ]
 [385.47446]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3.  6. 14. 10.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 8 0 8 0 6 3 0] -> size -> 10 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-20   0   5  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 35 

action type: buy - action -1.0
Learning step: [-4.177939]
desired expected reward: 347.0119934082031



action possibilites: [-1] 
expected returns: [[369.14136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3.  6. 10.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [8 0 8 8 0 8 0 6 3 0] -> size -> 10 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-20   0   5  50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action 14.0
Learning step: [-5.919702]
desired expected reward: 379.7133483886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[369.27637]
 [369.82745]
 [369.34473]
 [370.23853]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  3.  6. 10.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 26. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [8 0 8 8 0 8 0 6 3 0] -> size -> 10 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-20   0   5  50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: [-4.25723]
desired expected reward: 364.8841247558594



buy possibilites: [-1] 
expected returns: [[376.45297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  3.  6. 10.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [8 0 8 8 0 8 0 6 3 0] -> size -> 10 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-20   0   6  60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 74 

action type: buy - action 3.0
Learning step: [-2.0766022]
desired expected reward: 366.7320251464844






Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 8 0 8 0 6 3 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0. 15. 14.  3.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3] -> size -> 33 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 8 0 8 0 6 3 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0. 15. 14.  3.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3] -> size -> 33 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  6. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  8  0  8  0  6  3  0 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 15. 14.  3.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3] -> size -> 33 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 15. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[374.15598]
 [373.87473]
 [373.50784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15. 14.  3.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 8. 8. 0.] 
adversary cards in discard: [ 3.  6. 10.  0.  0.  0.] 
adversary owned cards: [ 8  0  8  8  0  8  0  6  3  0 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-20   0   6  60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: [-5.6150513]
desired expected reward: 370.8379211425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[372.96237]
 [373.9235 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15. 14.  3.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 8. 8. 0.] 
adversary cards in discard: [ 3.  6. 10.  0.  0.  0.] 
adversary owned cards: [ 8  0  8  8  0  8  0  6  3  0 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-20   0   6  60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: [-5.3827853]
desired expected reward: 368.773193359375



buy possibilites: [-1] 
expected returns: [[370.07788]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15. 14.  3.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 8. 8. 0.] 
adversary cards in discard: [ 3.  6. 10.  0.  0.  0.] 
adversary owned cards: [ 8  0  8  8  0  8  0  6  3  0 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 46.0 

action type: buy - action 0.0
Learning step: [-5.477878]
desired expected reward: 367.4844970703125






Player: 1 
cards in hand: [8. 8. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 8. 0.] 
cards in discard: [ 3.  6. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  8  0  8  0  6  3  0 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 11. 14.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 8. 0.] 
cards in discard: [ 3.  6. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  8  0  8  0  6  3  0 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 11. 14.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 8. 0.] 
cards in discard: [ 3.  6. 10.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  8  0  8  0  6  3  0 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 11. 14.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  3. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 14.] 
expected returns: [[360.73685]
 [359.84427]
 [359.84427]
 [360.39594]
 [360.0887 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 11. 14.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14 14  6 14  3  0  4  0  0
  0 29  6  8  3 10  6 25  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  8  0  8  0  6  3  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-20   0   6  60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: [-5.0753145]
desired expected reward: 365.0025634765625



action possibilites: [-1] 
expected returns: [[329.61414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  8  0  8  0  6  3  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-20   0   6  60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 66 

action type: trash_cards_n_from_hand - action 3
Learning step: [-2.7215943]
desired expected reward: 358.0503234863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[328.68433]
 [329.64542]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  8  0  8  0  6  3  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-20   0   6  60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 66 

action type: take_action - action -1
Learning step: [0.43214417]
desired expected reward: 330.0462646484375



buy possibilites: [-1] 
expected returns: [[327.53024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  8  0  8  0  6  3  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-20   0   6  60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 66 

action type: buy - action 0.0
Learning step: [0.08635254]
desired expected reward: 328.77069091796875






Player: 1 
cards in hand: [0. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  8  0  8  0  6  3  0 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.  0.  8.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  0  8  0  3  0 10  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.  0.  8.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  0  8  0  3  0 10  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.  0.  8.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  0  8  0  3  0 10  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.  0.  8.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[358.52072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.  0.  8.  8.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 8  8  8  0  8  0  3  0 10  0  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: [-3.123294]
desired expected reward: 324.4069519042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[358.2908 ]
 [358.65768]
 [358.8425 ]
 [358.44153]
 [358.91098]
 [358.3593 ]
 [358.9365 ]
 [358.60373]
 [358.5441 ]
 [358.9706 ]
 [359.2519 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.  0.  8.  8.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 8  8  8  0  8  0  3  0 10  0  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: [-6.1205354]
desired expected reward: 352.4001770019531



buy possibilites: [-1] 
expected returns: [[360.98434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [25. 16.  6.  3.  0.  3. 29.  8.  0.  0.  3. 14.  4.  3.  6. 10.  0.  6.
  0. 15. 14.  3.  0.  8.  8.  3. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 8  8  8  0  8  0  3  0 10  0  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-20.    0.    6.   50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 40.5 

action type: buy - action 10.0
Learning step: [-5.483124]
desired expected reward: 353.0610046386719






Player: 1 
cards in hand: [ 8. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3.  0.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  0  8  0  3  0 10  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  6. 10.  9.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10] -> size -> 35 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  3.  0.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  0  8  0  3  0 10  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  6. 10.  9.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10] -> size -> 35 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  3.  0.] 
cards in discard: [0. 8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  0  8  0  3  0 10  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  6. 10.  9.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10] -> size -> 35 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [14.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[323.3546 ]
 [322.70642]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  0  8  0  3  0 10  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: [-7.7849884]
desired expected reward: 353.1993408203125



action possibilites: [-1] 
expected returns: [[338.68173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  6. 10.  9.] 
adversary cards in hand: [8. 8. 8.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  8  8  0  8  0  3  0 10  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: take_action - action 14.0
Learning step: [-1.7996033]
desired expected reward: 321.4874572753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[338.77927]
 [339.1461 ]
 [339.3309 ]
 [338.9299 ]
 [339.39938]
 [338.84772]
 [339.42493]
 [339.09216]
 [339.0325 ]
 [339.459  ]
 [339.74036]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  6. 10.  6. 10.  9.] 
adversary cards in hand: [8. 8. 8.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  8  8  0  8  0  3  0 10  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: take_action - action -1
Learning step: [-3.2917817]
desired expected reward: 335.38995361328125



buy possibilites: [-1] 
expected returns: [[345.69174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [8. 8. 8.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  8  8  0  8  0  3  0 10  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  50   0   0  20   0   0   0   0  -1   0   0  32   0] 
sum of rewards: 87 

action type: buy - action 14.0
Learning step: [0.62041014]
desired expected reward: 339.7125549316406






Player: 1 
cards in hand: [8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  0  8  0  3  0 10  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  8.  4.  6. 14.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10 14] -> size -> 36 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  8.  4.  6. 14.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10 14] -> size -> 36 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  8.  4.  6. 14.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10 14] -> size -> 36 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  4.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[345.97488]
 [345.0808 ]
 [345.32602]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  4.  6. 14.] 
cards in discard: [14. 14.  0.  3.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  6  8 16 14  6 14  3  0  4  0  0  0
 29  6  8  3 10  6 25  3  0  0 10 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [0. 0. 8.] 
adversary owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-20   0   6  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: [-4.855902]
desired expected reward: 340.8358459472656



action possibilites: [-1] 
expected returns: [[327.34885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [14. 14.  0.  3.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [0. 0. 8.] 
adversary owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 34 

action type: trash_cards_n_from_hand - action 10
Learning step: [-6.5238433]
desired expected reward: 339.12646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[327.57108]
 [328.53378]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [14. 14.  0.  3.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [0. 0. 8.] 
adversary owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 34 

action type: take_action - action -1
Learning step: [-4.662637]
desired expected reward: 322.68621826171875






Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 16. 11.  8.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14] -> size -> 33 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 16. 11.  8.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14] -> size -> 33 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 16. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 11.  8.] 
expected returns: [[346.9451 ]
 [346.2365 ]
 [346.13306]
 [346.60544]
 [346.05103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 16. 11.  8.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: buy - action -1.0
Learning step: [-6.0136504]
desired expected reward: 322.5201416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[346.28757]
 [347.25027]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 16. 11.  8.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: take_action - action -1.0
Learning step: [-7.883148]
desired expected reward: 339.1952819824219



buy possibilites: [-1] 
expected returns: [[348.08035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 16. 11.  8.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: buy - action 0.0
Learning step: [-7.575464]
desired expected reward: 338.71209716796875






Player: 1 
cards in hand: [ 0.  8.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0 10  0  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 25.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 0 3 0 0 0 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 25.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 0 3 0 0 0 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 25.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 0 3 0 0 0 0 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 25.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[359.75363]
 [359.04504]
 [359.37912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 25.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 0. 3.] 
adversary owned cards: [8 0 8 0 3 0 0 0 0 0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: buy - action -1
Learning step: [-7.4637485]
desired expected reward: 340.6166076660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[359.38174]
 [359.7506 ]
 [359.93613]
 [360.00476]
 [359.4504 ]
 [359.6359 ]
 [360.34448]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 25.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 0. 3.] 
adversary owned cards: [8 0 8 0 3 0 0 0 0 0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: take_action - action -1.0
Learning step: [-8.57471]
desired expected reward: 351.1098937988281



buy possibilites: [-1] 
expected returns: [[361.38684]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 25.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 0. 3.] 
adversary owned cards: [8 0 8 0 3 0 0 0 0 0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 32 

action type: buy - action 10.0
Learning step: [-6.382324]
desired expected reward: 353.2535400390625






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [0. 8. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 0 3 0 0 0 0 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0 10] -> size -> 35 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [0. 8. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 0 3 0 0 0 0 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  8.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0 10] -> size -> 35 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0 10] -> size -> 35 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[319.8957 ]
 [319.00165]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8
  3 10  6 25  3  0  0 10 14  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: buy - action -1
Learning step: [-9.621381]
desired expected reward: 351.7654724121094



action possibilites: [-1] 
expected returns: [[329.21805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: trash_cards_n_from_hand - action 2
Learning step: [-4.474347]
desired expected reward: 314.44049072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[329.67258]
 [330.22693]
 [329.7412 ]
 [330.63528]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 25. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-20   0   3  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: take_action - action -1
Learning step: [-5.3959503]
desired expected reward: 323.82208251953125



buy possibilites: [-1] 
expected returns: [[330.3445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 42 

action type: buy - action 3.0
Learning step: [-3.59563]
desired expected reward: 326.63128662109375






Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 29.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 24. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 29.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 29.] 
adversary cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[341.6066 ]
 [341.29178]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  0. 29.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.  3.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [10.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: buy - action -1
Learning step: [-5.5632234]
desired expected reward: 324.7812805175781



action possibilites: [-1.] 
expected returns: [[320.90765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.  3.  8.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 24. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [10.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 34 

action type: discard_n_cards - action 1
Learning step: [-3.77417]
desired expected reward: 326.9489440917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[319.50238]
 [319.86008]
 [320.03925]
 [319.64694]
 [320.10443]
 [319.5676 ]
 [320.1269 ]
 [319.80368]
 [319.7467 ]
 [320.16144]
 [320.42615]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.  3.  8.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 28. 30. 24. 29.  8.  0.  9.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [10.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 34 

action type: take_action - action -1.0
Learning step: [-2.7899811]
desired expected reward: 318.11767578125



buy possibilites: [-1] 
expected returns: [[306.39893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14. 14.  0.  3.  0.  3.  8.  6.  0.  3. 10. 16. 11.  8. 10.  0. 10.  0.
  0. 25.  3.  8.  0.  0.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [10.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-20   0   4  30   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 66 

action type: buy - action 16.0
Learning step: [0.7555176]
desired expected reward: 320.4024658203125






Player: 1 
cards in hand: [ 8. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [10.  0.  3.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.  0.  3.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 23. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.  0.  3.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 23. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.  0.  3.  8.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  3.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[300.65598]
 [299.7974 ]
 [300.39124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  6. 15.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: buy - action -1
Learning step: [-6.5659]
desired expected reward: 299.8330383300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[300.2734]
 [301.1972]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3.  6. 15.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: [-6.0269456]
desired expected reward: 294.89385986328125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  0. 10.  0.] 
adversary cards in discard: [ 8.  3.  3.  6. 15.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  0. 10.  0.] 
adversary cards in discard: [ 8.  3.  3.  6. 15.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [10.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[318.19284]
 [317.5134 ]
 [317.5134 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 10.  0.] 
cards in discard: [ 8.  3.  3.  6. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  8.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: buy - action -1.0
Learning step: [-5.542218]
desired expected reward: 295.655029296875



action possibilites: [-1. 10.  8.] 
expected returns: [[320.10825]
 [319.4288 ]
 [319.2497 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  8.] 
cards in discard: [ 8.  3.  3.  6. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  8.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: take_action - action 10.0
Learning step: [-5.0978637]
desired expected reward: 312.6755676269531



action possibilites: [-1.  8.] 
expected returns: [[325.2883 ]
 [324.42975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [ 8.  3.  3.  6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
action values: 3 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  8.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: [-3.032138]
desired expected reward: 316.39666748046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[324.0276 ]
 [324.3853 ]
 [324.5644 ]
 [324.62967]
 [324.0928 ]
 [324.27188]
 [324.95135]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [ 8.  3.  3.  6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  8.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 34 

action type: take_action - action -1.0
Learning step: [-3.7075715]
desired expected reward: 321.5807189941406



buy possibilites: [-1] 
expected returns: [[323.22424]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  8.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0  40   0   0   0   0  -1   0   0  18   0] 
sum of rewards: 51 

action type: buy - action 10.0
Learning step: [-2.053949]
desired expected reward: 322.21795654296875






Player: 1 
cards in hand: [10.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [ 3.  0. 11.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10] -> size -> 36 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [ 3.  0. 11.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  2.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10] -> size -> 36 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [ 3.  0. 11.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10] -> size -> 36 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[298.13403]
 [297.27548]
 [297.83478]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  0.  0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: buy - action -1
Learning step: [-8.093738]
desired expected reward: 315.1304931640625



action possibilites: [-1.  8.] 
expected returns: [[325.65067]
 [324.79214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: discard_n_cards - action 3
Learning step: [-2.4521759]
desired expected reward: 295.294921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[324.72638]
 [325.08414]
 [325.26324]
 [325.32846]
 [324.79166]
 [324.97073]
 [325.65018]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: take_action - action -1.0
Learning step: [-5.2123933]
desired expected reward: 320.4382629394531



buy possibilites: [-1] 
expected returns: [[308.2367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20.   0.   4.  10.   0.   0.  20.   0.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: 12.0 

action type: buy - action 0.0
Learning step: [-6.162082]
desired expected reward: 318.5643310546875






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  6. 25.  0.  3.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0] -> size -> 37 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  6. 25.  0.  3.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0] -> size -> 37 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[336.2278 ]
 [335.88156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 25.  0.  3.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  8. 10.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: buy - action -1
Learning step: [-5.7187014]
desired expected reward: 302.51800537109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[335.47513]
 [336.37952]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 25.  0.  3.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  8. 10.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: [-8.512018]
desired expected reward: 327.7157897949219



buy possibilites: [-1] 
expected returns: [[329.89255]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 25.  0.  3.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  8. 10.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20.   0.   4.  10.   0.   0.   0.   0.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -9.0 

action type: buy - action 0.0
Learning step: [-9.360549]
desired expected reward: 326.1146240234375






Player: 1 
cards in hand: [ 8. 11.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8. 10.  0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 16.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0] -> size -> 38 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8. 10.  0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 16.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0] -> size -> 38 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8. 10.  0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 16.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0] -> size -> 38 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 14.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[331.9237 ]
 [331.31458]
 [331.16095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0. 16.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0.  8. 11.  8. 10.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: buy - action -1
Learning step: [-8.105629]
desired expected reward: 321.78692626953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[330.62283]
 [331.15247]
 [330.68628]
 [331.52722]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  0. 16.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 22. 29.  8.  0.  8.  7.  1.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0.  8. 11.  8. 10.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: [-8.29113]
desired expected reward: 323.632568359375



buy possibilites: [-1] 
expected returns: [[315.00192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  0. 16.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 22. 29.  8.  0.  8.  7.  0.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0.  8. 11.  8. 10.  0.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0  -4   0   0   8   0] 
sum of rewards: -2 

action type: buy - action 8.0
Learning step: [-8.075011]
desired expected reward: 322.6112976074219






Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  0.  8. 11.  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 22. 29.  8.  0.  8.  7.  0.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [10. 16.  0. 14.  0.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.  3.  0. 14.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0  8] -> size -> 39 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  0.  8. 11.  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 22. 29.  8.  0.  8.  7.  0.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [10. 16.  0. 14.  0.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.  3.  0. 14.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0  8] -> size -> 39 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  0.  8. 11.  8. 10.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [10. 16.  0. 14.  0.] 
adversary cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.  3.  0. 14.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0  8] -> size -> 39 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [10. 16.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 14.] 
expected returns: [[339.15213]
 [338.4878 ]
 [338.38934]
 [338.54297]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0. 14.  0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.  3.  0. 14.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-20   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: [-7.072934]
desired expected reward: 307.9289855957031



action possibilites: [-1. 16. 14.] 
expected returns: [[325.65305]
 [324.8903 ]
 [325.04388]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 14.  0.  0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.  3.  0. 14.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6 14  3  0  0  0  0 29  6  8  3 10
  6 25  3  0  0 10 14  0 10  3 16 10  0  0  8] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  9.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-20   0   4   0   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: [-7.989783]
desired expected reward: 330.4980163574219



action possibilites: [-1.] 
expected returns: [[337.83884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.  3.  0. 14.  0. 16. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-20   0   4   0   0   0  40   0   0   0   0  -4   0   0  25   0] 
sum of rewards: 45 

action type: gain_card_n - action 7
Learning step: [-1.1698426]
desired expected reward: 317.30078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[336.93445]
 [337.2875 ]
 [337.46405]
 [337.52756]
 [337.17447]
 [337.83887]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.  3.  0. 14.  0. 16. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-20   0   4   0   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 24 

action type: take_action - action -1.0
Learning step: [-5.206665]
desired expected reward: 332.6321716308594



buy possibilites: [-1] 
expected returns: [[331.75607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  3.  3.  6. 15. 10. 10. 10.  3.  0.  0.  8.  0. 11.  0. 29.  3.  8.
  0.  0.  0.  3.  6. 25.  0.  3.  8.  3.  0. 14.  0. 16. 25. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  5. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-20   0   4   0   0   0  40   0   0   0   0  -5   0   0  18   0] 
sum of rewards: 37 

action type: buy - action 10.0
Learning step: [-3.855307]
desired expected reward: 333.3191833496094






Player: 1 
cards in hand: [ 0.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  5. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  3. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10] -> size -> 40 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  3. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10] -> size -> 40 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  3. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10] -> size -> 40 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[293.6395 ]
 [293.3484 ]
 [293.03033]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 14.  6.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  8.  8.  3.] 
adversary cards in discard: [14. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-20   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: [-9.520541]
desired expected reward: 322.23553466796875



action possibilites: [-1] 
expected returns: [[301.28104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [10.  8.  3.] 
adversary cards in discard: [14. 11.  0.  3.  0.  3.  0.  8.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-20   0   4   0   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 14.0
Learning step: [-3.1809022]
desired expected reward: 289.7841796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[300.52682]
 [300.87982]
 [301.05643]
 [301.11987]
 [300.76685]
 [301.4312 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 21. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [10.  8.  3.] 
adversary cards in discard: [14. 11.  0.  3.  0.  3.  0.  8.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-20   0   4   0   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: [-3.9806702]
desired expected reward: 297.30035400390625



buy possibilites: [-1] 
expected returns: [[287.55136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  6.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [10.  8.  3.] 
adversary cards in discard: [14. 11.  0.  3.  0.  3.  0.  8.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20.   0.   5.  10.   0.   0.  20.   0.   0.   0.   0.  -6.   0.   0.
   2.   0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: [-2.507532]
desired expected reward: 289.0318908691406






Player: 1 
cards in hand: [10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.] 
cards in discard: [14. 11.  0.  3.  0.  3.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 15.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3] -> size -> 41 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.] 
cards in discard: [14. 11.  0.  3.  0.  3.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 15.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3] -> size -> 41 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[327.13123]
 [326.89008]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3. 15.  0.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6
 25  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [14. 11.  0.  3.  0.  3.  0.  8. 10.  8.  3.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: [-3.0239074]
desired expected reward: 284.5274658203125



action possibilites: [-1] 
expected returns: [[341.3984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [14. 11.  0.  3.  0.  3.  0.  8. 10.  8.  3.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: [-4.2613893]
desired expected reward: 322.6286926269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[340.6214 ]
 [340.96283]
 [341.13303]
 [341.193  ]
 [340.85156]
 [341.48602]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [14. 11.  0.  3.  0.  3.  0.  8. 10.  8.  3.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: [-5.69939]
desired expected reward: 335.6990051269531



buy possibilites: [-1] 
expected returns: [[344.28287]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [14. 11.  0.  3.  0.  3.  0.  8. 10.  8.  3.] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0  20   0   0   0   0  -6   0   0  18   0] 
sum of rewards: 27 

action type: buy - action 1.0
Learning step: [-4.858377]
desired expected reward: 336.1044006347656






Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [14. 11.  0.  3.  0.  3.  0.  8. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 10. 25.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1] -> size -> 41 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [14. 11.  0.  3.  0.  3.  0.  8. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  7.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 10. 25.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1] -> size -> 41 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [14. 11.  0.  3.  0.  3.  0.  8. 10.  8.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 10. 25.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1] -> size -> 41 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25.] 
expected returns: [[333.77972]
 [333.14523]
 [333.14523]
 [333.45227]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 25.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14 11] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: [-8.5185795]
desired expected reward: 335.7642822265625



action possibilites: [-1. 10. 25.] 
expected returns: [[318.5964 ]
 [317.9619 ]
 [318.26892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 25.  0.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14 11] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 16 

action type: take_action - action 10.0
Learning step: [-5.8484406]
desired expected reward: 327.29681396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[317.8172 ]
 [318.15863]
 [318.32883]
 [318.38876]
 [318.04742]
 [318.68192]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 25.  0.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14 11] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: [-4.457657]
desired expected reward: 314.13873291015625



buy possibilites: [-1] 
expected returns: [[325.06122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 25.  0.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14 11] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0  20   0   0   0   0  -7   0   0  18   0] 
sum of rewards: 26 

action type: buy - action 10.0
Learning step: [-3.5078187]
desired expected reward: 314.5395812988281






Player: 1 
cards in hand: [ 8. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  3  0  0  0  0  0 11 10  3  3  8  0  3 14 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.] 
adversary owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 42 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.] 
adversary owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 42 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.] 
adversary owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 42 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.] 
adversary owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 42 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[329.07486]
 [328.2702 ]
 [328.44037]
 [328.2702 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  8.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3 10  6 25
  3  0  0 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: [-7.044849]
desired expected reward: 318.016357421875



action possibilites: [-1] 
expected returns: [[317.59818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: [-5.245731]
desired expected reward: 323.460205078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[316.73376]
 [317.59842]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-20   0   5  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: [-4.096994]
desired expected reward: 313.5011901855469






Player: 1 
cards in hand: [ 8.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0.  0.] 
cards in discard: [0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.] 
adversary owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 19. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.] 
adversary owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 19. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.] 
adversary owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 18. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.] 
adversary owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[323.27988]
 [322.9524 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 25.  0.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 18. 29.  8.  0.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  8.  3.  0.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: [-8.114108]
desired expected reward: 309.4842834472656



action possibilites: [-1] 
expected returns: [[316.99017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 16.  3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  8.  3.  0.  0.  6.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6] -> size -> 19 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 25.0
Learning step: [-6.4427614]
desired expected reward: 316.5096435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[316.29492]
 [316.80652]
 [317.1596 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 16.  3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  8.  3.  0.  0.  6.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6] -> size -> 19 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: [-5.793152]
desired expected reward: 311.197021484375



buy possibilites: [-1] 
expected returns: [[301.7844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 16.  3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  8.  3.  0.  0.  6.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6] -> size -> 19 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20.   0.   5. -10.   0.   0.  20.   0.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -10.0 

action type: buy - action 0.0
Learning step: [-6.004907]
desired expected reward: 305.5080871582031






Player: 1 
cards in hand: [ 8. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  3.  0.] 
cards in discard: [ 0.  8.  3.  3. 11.  8.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  8. 11.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10  0] -> size -> 40 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  3.  0.] 
cards in discard: [ 0.  8.  3.  3. 11.  8.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  8. 11.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10  0] -> size -> 40 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  3.  0.] 
cards in discard: [ 0.  8.  3.  3. 11.  8.  3.  0.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  8. 11.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10  0] -> size -> 40 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 11.] 
expected returns: [[301.88773]
 [301.26837]
 [301.10086]
 [301.10086]
 [301.6045 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  8. 11.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  0  8 11  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0
 10 14  0 10  3 16 10  0  0  8 25 10  3  1 10  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-20   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: [-5.8038483]
desired expected reward: 295.98052978515625



action possibilites: [-1] 
expected returns: [[308.01843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-20   0   5   0   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 10
Learning step: [-3.8046722]
desired expected reward: 297.46368408203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[307.04935]
 [307.89438]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-20   0   5   0   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: [-4.4329376]
desired expected reward: 303.58551025390625



buy possibilites: [-1] 
expected returns: [[304.96677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-20   0   5   0   0   0  20   0   0   0   0  -3   0   0   0   0] 
sum of rewards: 2 

action type: buy - action 0.0
Learning step: [-4.7578464]
desired expected reward: 302.2915344238281






Player: 1 
cards in hand: [11.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.  0.  8.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.  0.  8.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.  0.  8.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[288.21152]
 [287.4994 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-20   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: [-7.5783067]
desired expected reward: 297.3884582519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. -1.] 
expected returns: [[287.36652]
 [287.70264]
 [287.87015]
 [287.92828]
 [288.21152]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [ 3. 14. 29.  0.  3.  6.  1. 15.  6.  6.  3. 10. 10.  0.  0. 10. 25.  0.
  8.  8.  0. 25.  3.  0.  3.  0. 16.  3.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-20   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: [-5.902782]
desired expected reward: 282.3087463378906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10. 11.  0.  3.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10. 11.  0.  3.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 18. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10. 11.  0.  3.  0. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 1. 10. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[298.2596 ]
 [297.64023]
 [297.64023]
 [297.64023]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  0.  0.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: [-6.430977]
desired expected reward: 281.7805480957031



action possibilites: [-1. 10. 10.] 
expected returns: [[292.5709]
 [291.9515]
 [291.9515]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  0.  0.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -4 

action type: take_action - action 10.0
Learning step: [-5.5060015]
desired expected reward: 292.13421630859375



action possibilites: [-1. 10.] 
expected returns: [[287.3252 ]
 [286.70584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  0.  0.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: 16 

action type: take_action - action 10.0
Learning step: [-3.3402526]
desired expected reward: 288.61126708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[287.8215 ]
 [288.15762]
 [288.3251 ]
 [287.87183]
 [287.95438]
 [288.3832 ]
 [288.34863]
 [288.39896]
 [288.09744]
 [288.5083 ]
 [288.1722 ]
 [288.43356]
 [288.6665 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  0.  0.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: [-2.9106781]
desired expected reward: 284.4145202636719



buy possibilites: [-1] 
expected returns: [[297.41602]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  6. 10.  0.  0.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20.   0.   5. -10.   0.   0.  40.   0.   0.   0.   0.  -4.   0.   0.
   8.   0.] 
sum of rewards: 19.0 

action type: buy - action 15.0
Learning step: [-2.0924287]
desired expected reward: 286.34112548828125






Player: 1 
cards in hand: [ 3.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  0.  0.] 
cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [14.  3.  3. 15.  8.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  0.  0.] 
cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [14.  3.  3. 15.  8.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  0.  0.] 
cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [14.  3.  3. 15.  8.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [14.  3.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.  8.] 
expected returns: [[312.71713]
 [312.1481 ]
 [312.48422]
 [311.93027]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3. 15.  8.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [8. 3. 8. 3. 3.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.  0.  3.  6. 10.  0.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0] -> size -> 23 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: [-7.078641]
desired expected reward: 290.3373718261719



action possibilites: [-1] 
expected returns: [[298.20648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  8.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [8. 8. 3.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.  0.  3.  6. 10.  0.  0.
  3.  3.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0] -> size -> 23 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 14.0
Learning step: [-6.9908233]
desired expected reward: 305.15728759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[297.65958]
 [298.16318]
 [298.50455]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  8.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [8. 8. 3.] 
adversary cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.  0.  3.  6. 10.  0.  0.
  3.  3.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0] -> size -> 23 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: [-5.5698]
desired expected reward: 292.6366882324219






Player: 1 
cards in hand: [8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3.] 
cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.  0.  3.  6. 10.  0.  0.
  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  0. 16.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.  0.  3.  6. 10.  0.  0.
  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  0. 16.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [10. 11.  0.  3.  0. 11.  3.  8.  3.  0.  0.  0.  0.  3.  6. 10.  0.  0.
  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  0. 16.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
expected returns: [[297.5018 ]
 [297.24655]
 [296.81686]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 16.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: [-6.117734]
desired expected reward: 282.89324951171875



action possibilites: [-1.] 
expected returns: [[287.96054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: discard_n_cards - action 3
Learning step: [-5.324918]
desired expected reward: 291.85284423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[287.18552]
 [287.67456]
 [287.9986 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 17. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-20   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: [-4.383928]
desired expected reward: 283.57659912109375



buy possibilites: [-1] 
expected returns: [[294.05234]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-20   0   6   0   0   0  20   0   0   0   0  -5   0   0   8   0] 
sum of rewards: 9 

action type: buy - action 3.0
Learning step: [-2.4505677]
desired expected reward: 285.2240295410156






Player: 1 
cards in hand: [ 0. 11.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  9.  4. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  6.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  6.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  6.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.] 
adversary owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 6 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [10.  0.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[273.39005]
 [272.79422]
 [272.632  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  6.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  0  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0
 10  3 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [29. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29] -> size -> 25 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-20   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: [-6.7590747]
desired expected reward: 287.29327392578125



action possibilites: [-1] 
expected returns: [[275.06403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [29. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29] -> size -> 25 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-20   0   6   0   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 3
Learning step: [-2.2694032]
desired expected reward: 270.7341003417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[274.1912]
 [275.0043]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [29. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29] -> size -> 25 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-20   0   6   0   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: [-2.4421432]
desired expected reward: 272.62188720703125






Player: 1 
cards in hand: [ 3.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [29. 11.  0.  0.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  8.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [29. 11.  0.  0.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 16. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  8.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [29. 11.  0.  0.  8.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  8.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 16.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[282.4054 ]
 [281.72043]
 [281.6473 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  3.  8.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29  3] -> size -> 26 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: [-5.158194]
desired expected reward: 269.8460998535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[281.79324]
 [282.60635]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  3.  8.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29  3] -> size -> 26 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: [-5.8675904]
desired expected reward: 276.53778076171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0
 29  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 6 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[288.61136]
 [288.30832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.  8.  3.  0.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3] -> size -> 24 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-20   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: [-5.0931125]
desired expected reward: 277.51324462890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. -1.] 
expected returns: [[287.62552]
 [287.95236]
 [288.1146 ]
 [288.16965]
 [288.4386 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.  8.  3.  0.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3] -> size -> 24 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-20   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: [-5.695906]
desired expected reward: 282.9154357910156



buy possibilites: [-1] 
expected returns: [[282.62692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.  8.  3.  0.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3] -> size -> 24 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-20   0   6   0   0   0   0   0   0   0   0  -4   0   0  18   0] 
sum of rewards: 0 

action type: buy - action 1.0
Learning step: [-4.6694474]
desired expected reward: 283.2829284667969






Player: 1 
cards in hand: [ 0.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  3.] 
cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.  8.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6. 25.  3.  0.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.  1.  0.  0. 25.  3.  0.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.  3.] 
cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.  8.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 26. 30. 15. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6. 25.  3.  0.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.  1.  0.  0. 25.  3.  0.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.  3.] 
cards in discard: [29. 11.  0.  0.  8.  6.  3.  3.  3.  0. 10.  0.  8.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 14. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6. 25.  3.  0.] 
adversary cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.  1.  0.  0. 25.  3.  0.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[274.1628]
 [273.8598]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25.  3.  0.] 
cards in discard: [15. 10. 10.  1.  0. 10.  0.  0. 14.  3.  3. 15.  8.  3. 16.  3. 29.  3.
  0.  3.  8.  0.  6.  6.  0. 16.  3.  8.  1.  0.  0. 25.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 14. 29.  8. -1.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: [-6.2952]
desired expected reward: 276.33172607421875



action possibilites: [-1] 
expected returns: [[277.11664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 14. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  3.  0.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 25.0
Learning step: [-3.0527954]
desired expected reward: 270.8070068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[277.31674]
 [277.79526]
 [278.10538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 26. 30. 14. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  3.  0.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: [-3.300087]
desired expected reward: 273.8165588378906






Player: 1 
cards in hand: [11.  3.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.  8.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 14. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 16. 16.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.  8.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 14. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 16. 16.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
adversary victory points: 6
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 16.] 
expected returns: [[281.80188]
 [281.55627]
 [281.13776]
 [281.13776]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 16. 16.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3
 16 10  0  0  8 25 10  3  1 10  0  0 15  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 14. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 11.  3.  3.  0.  8.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-20   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: [-3.9161286]
desired expected reward: 274.1892395019531



action possibilites: [-1] 
expected returns: [[277.55054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 16.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 13. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 11.  3.  3.  0.  8.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-20   0   7  10   0   0  20   0   0   0   0  -4   0   0   4   0] 
sum of rewards: 17 

action type: gain_card_n - action 1
Learning step: [-1.3360687]
desired expected reward: 281.067626953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[276.6607 ]
 [277.44934]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 16.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 13. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 11.  3.  3.  0.  8.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-20   0   7  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: [-0.79658204]
desired expected reward: 276.75396728515625



buy possibilites: [-1] 
expected returns: [[269.03674]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 16.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 13. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 11.  3.  3.  0.  8.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-20.   0.   7.  10.   0.   0.  20.   0.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: 12.0 

action type: buy - action 0.0
Learning step: [-1.0473756]
desired expected reward: 275.61334228515625






Player: 1 
cards in hand: [6. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 8.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  3  8  0  3 11  0  3  3  6  0 10  3  0  0 29  3
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 13. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 13. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 13. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 12. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 7 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[289.51025]
 [288.7745 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 12. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3] -> size -> 25 
adversary victory points: 7
player victory points: 7 

Reward from previous game state: 
[-20   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: [-3.465683]
desired expected reward: 265.571044921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. -1.] 
expected returns: [[288.93332]
 [289.2533 ]
 [289.4118 ]
 [289.4647 ]
 [289.722  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 12. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3] -> size -> 25 
adversary victory points: 7
player victory points: 7 

Reward from previous game state: 
[-20   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: [-5.456537]
desired expected reward: 284.0537109375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 12. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 15.  3.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 12. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 15.  3.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 11. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 15.  3.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 8 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[280.4982 ]
 [279.92096]
 [280.28662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 15.  3.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 11. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 10. 29.] 
adversary cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.  3.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3  3] -> size -> 26 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[-20   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: [-6.973352]
desired expected reward: 282.74859619140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[279.46115]
 [280.24976]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 15.  3.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 11. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 10. 29.] 
adversary cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.  3.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3  3] -> size -> 26 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[-20   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: [-6.0416656]
desired expected reward: 274.45654296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10. 29.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.  3.  0.  3.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 11. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.  3.  0.  3.  0. 11.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8  0  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 11. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.  3.  0.  3.  0. 11.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 11. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6. 11.  3.  3.  0.  8.  3.  8.  0.  0.  3.  0.  3.  0. 11.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 11. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
adversary victory points: 7
player victory points: 8 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[275.0908]
 [274.7995]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  3.  0.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 11. 29.  8. -2.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3] -> size -> 25 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[-20   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: [-6.1563582]
desired expected reward: 274.0933837890625



action possibilites: [-1] 
expected returns: [[281.01514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 1. 6.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 11. 29.  8. -3.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  3.  3. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6] -> size -> 26 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[-20   0   7 -10   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -1 

action type: take_action - action 25.0
Learning step: [-3.1577744]
desired expected reward: 271.6417236328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 15. -1.] 
expected returns: [[279.71924]
 [280.03918]
 [280.19778]
 [279.84375]
 [280.25064]
 [280.26227]
 [279.97632]
 [280.2963 ]
 [280.50787]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1. 6.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 26. 30. 11. 29.  8. -3.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  3.  3. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6] -> size -> 26 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[-20   0   7 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: [-3.919429]
desired expected reward: 277.095703125



buy possibilites: [-1] 
expected returns: [[282.01343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1. 6.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  3.  3. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6] -> size -> 26 
adversary victory points: 8
player victory points: 8 

Reward from previous game state: 
[-20.   0.   8.   0.   0.   0.  20.   0.   0.   0.   0.  -6.   0.   0.
   2.   0.] 
sum of rewards: 4.0 

action type: buy - action 3.0
Learning step: [-2.7952805]
desired expected reward: 277.4024353027344






Player: 1 
cards in hand: [11.  3.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3. 10.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [3. 3. 1. 3. 8.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 41 
adversary victory points: 8
player victory points: 7 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3.  0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  6.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [3. 3. 1. 3. 8.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 41 
adversary victory points: 8
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [3. 3. 1. 3. 8.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 41 
adversary victory points: 8
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [3. 3. 1. 3. 8.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.] 
adversary owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 41 
adversary victory points: 8
player victory points: 7 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [3. 3. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[257.61414]
 [256.87836]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 3. 8.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16
 10  0  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 8 

Reward from previous game state: 
[-20   0   8  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: [-4.743816]
desired expected reward: 277.2696228027344



action possibilites: [-1] 
expected returns: [[266.82568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0
  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 3
Learning step: [-1.4524872]
desired expected reward: 251.93295288085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[266.05466]
 [266.52628]
 [266.8257 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0
  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: [-2.796512]
desired expected reward: 264.0291748046875






Player: 1 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [14.  0. 10. 15.  8.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.  8.  1.  3.] 
adversary owned cards: [15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0
  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 39 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [14.  0. 10. 15.  8.] 
adversary cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.  8.  1.  3.] 
adversary owned cards: [15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0
  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 39 
adversary victory points: 6
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [14.  0. 10. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 15.  8.] 
expected returns: [[260.97104]
 [260.45154]
 [260.40747]
 [260.76712]
 [260.2514 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10. 15.  8.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.  8.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 16  6  3  0  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0
  0  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [10.  6. 29.  3.  3.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: [-4.781044]
desired expected reward: 262.0446472167969



action possibilites: [-1] 
expected returns: [[269.8296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  8.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.  8.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [10.  6. 29.  3.  3.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 15.0
Learning step: [-2.0719483]
desired expected reward: 258.6951599121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. -1.] 
expected returns: [[269.05856]
 [269.3741 ]
 [269.5302 ]
 [269.58157]
 [269.8296 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  8.] 
cards in discard: [25.  0.  6.  3.  0.  6. 10.  3.  0. 16.  0. 29. 16.  0.  0.  0.  8.  3.
  0. 10.  3. 15.  3.  3. 25.  0.  3.  3.  0.  1.  6.  8.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [10.  6. 29.  3.  3.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: [-2.9781952]
desired expected reward: 266.85137939453125






Player: 1 
cards in hand: [10.  6. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 29.  3.  3.] 
cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0. 29.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 38 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 29.  3.  3.] 
cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0. 29.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 38 
adversary victory points: 6
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [16.  0. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 10.] 
expected returns: [[244.23445]
 [243.58519]
 [243.99622]
 [243.6709 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29.  3. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0. 10.  6. 29.  3.  3.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: [-5.671338]
desired expected reward: 264.15826416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[244.02112]
 [244.79216]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  3. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0. 10.  6. 29.  3.  3.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: [-3.0889375]
desired expected reward: 241.14549255371094



buy possibilites: [-1] 
expected returns: [[247.35165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  3. 10.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0. 10.  6. 29.  3.  3.] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6. -10.   0.   0.   0.   0.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: -28.0 

action type: buy - action 0.0
Learning step: [-3.6218414]
desired expected reward: 240.39927673339844






Player: 1 
cards in hand: [11.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  8.] 
cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0. 10.  6. 29.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  3.] 
adversary cards in discard: [ 0. 16.  0. 29.  3. 10.] 
adversary owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3  0] -> size -> 39 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  8.] 
cards in discard: [ 6. 11. 10. 11.  3.  3.  3.  0.  0.  3.  8.  3.  0. 10.  6. 29.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  3.] 
adversary cards in discard: [ 0. 16.  0. 29.  3. 10.] 
adversary owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3  0] -> size -> 39 
adversary victory points: 6
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [10.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[258.3081 ]
 [257.74454]
 [257.58847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  3.] 
cards in discard: [ 0. 16.  0. 29.  3. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: [-3.2581406]
desired expected reward: 244.093505859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[257.1702]
 [257.6418]
 [257.9412]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  0.  3.] 
cards in discard: [ 0. 16.  0. 29.  3. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[-20   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: [-4.332254]
desired expected reward: 253.9758758544922



Player 1 won the game! 



Player 0 bought cards:
Copper: 15 
Silver: 4 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 3 

Remodel: 2 
Workshop: 1 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 3 
Market: 0 
Village: 6 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  0.  8.  0.  3.] 
cards in discard: [ 0. 16.  0. 29.  3. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 16  6  3  0  0 29  6  8  3  6 25  3  0  0 14  0  3 16 10  0  0
  8 25 10  3  1 10  0  0 15  3  1  3  0  3  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 10. 29.  8. -3.  8.  5.  0.  8.  8.  4. 10.  0. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0 11 10  3  8  0  3 11  0  3  3  0 10  3  0  0 29  3  3  6  3
  3  6 11] -> size -> 27 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[  -20 -1000     6   -10     0     0     0     0     0     0     0    -5
     0     0     0     0] 
sum of rewards: -1029 

action type: buy - action 0.0
Learning step: [-128.61702]
desired expected reward: 128.5531768798828



