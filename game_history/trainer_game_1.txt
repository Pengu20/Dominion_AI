 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[340.7222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -3  -90    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -598 

action type: buy - action -1.0
Learning step: -46.1785888671875
desired expected reward: 279.3932189941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[339.7489 ]
 [340.3011 ]
 [340.27576]
 [340.04196]
 [342.20706]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.550251960754395
desired expected reward: 333.00030517578125



buy possibilites: [-1] 
expected returns: [[343.98724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -24.924076080322266
desired expected reward: 315.3516845703125






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[343.83167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 0. 0. 3. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -10.050774574279785
desired expected reward: 333.93646240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[346.10028]
 [346.36856]
 [346.6525 ]
 [346.3432 ]
 [346.6272 ]
 [346.36456]
 [346.97324]
 [346.39337]
 [346.98145]
 [347.25217]
 [346.948  ]
 [347.21527]
 [346.67728]
 [346.9192 ]
 [347.24402]
 [348.5584 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 0. 0. 3. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.160213470458984
desired expected reward: 336.4436950683594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[339.17935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  8.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -10.391036033630371
desired expected reward: 338.1673889160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[338.82132]
 [339.0896 ]
 [339.37347]
 [339.3482 ]
 [339.69434]
 [339.1144 ]
 [339.39832]
 [341.27945]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  8.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.076519966125488
desired expected reward: 331.5628356933594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  8.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [ 8.  0.  3.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[357.74902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.602242469787598
desired expected reward: 331.67718505859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[358.2062 ]
 [358.4745 ]
 [358.75833]
 [358.73306]
 [358.4705 ]
 [359.0792 ]
 [358.49927]
 [359.35806]
 [359.05386]
 [358.78317]
 [359.34988]
 [360.66434]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.583758354187012
desired expected reward: 349.9375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[344.50803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -10.872893333435059
desired expected reward: 349.7914123535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[343.89038]
 [344.1587 ]
 [344.44257]
 [344.41727]
 [344.76343]
 [344.18344]
 [344.4674 ]
 [346.34848]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.236769676208496
desired expected reward: 336.888671875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 0.] 
cards in discard: [0. 0. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 15  8 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [0. 0. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 15  8 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [0. 0. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 15  8 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [0. 0. 3. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 15  8 10  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[359.77478]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 15  8 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.810117721557617
desired expected reward: 336.53839111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[359.74417]
 [360.01245]
 [360.29636]
 [360.27106]
 [360.61716]
 [360.03723]
 [360.32117]
 [362.20227]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 15  8 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.651141166687012
desired expected reward: 351.8958740234375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 15  8 10  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  8 15  8 10  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  8 15  8 10  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  8 15  8 10  0  0 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.07684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 0.] 
adversary cards in discard: [14. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  8 15  8 10  0  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -10.89553451538086
desired expected reward: 351.3067321777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[346.7188 ]
 [346.98715]
 [347.27103]
 [347.2457 ]
 [347.59186]
 [347.01187]
 [347.2958 ]
 [349.17697]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 0.] 
adversary cards in discard: [14. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  8 15  8 10  0  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.293701171875
desired expected reward: 339.2431640625



buy possibilites: [-1] 
expected returns: [[367.2571]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 0.] 
adversary cards in discard: [14. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  8 15  8 10  0  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 11.0
Learning step: -8.866308212280273
desired expected reward: 338.7255554199219






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 0.] 
cards in discard: [14. 15.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8 15  8 10  0  0 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [14. 15.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [14. 15.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.8235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -11.122942924499512
desired expected reward: 356.1341552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[329.8194 ]
 [330.06747]
 [330.33328]
 [330.3087 ]
 [330.06375]
 [330.63458]
 [330.0905 ]
 [330.8969 ]
 [330.60995]
 [330.35635]
 [330.8882 ]
 [332.1251 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.797987937927246
desired expected reward: 322.19244384765625



buy possibilites: [-1] 
expected returns: [[335.93582]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 3.0
Learning step: -8.958108901977539
desired expected reward: 321.37518310546875






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[326.4899]
 [324.9994]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3.  6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  0. 14.] 
adversary cards in discard: [10.  3.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.507970809936523
desired expected reward: 326.4278564453125



action possibilites: [-1] 
expected returns: [[360.7761]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 6.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  0. 14.] 
adversary cards in discard: [10.  3.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 27 

action type: gain_card_n - action 9
Learning step: -6.881660461425781
desired expected reward: 320.1007995605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[356.28827]
 [356.77756]
 [358.594  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  0. 14.] 
adversary cards in discard: [10.  3.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -9.088614463806152
desired expected reward: 351.6874694824219






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  0. 14.] 
cards in discard: [10.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  0.] 
cards in discard: [10.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  3.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.  0.] 
cards in discard: [10.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  3.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.  0.] 
cards in discard: [10.  3.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  3.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[363.02966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [10. 11.  3.  3.  3.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  8 10  0  0 14  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    3    0    0    0    0 -120    0    0    0    0    0 -300
   13    0] 
sum of rewards: -409 

action type: discard_down_to_3_cards - action 2
Learning step: -29.99421501159668
desired expected reward: 325.3030700683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[362.19928]
 [362.71317]
 [362.68854]
 [362.47043]
 [364.50497]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [10. 11.  3.  3.  3.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  8 10  0  0 14  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.187777519226074
desired expected reward: 355.1744689941406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 14.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  8 10  0  0 14  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  8 10  0  0  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  8 10  0  0  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  8 10  0  0  8  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[329.11884]
 [327.35016]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  3. 15.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 3  3  3 15  8 10  0  0  8  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.87833309173584
desired expected reward: 353.6266174316406



action possibilites: [-1.] 
expected returns: [[342.8722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  3. 15.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 3  3  3 15  8 10  0  0  8  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: -7.871634006500244
desired expected reward: 321.853515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[337.8769 ]
 [338.12497]
 [338.39075]
 [338.36618]
 [338.69205]
 [338.14804]
 [338.41382]
 [340.18253]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  3. 15.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 3  3  3 15  8 10  0  0  8  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -8.611433982849121
desired expected reward: 334.2607727050781



buy possibilites: [-1] 
expected returns: [[347.44452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  3. 15.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 3  3  3 15  8 10  0  0  8  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 11.0
Learning step: -7.317101955413818
desired expected reward: 331.3749694824219






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3. 15.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  8 10  0  0  8  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  6.  3.  0.] 
adversary cards in discard: [11. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3. 15.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  8 10  0  0  8  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  6.  3.  0.] 
adversary cards in discard: [11. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3. 15.] 
cards in discard: [0. 8. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  8 10  0  0  8  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  6.  3.  0.] 
adversary cards in discard: [11. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[358.656  ]
 [357.16547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  3.  0.] 
cards in discard: [11. 10.  3.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  8 10  0  0  8  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.359091758728027
desired expected reward: 338.0854187011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[357.65118]
 [358.16507]
 [358.14047]
 [357.92233]
 [359.95688]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  3.  0.] 
cards in discard: [11. 10.  3.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  8 10  0  0  8  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.073090553283691
desired expected reward: 350.9487609863281



buy possibilites: [-1] 
expected returns: [[337.1872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  3.  0.] 
cards in discard: [11. 10.  3.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  8 10  0  0  8  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -11.468916893005371
desired expected reward: 346.1822814941406






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  8 10  0  0  8  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  8 10  0  8  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15  8 10  0  8  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[320.049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10. 15.  0.  3.  0.] 
adversary cards in discard: [8. 8. 0. 3.] 
adversary owned cards: [ 3  3  3 15  8 10  0  8  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.701652526855469
desired expected reward: 327.48553466796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[319.5858 ]
 [319.81793]
 [320.06866]
 [320.04514]
 [320.35437]
 [319.83963]
 [320.09033]
 [321.77206]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10. 15.  0.  3.  0.] 
adversary cards in discard: [8. 8. 0. 3.] 
adversary owned cards: [ 3  3  3 15  8 10  0  8  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.009203910827637
desired expected reward: 313.5555725097656



buy possibilites: [-1] 
expected returns: [[323.88623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10. 15.  0.  3.  0.] 
adversary cards in discard: [8. 8. 0. 3.] 
adversary owned cards: [ 3  3  3 15  8 10  0  8  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -7.930277347564697
desired expected reward: 312.424072265625






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [10. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  3.  0.] 
cards in discard: [8. 8. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  8 10  0  8  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  0.  3.] 
cards in discard: [8. 8. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 15  8 10  0  8  0  0] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [8. 8. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3  3 15  8 10  8  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [8. 8. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3  3 15  8 10  8  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [8. 8. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3  3 15  8 10  8  0  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  7.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[335.40466]
 [333.98694]
 [333.72293]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  3.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  7.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  8 10  8  0  0  3] -> size -> 10 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.210038185119629
desired expected reward: 314.6761779785156



action possibilites: [-1] 
expected returns: [[334.2862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [11.  3.  0.  0.  3.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  7.  7. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  8 10  8  0  0  3] -> size -> 10 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 24 

action type: gain_card_n - action 8
Learning step: -8.064583778381348
desired expected reward: 327.6558837890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[331.7819 ]
 [332.26474]
 [332.24127]
 [332.03577]
 [333.96823]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [11.  3.  0.  0.  3.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  9. 10.  7.  7. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  8 10  8  0  0  3] -> size -> 10 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -8.819995880126953
desired expected reward: 325.4661865234375



buy possibilites: [-1] 
expected returns: [[340.63977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [11.  3.  0.  0.  3.  0. 14.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  8 10  8  0  0  3] -> size -> 10 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -303.0 

action type: buy - action 6.0
Learning step: -24.09766960144043
desired expected reward: 308.1435852050781






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  8 10  8  0  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 14.  6. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  8 10  8  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 14.  6. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  8 10  8  0  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 14.  6. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[338.70197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 14.  6. 11.  0.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 15.  3.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 3 15  8 10  8  0  3] -> size -> 7 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -9.54085636138916
desired expected reward: 331.0989074707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[338.3987 ]
 [338.6309 ]
 [338.88162]
 [338.8581 ]
 [339.1673 ]
 [338.6526 ]
 [338.9033 ]
 [340.58502]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 14.  6. 11.  0.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 15.  3.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 3 15  8 10  8  0  3] -> size -> 7 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -9.487969398498535
desired expected reward: 330.117919921875



buy possibilites: [-1] 
expected returns: [[349.75946]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 14.  6. 11.  0.  0. 10.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  3. 15.  3.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 3 15  8 10  8  0  3] -> size -> 7 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 15 

action type: buy - action 10.0
Learning step: -8.325575828552246
desired expected reward: 330.57769775390625






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [10.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 15.  3.] 
cards in discard: [8. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8 10  8  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [8. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  8 10  8  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [8. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  8 10  8  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [8. 8. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  8 10  8  3  1] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 3. 11.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[333.19745]
 [331.77972]
 [331.77972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  8 10  8  3  1] -> size -> 7 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -10.097509384155273
desired expected reward: 339.6619567871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[331.98477]
 [332.4441 ]
 [334.17108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  8 10  8  3  1] -> size -> 7 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -9.43277359008789
desired expected reward: 326.2546081542969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8 10  8  3  1] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 11.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 15.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  3.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  8 10  8  3  1] -> size -> 7 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 11.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3 15  8 10  8  3  1] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 11.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 3 15 10  8  3  1] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 11.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 3 15 10  8  3  1] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 11.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 3 15 10  8  3  1  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 11.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[324.9856 ]
 [323.56787]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 3. 11.  3.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  1  0] -> size -> 7 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -9.503521919250488
desired expected reward: 324.6675720214844



action possibilites: [-1] 
expected returns: [[314.0358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3. 11.  3.  3. 11. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  1  0] -> size -> 7 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 33 

action type: gain_card_n - action 7
Learning step: -7.1625237464904785
desired expected reward: 318.6364440917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[313.07666]
 [313.2943 ]
 [313.53082]
 [313.50763]
 [313.2921 ]
 [313.80222]
 [313.31467]
 [314.0425 ]
 [313.77905]
 [313.55115]
 [314.0301 ]
 [315.1521 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3. 11.  3.  3. 11. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  1  0] -> size -> 7 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -7.780105113983154
desired expected reward: 306.2557067871094






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 15.  1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  1  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 11.  3.  3. 11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 15.  1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  1  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 28. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 11.  3.  3. 11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 15.  1.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  1  0  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 11.  3.  3. 11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [10.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[310.45264]
 [308.85168]
 [309.0796 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.  0.  0.] 
cards in discard: [ 3. 11.  3.  3. 11. 29. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  1  0  3] -> size -> 8 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.416183471679688
desired expected reward: 305.73590087890625



action possibilites: [-1. 14.] 
expected returns: [[324.66925]
 [323.2962 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 3. 11.  3.  3. 11. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  1  0  3] -> size -> 8 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 8 

action type: take_action - action 10.0
Learning step: -7.789605140686035
desired expected reward: 301.9220275878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[323.50397]
 [323.7216 ]
 [323.95807]
 [323.9349 ]
 [323.71942]
 [324.2295 ]
 [323.7419 ]
 [324.46985]
 [324.20636]
 [323.97842]
 [324.45743]
 [325.57938]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 3. 11.  3.  3. 11. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  1  0  3] -> size -> 8 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -8.577162742614746
desired expected reward: 316.09210205078125






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [15.  0.  1.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  8. 10.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  1  0  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  8.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 10  8  3  1  0  3] -> size -> 8 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3 15 10  8  3  1  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 3 15 10  8  3  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 3 15 10  8  3  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 3 15 10  8  3  3 11] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[320.10913]
 [318.50815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  3.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  3 11] -> size -> 7 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.680508613586426
desired expected reward: 315.89886474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[318.85797]
 [319.2889 ]
 [320.93335]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  3.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  3 11] -> size -> 7 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.576618194580078
desired expected reward: 313.0477294921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  3 11] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  3 11] -> size -> 7 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 11.  3.  3.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 14. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[320.6247 ]
 [319.25165]
 [319.0237 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  3.  0.] 
cards in discard: [ 0. 10.  6.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.450505256652832
desired expected reward: 311.48284912109375



action possibilites: [-1. 14.] 
expected returns: [[329.8991 ]
 [328.52606]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [ 0. 10.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 8 

action type: take_action - action 10.0
Learning step: -8.238024711608887
desired expected reward: 312.7954406738281



action possibilites: [-1.] 
expected returns: [[337.0394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 0. 10.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 15.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action 14.0
Learning step: -7.492917060852051
desired expected reward: 321.03314208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[335.18576]
 [335.40344]
 [335.63992]
 [335.38025]
 [335.61673]
 [335.40125]
 [335.91135]
 [335.42374]
 [335.92374]
 [336.1516 ]
 [335.88818]
 [336.11673]
 [335.66022]
 [335.86563]
 [336.13922]
 [337.26126]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 0. 10.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 27. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 15.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: -7.932779788970947
desired expected reward: 329.10662841796875



buy possibilites: [-1] 
expected returns: [[333.8073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 0. 10.  6.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 15.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -284.0 

action type: buy - action 6.0
Learning step: -23.47017478942871
desired expected reward: 312.1465759277344






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 15.] 
cards in discard: [3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 0. 10.  6.  3.  6.  6. 10. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 15.] 
cards in discard: [3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 0. 10.  6.  3.  6.  6. 10. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[345.27808]
 [344.1685 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [ 0. 10.  6.  3.  6.  6. 10. 14.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  8.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -10.119414329528809
desired expected reward: 323.6878967285156



action possibilites: [-1.] 
expected returns: [[355.47473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 10.  6.  3.  6.  6. 10. 14.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  8.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 29.0
Learning step: -9.431427001953125
desired expected reward: 335.1607360839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[353.6493 ]
 [353.86697]
 [354.1034 ]
 [354.08026]
 [353.86472]
 [354.37488]
 [353.88727]
 [354.6151 ]
 [354.35168]
 [354.12378]
 [354.60275]
 [355.7247 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 10.  6.  3.  6.  6. 10. 14.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  8.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -9.989167213439941
desired expected reward: 345.4855651855469






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [15.  8.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 10  8  3  3 11  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  3  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  3  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  3  3  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 3. 11.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[313.3717 ]
 [312.02185]
 [312.02185]
 [312.02185]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -11.395398139953613
desired expected reward: 344.329345703125



action possibilites: [-1] 
expected returns: [[306.33328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 10 

action type: gain_card_n - action 6
Learning step: -7.437201023101807
desired expected reward: 289.15679931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[303.05716]
 [303.46088]
 [305.0256 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -8.16916561126709
desired expected reward: 298.16412353515625



buy possibilites: [-1] 
expected returns: [[301.91882]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.] 
cards in discard: [8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -9.559686660766602
desired expected reward: 293.49749755859375






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  0.] 
adversary cards in discard: [ 8.  0. 11.  3.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  3  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  0.] 
adversary cards in discard: [ 8.  0. 11.  3.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[292.6857 ]
 [291.37875]
 [291.1636 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 10.  0.] 
cards in discard: [ 8.  0. 11.  3.  0. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -9.191651344299316
desired expected reward: 292.7271728515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[293.1554 ]
 [293.3599 ]
 [293.58295]
 [293.55908]
 [293.84073]
 [293.37866]
 [293.6017 ]
 [295.12384]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14. 10.  0.] 
cards in discard: [ 8.  0. 11.  3.  0. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.782463073730469
desired expected reward: 285.2959289550781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  3  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[312.11337]
 [310.59128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -8.430854797363281
desired expected reward: 286.6929626464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[312.44974]
 [312.8773 ]
 [312.85342]
 [312.67303]
 [314.4182 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -9.277859687805176
desired expected reward: 303.4067077636719



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  3  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 10.  3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  3  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.35434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.  0.  3.  0.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0  0] -> size -> 6 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -9.858712196350098
desired expected reward: 304.5594787597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[291.05704]
 [291.46072]
 [293.02548]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [ 8.  0. 11.  3.  0. 11. 11.  0.  0. 14. 10.  0.  0.  3.  0.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  3  0  0] -> size -> 6 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.70516586303711
desired expected reward: 282.94805908203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  3  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  3  3  0  0] -> size -> 6 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  3  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  3  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  3  0  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[298.74985]
 [297.69562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0] -> size -> 5 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -8.083703994750977
desired expected reward: 284.9417724609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[297.9341 ]
 [298.3616 ]
 [298.33777]
 [298.1574 ]
 [299.90256]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0] -> size -> 5 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -8.524772644042969
desired expected reward: 292.5660095214844



buy possibilites: [-1] 
expected returns: [[297.88556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0] -> size -> 5 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -9.894281387329102
desired expected reward: 288.0398254394531






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0. 14.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  3  0  0] -> size -> 5 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0. 14.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  3  0  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0. 14.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[277.55786]
 [276.03574]
 [276.25092]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 14.] 
cards in discard: [ 0.  3.  0.  3.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0] -> size -> 5 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -8.830365180969238
desired expected reward: 289.0552062988281



action possibilites: [-1. 14.  8.] 
expected returns: [[284.41794]
 [283.111  ]
 [282.67282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  8.] 
cards in discard: [ 0.  3.  0.  3.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0] -> size -> 5 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 10.0
Learning step: -6.6854729652404785
desired expected reward: 270.742919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[282.34225]
 [282.54684]
 [282.7698 ]
 [282.74597]
 [283.02765]
 [282.5656 ]
 [282.7886 ]
 [284.31073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  8.] 
cards in discard: [ 0.  3.  0.  3.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0] -> size -> 5 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -7.042735576629639
desired expected reward: 277.3752136230469






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [10.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  6. 11.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  6. 11.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  6. 11.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [11.  6.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[297.9728]
 [296.6897]
 [296.6897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  6. 11.] 
cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3] -> size -> 6 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -8.21402645111084
desired expected reward: 276.0967102050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[283.66797]
 [284.05087]
 [285.55292]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  6. 11.] 
cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3] -> size -> 6 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.511401176452637
desired expected reward: 275.916748046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8. 11.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  3  0  0  3] -> size -> 6 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8. 11.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  3  0  0  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  6. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8. 11.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  3  0  0  3  8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8. 11.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 6. 11.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[274.65625]
 [273.4263 ]
 [273.19666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0. 10.] 
cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8. 11.  6.  0.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8] -> size -> 7 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -8.833816528320312
desired expected reward: 276.7191162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[273.6463 ]
 [274.02917]
 [275.53128]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0. 10.] 
cards in discard: [ 0.  3.  0.  3.  0. 29. 10.  0.  0.  0. 14.  8. 11.  6.  0.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8] -> size -> 7 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.194787979125977
desired expected reward: 265.391357421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 26. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[281.63318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3] -> size -> 8 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -8.59455394744873
desired expected reward: 266.9367370605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[281.32434]
 [281.51892]
 [281.73166]
 [281.7072 ]
 [281.9793 ]
 [281.537  ]
 [281.74966]
 [283.20926]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3] -> size -> 8 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.028085708618164
desired expected reward: 274.6168212890625



buy possibilites: [-1] 
expected returns: [[285.31763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3] -> size -> 8 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 1.0
Learning step: -7.956299781799316
desired expected reward: 273.5626220703125






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [10.  3.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  6.  3. 11.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8  3] -> size -> 8 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  6.  3. 11.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  3.  8.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8  3  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  6.  3. 11.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [11.  6.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[283.3414 ]
 [282.11145]
 [282.11145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.  3. 11.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3  0] -> size -> 9 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -9.089118957519531
desired expected reward: 276.228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[282.38275]
 [282.76562]
 [284.2677 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  6.  3. 11.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3  0] -> size -> 9 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.013594627380371
desired expected reward: 274.8800964355469



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8  3  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10. 11.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8  3  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10. 11.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8  3  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10. 11.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 14. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11.] 
expected returns: [[276.57648]
 [275.3221 ]
 [275.1169 ]
 [275.34656]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 10. 11.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -9.218657493591309
desired expected reward: 275.0490417480469



action possibilites: [-1. 14. 11.] 
expected returns: [[275.4291 ]
 [274.1747 ]
 [274.19916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 11.  0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -7.685863018035889
desired expected reward: 266.75543212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[274.0916 ]
 [274.28622]
 [274.4989 ]
 [274.4745 ]
 [274.74664]
 [274.3043 ]
 [274.51697]
 [275.97656]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14. 11.  0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -7.780032634735107
desired expected reward: 267.6490783691406



buy possibilites: [-1] 
expected returns: [[296.3921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14. 11.  0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  0  3  8  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -2.0 

action type: buy - action 8.0
Learning step: -7.14639139175415
desired expected reward: 267.1578674316406






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  0  3  8  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0.  6.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.  8. 10.  0.  0. 14. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  3  8  3  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0.  6.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.  8. 10.  0.  0. 14. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8] -> size -> 27 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  3  8  3  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0.  6.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.  8. 10.  0.  0. 14. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8] -> size -> 27 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [29. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[299.56125]
 [298.55084]
 [298.10162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0.  6.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.  8. 10.  0.  0. 14. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3. 10.] 
adversary owned cards: [10  0  0  3  8  3  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -8.807868957519531
desired expected reward: 287.584228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[297.7917 ]
 [298.199  ]
 [298.17453]
 [298.00433]
 [299.67664]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  0.  6.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.  8. 10.  0.  0. 14. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 25. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3. 10.] 
adversary owned cards: [10  0  0  3  8  3  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.913738250732422
desired expected reward: 289.8696594238281



buy possibilites: [-1] 
expected returns: [[293.7357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  0.  6.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 11.  6.  6.  3. 11.  8. 10.  0.  0. 14. 11.  0.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3. 10.] 
adversary owned cards: [10  0  0  3  8  3  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 5 

action type: buy - action 3.0
Learning step: -8.050898551940918
desired expected reward: 290.14813232421875






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3] -> size -> 28 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 28. 30. 24. 30.  8.  7. 10.  6.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3] -> size -> 28 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3. 10. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 30.  8.  7. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3] -> size -> 28 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [6. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[283.6684]
 [281.9961]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 30.  8.  7. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  8  3  0  0 14] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -8.440464973449707
desired expected reward: 285.29522705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[272.51965]
 [272.91214]
 [272.88788]
 [272.7243 ]
 [274.34473]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 24. 30.  8.  7. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  8  3  0  0 14] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -7.76478910446167
desired expected reward: 267.65093994140625



buy possibilites: [-1] 
expected returns: [[283.33667]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 24. 30.  8.  6. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  8  3  0  0 14] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -22.96932029724121
desired expected reward: 249.91856384277344






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 30.  8.  6. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  3.] 
adversary cards in discard: [6. 6. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 24. 30.  8.  6. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  3.] 
adversary cards in discard: [6. 6. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  6. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  3.] 
adversary cards in discard: [6. 6. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[282.0654 ]
 [280.87308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  3.] 
cards in discard: [6. 6. 3. 8. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  6. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3] -> size -> 10 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -9.031779289245605
desired expected reward: 274.3049011230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[280.423  ]
 [280.81546]
 [280.7912 ]
 [280.62762]
 [282.24805]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  3.] 
cards in discard: [6. 6. 3. 8. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 23. 30.  8.  6. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3] -> size -> 10 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.96159839630127
desired expected reward: 272.9468078613281



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  6. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 14.  6.] 
adversary cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 23. 30.  8.  6. 10.  6.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 14.  6.] 
adversary cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0. 10.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 14.  6.] 
adversary cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11. 29. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 14.] 
expected returns: [[275.78928]
 [274.5969 ]
 [274.81   ]
 [274.57266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 14.  6.] 
cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  3. 14.  0.  0. 10.] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -9.138384819030762
desired expected reward: 273.1096496582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[274.8157 ]
 [275.18393]
 [276.64078]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29. 14.  6.] 
cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  3. 14.  0.  0. 10.] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.734990119934082
desired expected reward: 266.16375732421875



buy possibilites: [-1] 
expected returns: [[285.90982]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29. 14.  6.] 
cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  3. 14.  0.  0. 10.] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -10.00781536102295
desired expected reward: 264.8078918457031






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 8.  3. 14.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 8.  3. 14.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[272.23865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -9.375866889953613
desired expected reward: 276.5339660644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[271.59317]
 [271.78024]
 [271.9857 ]
 [271.96146]
 [271.7778 ]
 [272.22595]
 [271.79788]
 [272.43906]
 [272.2017 ]
 [272.00333]
 [272.42432]
 [273.41827]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.664240837097168
desired expected reward: 263.3190612792969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.  0.
  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.  0.
  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.  0.
  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
expected returns: [[297.36984]
 [296.17752]
 [295.74945]
 [295.9549 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0. 10.] 
cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.  0.
  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  3 10 11  0 11 14  6 10 29  6  8  0
  0  1  8  3  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 14.  8.] 
adversary cards in discard: [ 0.  3. 10.  0.  3.  3.] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -8.194072723388672
desired expected reward: 265.2242126464844



action possibilites: [-1] 
expected returns: [[270.71698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.  0.
  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 14.  8.] 
adversary cards in discard: [ 0.  3. 10.  0.  3.  3.] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 7
Learning step: -8.900339126586914
desired expected reward: 286.9290771484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[269.95535]
 [270.32358]
 [271.78043]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 6.  6.  3.  8.  0.  0. 11.  0.  6.  0.  3.  0.  0. 11. 29. 14.  6.  0.
  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 14.  8.] 
adversary cards in discard: [ 0.  3. 10.  0.  3.  3.] 
adversary owned cards: [10  0  0  3  8  3  0  0 14  3  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.63525915145874
desired expected reward: 263.08172607421875






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.  8.] 
cards in discard: [ 0.  3. 10.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  8  3  0  0 14  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 0.  3. 10.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  3  3  0  0 14  3  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 0.  3. 10.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  3  3  0  0 14  3  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 0.  3. 10.  0.  3.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  3  3  0  0 14  3  8  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[263.86795]
 [262.45297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  3  0  0 14  3  8  0  8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -8.843761444091797
desired expected reward: 262.9366455078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[263.68588]
 [263.87283]
 [264.07834]
 [264.05408]
 [264.31857]
 [263.8905 ]
 [264.09598]
 [265.51093]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  3  3  0  0 14  3  8  0  8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.47597885131836
desired expected reward: 256.17364501953125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  3  3  0  0 14  3  8  0  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  3.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 14  3  8  0  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  3.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  0 14  3  8  0  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  3.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0. 10.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[269.32593]
 [267.91098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  3.] 
cards in discard: [ 0.  0.  0.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  8.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [10  0  0  0 14  3  8  0  8] -> size -> 9 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -7.413100719451904
desired expected reward: 258.09783935546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[254.66473]
 [255.03476]
 [255.01065]
 [254.85733]
 [256.39523]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  3.] 
cards in discard: [ 0.  0.  0.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  8.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [10  0  0  0 14  3  8  0  8] -> size -> 9 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -7.232215881347656
desired expected reward: 248.4718017578125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  8.  0.] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  0 14  3  8  0  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  0  8] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  0  8] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  0  8  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [29.  3.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[248.16862]
 [247.23877]
 [246.63072]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0.  8.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8
  3  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  8  0] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -7.439630031585693
desired expected reward: 248.95559692382812



action possibilites: [-1] 
expected returns: [[261.28555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  8  0] -> size -> 6 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: trash_cards_n_from_hand - action 4
Learning step: -6.684617519378662
desired expected reward: 238.58624267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[261.2773 ]
 [261.6232 ]
 [263.00778]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  8  0] -> size -> 6 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -7.460337162017822
desired expected reward: 253.82521057128906



buy possibilites: [-1] 
expected returns: [[245.32314]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  8  0] -> size -> 6 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -36.0 

action type: buy - action 0.0
Learning step: -9.344095230102539
desired expected reward: 251.93321228027344






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0. 14.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0. 14.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0. 14.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0. 14.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 11.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[239.61055]
 [238.47855]
 [238.45439]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0. 14.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -7.688685894012451
desired expected reward: 237.6344451904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[239.28807]
 [239.65814]
 [239.634  ]
 [239.48064]
 [241.01855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0. 14.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -7.365344524383545
desired expected reward: 232.0817413330078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  6.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.  6.  0. 11.  0.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  6.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.  6.  0. 11.  0.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  6.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.  6.  0. 11.  0.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  6.] 
adversary cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.  6.  0. 11.  0.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[248.83842]
 [247.70644]
 [247.30052]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3.  6.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.  6.  0. 11.  0.
 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -7.284263610839844
desired expected reward: 233.73431396484375



action possibilites: [-1] 
expected returns: [[277.49393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 6.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.  6.  0. 11.  0.
 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 20 

action type: gain_card_n - action 7
Learning step: -5.095638275146484
desired expected reward: 241.6893768310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[276.7939 ]
 [277.1398 ]
 [278.52438]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 6.] 
cards in discard: [ 0.  0.  0.  3. 10.  0. 10.  6.  0.  3.  0.  8. 29.  0.  6.  0. 11.  0.
 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -7.421631813049316
desired expected reward: 270.0722961425781






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10. 14.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10. 14.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  6.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10. 14.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0 11] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  5.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10. 14.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [10. 14.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[244.09105]
 [242.74751]
 [242.93492]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  5.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 11] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -9.202818870544434
desired expected reward: 269.3215637207031



action possibilites: [-1. 14.] 
expected returns: [[233.28415]
 [232.128  ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  6.  1.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  5.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 11] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: -6.740291118621826
desired expected reward: 237.8904571533203



action possibilites: [-1.] 
expected returns: [[233.10204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  5.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  0  0  0 11] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 24 

action type: take_action - action 14.0
Learning step: -5.161604404449463
desired expected reward: 226.96640014648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[229.50874]
 [229.6844 ]
 [229.66724]
 [229.87878]
 [229.66026]
 [229.85466]
 [229.68199]
 [230.10722]
 [229.7013 ]
 [230.12198]
 [230.30937]
 [230.08308]
 [230.27528]
 [229.8957 ]
 [230.06377]
 [230.2946 ]
 [231.23923]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  5.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  0  0  0 11] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 24 

action type: take_action - action -1.0
Learning step: -5.268589019775391
desired expected reward: 227.8334503173828



buy possibilites: [-1] 
expected returns: [[232.68399]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  4.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  0  0  0 11] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -10.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 28.5 

action type: buy - action 11.0
Learning step: -4.165153503417969
desired expected reward: 212.345703125






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.] 
cards in discard: [0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 11] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  4.  2. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 29. 11.  6.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0 11  8] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 29. 11.  6.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0 11  8] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 23. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 29. 11.  6.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0 11  8  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 29. 11.  6.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [11.  0. 29. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[247.02272]
 [245.95058]
 [246.14209]
 [245.95058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 11.  6.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 11  8  0] -> size -> 7 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -6.878833293914795
desired expected reward: 225.80516052246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[245.54938]
 [245.87303]
 [247.18533]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29. 11.  6.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 11  8  0] -> size -> 7 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -7.618817329406738
desired expected reward: 239.73094177246094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 11  8  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8 0 8] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[243.48576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 0 8] -> size -> 6 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -7.6910080909729
desired expected reward: 239.49429321289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[243.92049]
 [244.08478]
 [244.26802]
 [244.24413]
 [244.08252]
 [244.48431]
 [244.6758 ]
 [244.4604 ]
 [244.28384]
 [244.66086]
 [245.55644]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 0 8] -> size -> 6 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -7.4415717124938965
desired expected reward: 235.59207153320312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 0 8] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[255.2095]
 [253.9369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  3.  0.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -7.365809917449951
desired expected reward: 238.1906280517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[253.73512]
 [254.08267]
 [254.05878]
 [255.37108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  3.  0.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -7.780224800109863
desired expected reward: 246.46104431152344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8.  3.  0.  6.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.  0.
  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8.  3.  0.  6.] 
adversary cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.  0.
  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  8.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[237.12976]
 [236.24913]
 [235.67395]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.  0.  6.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.  0.
  6. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  3 10 11  0 11 14  6 10 29  6  8  0  0  1  8  3  6
  0  0 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -8.261634826660156
desired expected reward: 247.10943603515625



action possibilites: [-1] 
expected returns: [[238.13393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.  0.
  6. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: trash_cards_n_from_hand - action 7
Learning step: -6.753907680511475
desired expected reward: 228.4844970703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[237.88852]
 [238.21216]
 [239.52444]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.  0.
  6. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -6.880395412445068
desired expected reward: 231.25352478027344



buy possibilites: [-1] 
expected returns: [[234.34822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [11. 10. 14.  0.  6.  1.  0. 11.  0. 29. 11.  6.  0.  3.  0.  0.  0.  0.
  6. 10.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0] -> size -> 4 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -37.0 

action type: buy - action 0.0
Learning step: -8.471590995788574
desired expected reward: 229.41693115234375






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [8. 6. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[204.44986]
 [202.99402]
 [202.99402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -8.439111709594727
desired expected reward: 225.9091033935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[203.85687]
 [204.18054]
 [205.49283]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -7.053048610687256
desired expected reward: 199.21971130371094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 14. 11.  0.] 
adversary cards in discard: [8. 6. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 30. 23. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 14. 11.  0.] 
adversary cards in discard: [8. 6. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 14. 11.  0.] 
adversary cards in discard: [8. 6. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 14. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 11.] 
expected returns: [[214.77422]
 [213.70209]
 [213.67819]
 [213.70209]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14. 11.  0.] 
cards in discard: [8. 6. 3. 0. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1.0
Learning step: -7.2768402099609375
desired expected reward: 198.21597290039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[214.32529]
 [214.67282]
 [214.64894]
 [215.96121]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 14. 11.  0.] 
cards in discard: [8. 6. 3. 0. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -7.801585674285889
desired expected reward: 208.13246154785156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  6.  6. 10.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  6.  6. 10.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  6.  6. 10.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  6.  6. 10.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 1.  6.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[206.80702]
 [205.58797]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  6. 10.  0.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -7.014007091522217
desired expected reward: 199.46641540527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[207.46867]
 [207.62448]
 [207.79962]
 [207.77628]
 [208.00691]
 [207.81493]
 [209.03401]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  6. 10.  0.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -7.034812927246094
desired expected reward: 200.43524169921875



buy possibilites: [-1] 
expected returns: [[198.40881]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  6. 10.  0.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -57.0 

action type: buy - action 0.0
Learning step: -8.759235382080078
desired expected reward: 198.70944213867188






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  6. 11.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 22. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  6. 11.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 21. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  6. 11.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[217.52124]
 [216.67757]
 [216.49419]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  6. 11.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 21. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -6.904027462005615
desired expected reward: 191.50479125976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[216.29742]
 [216.62837]
 [216.60503]
 [217.86275]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  6. 11.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 21. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -7.79408597946167
desired expected reward: 208.85752868652344



buy possibilites: [-1] 
expected returns: [[224.8608]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  6. 11.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 20. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -18 

action type: buy - action 3.0
Learning step: -6.672051429748535
desired expected reward: 209.95631408691406






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 20. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.  3.  0.
 29.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3] -> size -> 29 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 20. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.  3.  0.
 29.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3] -> size -> 29 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 30. 20. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.  3.  0.
 29.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3] -> size -> 29 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[223.82918]
 [222.6101 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.  3.  0.
 29.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0] -> size -> 5 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -7.527158260345459
desired expected reward: 217.33363342285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[221.92953]
 [222.08534]
 [222.26047]
 [222.23712]
 [222.08315]
 [222.46777]
 [222.65117]
 [222.44446]
 [222.27576]
 [222.6365 ]
 [223.49486]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.  3.  0.
 29.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 28. 30. 20. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0] -> size -> 5 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -7.449965000152588
desired expected reward: 215.83639526367188



buy possibilites: [-1] 
expected returns: [[223.13515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 8.  6.  3.  0.  8. 11.  0. 14. 11.  0.  0.  1.  6.  6. 10.  0.  3.  0.
 29.  0.  6. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 4. 28. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0] -> size -> 5 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -337.0 

action type: buy - action 6.0
Learning step: -22.941316604614258
desired expected reward: 199.29580688476562






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 28. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0 1] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[196.03477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 1. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0 1] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -8.5708646774292
desired expected reward: 214.5642852783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[196.74223]
 [196.89804]
 [197.0732 ]
 [197.04984]
 [197.2805 ]
 [197.08847]
 [198.30756]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 1. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0 1] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -7.260194301605225
desired expected reward: 189.89060974121094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0 1] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [0. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0 1] -> size -> 6 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 27. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [0. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8. 0.] 
cards in discard: [1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0 1 1] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [0. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [11.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[204.2395 ]
 [203.21245]
 [202.84528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [0. 0. 6. 3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0 1 1] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1.0
Learning step: -7.173633575439453
desired expected reward: 191.13394165039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[203.07889]
 [203.23468]
 [203.40985]
 [203.38647]
 [203.61717]
 [203.42514]
 [204.64418]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [0. 0. 6. 3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0 1 1] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -7.487680912017822
desired expected reward: 197.0643310546875



buy possibilites: [-1] 
expected returns: [[195.91869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [ 0.  0.  6.  3.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0 1 1] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -19 

action type: buy - action 10.0
Learning step: -6.7130866050720215
desired expected reward: 196.71205139160156






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0 1 1] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0 1 1] -> size -> 7 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 11.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[204.35783]
 [203.3308 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0.  6.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0 1 1] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -7.075791835784912
desired expected reward: 188.8428955078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[203.51631]
 [203.8239 ]
 [205.08162]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.  6.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0 1 1] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -7.419076442718506
desired expected reward: 196.000244140625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0 1 1] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  0.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0 1 1] -> size -> 7 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  0.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  3  0  1  1 22] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6.  9.  9.] 
adversary cards in hand: [11. 10.  0.  8. 10.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [11. 10.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 10.] 
expected returns: [[196.66737]
 [195.71373]
 [195.53537]
 [195.37344]
 [195.53537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  8. 10.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  3  0  1  1 22] -> size -> 8 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1.0
Learning step: -6.951775550842285
desired expected reward: 183.09461975097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[194.86461]
 [195.14613]
 [196.3149 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  8. 10.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 20. 30.  8.  5. 10.  4.  0. 10.  8.  7. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  3  0  1  1 22] -> size -> 8 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -7.249973297119141
desired expected reward: 188.86024475097656



buy possibilites: [-1] 
expected returns: [[191.56248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  8. 10.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  8.  7. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  3  0  1  1 22] -> size -> 8 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -348.0 

action type: buy - action 6.0
Learning step: -22.847150802612305
desired expected reward: 172.2989501953125






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  3  0  1  1 22] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  8.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  6.  0.  1.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  3  0  1  1 22] -> size -> 8 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  8.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  6.  0.  1.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  3  0  1  1 22 29] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  6.  0.  1.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[210.3602]
 [209.5768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  0.  1.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 29. 22.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  3  0  1  1 22 29] -> size -> 9 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -7.2502007484436035
desired expected reward: 184.31228637695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[209.38869]
 [209.53067]
 [209.69257]
 [209.6702 ]
 [209.52849]
 [209.88536]
 [210.05562]
 [209.86298]
 [209.70699]
 [210.04135]
 [210.83899]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  0.  1.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 29. 22.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  3  0  1  1 22 29] -> size -> 9 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -8.187392234802246
desired expected reward: 202.17282104492188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 3. 29. 22.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 22.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 22.  1.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  3  0  1  1 22 29] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 6.  3.  0. 14.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  1.  8.  0.] 
cards in discard: [3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  3  0  1  1 22 29] -> size -> 9 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 6.  3.  0. 14.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 1. 0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 8  0  0  3  0  1  1 22 29] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 6.  3.  0. 14.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 1. 0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 8  0  0  3  0  1  1 22 29] -> size -> 9 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0. 10.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 6.  3.  0. 14.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 1. 0. 0.] 
cards in discard: [ 3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 8  0  0  3  0  1  1 22 29 25] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 6.  3.  0. 14.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [ 6.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[205.56284]
 [204.58684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 14.  0.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.  0. 29.  6.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 22.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  3  0  1  1 22 29 25] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -8.323241233825684
desired expected reward: 202.51576232910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[203.96819]
 [204.2721 ]
 [204.24968]
 [205.4185 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 14.  0.] 
cards in discard: [ 0.  0.  6.  3.  0. 10. 11.  8.  0.  0.  0.  6. 11.  3.  0.  6.  6. 11.
 10.  0.  8. 10.  0. 29.  6.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 22.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  3  0  1  1 22 29 25] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -8.068678855895996
desired expected reward: 197.49417114257812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  8. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  8. 25.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  3  0  1  1 22 29 25] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0  1  1 22 29] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0  1  1 22 29] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0  1  1 22 29  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[188.89568]
 [187.94203]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  7. 10.  6.  9.  9.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 22.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0] -> size -> 9 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1.0
Learning step: -7.917611598968506
desired expected reward: 197.5008544921875



action possibilites: [-1] 
expected returns: [[198.64331]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 22.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0] -> size -> 9 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -2 

action type: gain_card_n - action 7
Learning step: -5.046483993530273
desired expected reward: 183.27268981933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[197.31223]
 [197.45421]
 [197.61613]
 [197.59375]
 [197.45204]
 [197.80891]
 [197.97916]
 [197.78651]
 [197.63055]
 [197.9649 ]
 [198.76254]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 22.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0] -> size -> 9 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1
Learning step: -6.373267650604248
desired expected reward: 192.27005004882812






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [29.  1.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1.  0.  0.] 
cards in discard: [ 0.  8.  0. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [14.  6.  1.  6.  6.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14] -> size -> 33 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  1  1 22 29  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [14.  6.  1.  6.  6.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14] -> size -> 33 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  1  1 22 29  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [14.  6.  1.  6.  6.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14] -> size -> 33 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [1. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 2. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [14.  6.  1.  6.  6.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14] -> size -> 33 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [14.  6.  1.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[200.06458]
 [199.08856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  1.  6.  6.] 
cards in discard: [14. 11.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  0. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0] -> size -> 10 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1.0
Learning step: -7.3631911277771
desired expected reward: 191.39935302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[199.21815]
 [199.52208]
 [199.49968]
 [200.66847]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  1.  6.  6.] 
cards in discard: [14. 11.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 20. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  0. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0] -> size -> 10 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1.0
Learning step: -7.356059551239014
desired expected reward: 191.81689453125



buy possibilites: [-1] 
expected returns: [[206.5272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  1.  6.  6.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  0. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0] -> size -> 10 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: -6.279242038726807
desired expected reward: 193.2428436279297






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 22.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  1.  0.  0.] 
cards in discard: [23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  8.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[191.10564]
 [189.81172]
 [189.97365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  0. 10.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 29.  1.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -7.395035743713379
desired expected reward: 199.13217163085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[189.42476]
 [189.72865]
 [189.70627]
 [190.87506]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3.  0. 10.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 29.  1.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -6.60558557510376
desired expected reward: 184.15086364746094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  1.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  1.  0.  1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  1.  0.  1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  9.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  1.  0.  1.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [29.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[165.60811]
 [164.89264]
 [164.57433]
 [164.57433]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0. 10.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 23. 22.  0.  0.] 
adversary cards in discard: [25.  8. 29.  1.  0.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25] -> size -> 12 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -6.321868896484375
desired expected reward: 167.45509338378906



action possibilites: [-1. 10. 10.] 
expected returns: [[171.433  ]
 [170.39922]
 [170.39922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 23. 22.  0.  0.] 
adversary cards in discard: [25.  8. 29.  1.  0.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25] -> size -> 12 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: discard_n_cards - action 1
Learning step: -4.722569942474365
desired expected reward: 159.6913604736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[170.18529]
 [170.31175]
 [170.45874]
 [170.43745]
 [170.63501]
 [170.47215]
 [171.50594]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  4.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 23. 22.  0.  0.] 
adversary cards in discard: [25.  8. 29.  1.  0.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25] -> size -> 12 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: -5.075115203857422
desired expected reward: 166.35787963867188



buy possibilites: [-1] 
expected returns: [[177.0227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 23. 22.  0.  0.] 
adversary cards in discard: [25.  8. 29.  1.  0.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25] -> size -> 12 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 11 

action type: buy - action 11.0
Learning step: -3.9987404346466064
desired expected reward: 166.63629150390625






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 0. 23. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 22.  0.  0.] 
cards in discard: [25.  8. 29.  1.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  0.  0.] 
cards in discard: [25.  8. 29.  1.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  0.  0.] 
cards in discard: [25.  8. 29.  1.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 26. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  0.  0.] 
cards in discard: [25.  8. 29.  1.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[191.18987]
 [190.31892]
 [190.00908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  3.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 22.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1] -> size -> 13 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -5.908409595489502
desired expected reward: 171.11428833007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[189.73137]
 [190.00482]
 [189.98354]
 [191.05205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0.  3.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 22.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1] -> size -> 13 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -6.6221842765808105
desired expected reward: 184.56765747070312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [ 1. 22.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.  0. 11.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  0. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 23.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.  0. 11.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  0. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 23.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  3.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.  0. 11.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  0. 25.  0.  1.] 
cards in discard: [11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 23.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  2.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.  0. 11.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [6. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[182.54619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.  0. 11.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  2.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  1.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11] -> size -> 14 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -6.795313358306885
desired expected reward: 184.25672912597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[180.30785]
 [180.5813 ]
 [180.56001]
 [181.6285 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.  0. 11.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 19. 30.  8.  4. 10.  2.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  1.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11] -> size -> 14 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -6.402030944824219
desired expected reward: 176.1441650390625



buy possibilites: [-1] 
expected returns: [[198.03743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [14. 11.  0.  0.  0.  0.  3. 14.  6.  1.  6.  6.  0.  8.  3.  0. 10.  3.
 11. 29.  0. 10.  0. 10.  0. 11.  8.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  4. 10.  2.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  1.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11] -> size -> 14 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0  -1   0   0   8   0] 
sum of rewards: -9 

action type: buy - action 3.0
Learning step: -5.023222923278809
desired expected reward: 175.55807495117188






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [ 1.  1.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  4. 10.  2.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [11.  0. 14.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3] -> size -> 36 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 18. 30.  8.  4. 10.  2.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [11.  0. 14.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3] -> size -> 36 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 2. 25. 30. 18. 30.  8.  4. 10.  2.  0.  8.  7.  6.  9.  6.  9.  9.] 
adversary cards in hand: [11.  0. 14.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3] -> size -> 36 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [25. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 25. 30. 18. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [11.  0. 14.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3] -> size -> 36 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [11.  0. 14.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 11.] 
expected returns: [[189.0292 ]
 [188.15828]
 [188.13701]
 [188.15828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  0. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22. 11.  8.  1.] 
adversary cards in discard: [25. 14. 29.  1.  1.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -6.473504066467285
desired expected reward: 191.5639190673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[188.96553]
 [189.23898]
 [189.2177 ]
 [190.28618]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 14.  0. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 18. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22. 11.  8.  1.] 
adversary cards in discard: [25. 14. 29.  1.  1.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -5.945651531219482
desired expected reward: 182.36891174316406



buy possibilites: [-1] 
expected returns: [[190.55385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 14.  0. 11.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22. 11.  8.  1.] 
adversary cards in discard: [25. 14. 29.  1.  1.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 1 

action type: buy - action 3.0
Learning step: -5.12448787689209
desired expected reward: 184.114501953125






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [ 0. 22. 11.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 11.  8.  1.] 
cards in discard: [25. 14. 29.  1.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22. 11.  8.  1.] 
cards in discard: [25. 14. 29.  1.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 25. 30. 17. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  6.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[165.75847]
 [164.88756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  6.] 
cards in discard: [ 3. 11.  0. 14.  0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 14. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -6.058413982391357
desired expected reward: 184.4954376220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[165.23492]
 [165.50838]
 [165.4871 ]
 [166.55559]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  6.] 
cards in discard: [ 3. 11.  0. 14.  0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 17. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 14. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.791724681854248
desired expected reward: 160.76553344726562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 23.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [ 6. 11.  0.  3. 10.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 23.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 25. 30. 17. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [ 6. 11.  0.  3. 10.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 23.  0.  0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [ 6. 11.  0.  3. 10.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 6. 11.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[158.07098]
 [157.20006]
 [157.0372 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  3. 10.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [25. 22.  1.  1. 29.] 
adversary cards in discard: [ 3.  0. 14. 23.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.529580116271973
desired expected reward: 161.0260009765625



action possibilites: [-1. 11. 29.] 
expected returns: [[155.86897]
 [155.0516 ]
 [155.19739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  3. 29.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [25. 22.  1.  1. 29.] 
adversary cards in discard: [ 3.  0. 14. 23.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: -3.53520131111145
desired expected reward: 142.17855834960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[154.40112]
 [154.63448]
 [155.63797]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  3. 29.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [25. 22.  1.  1. 29.] 
adversary cards in discard: [ 3.  0. 14. 23.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -4.051472187042236
desired expected reward: 151.8175048828125






         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [25. 22.  1.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 22. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 22.  1.  1. 29.] 
cards in discard: [ 3.  0. 14. 23.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [3. 1. 6. 3. 3.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 22.  1.  1. 29.] 
cards in discard: [ 3.  0. 14. 23.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  5.  9.  6.  9.  9.] 
adversary cards in hand: [3. 1. 6. 3. 3.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 22.  1.  1. 29.] 
cards in discard: [ 3.  0. 14. 23.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  6.  9.  9.] 
adversary cards in hand: [3. 1. 6. 3. 3.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [3. 1. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[169.75291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 3. 3.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  8. 11.] 
adversary cards in discard: [ 3.  0. 14. 23.  0.  0. 14. 25. 22.  1.  1. 29.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -4.71245813369751
desired expected reward: 150.92550659179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[168.5887 ]
 [168.84256]
 [168.82207]
 [169.82555]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 3. 3.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  8. 11.] 
adversary cards in discard: [ 3.  0. 14. 23.  0.  0. 14. 25. 22.  1.  1. 29.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -5.427229881286621
desired expected reward: 164.32568359375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  8. 11.] 
cards in discard: [ 3.  0. 14. 23.  0.  0. 14. 25. 22.  1.  1. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  6.  9.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 8.] 
cards in discard: [ 3.  0. 14. 23.  0.  0. 14. 25. 22.  1.  1. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  6.  9.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8.] 
cards in discard: [ 3.  0. 14. 23.  0.  0. 14. 25. 22.  1.  1. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  6.  9.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8.] 
cards in discard: [ 3.  0. 14. 23.  0.  0. 14. 25. 22.  1.  1. 29.  1. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [14. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[163.90611]
 [163.06825]
 [162.93594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  0.  3.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 14. 11. 22.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.561361312866211
desired expected reward: 164.26419067382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[162.53049]
 [162.78435]
 [162.76385]
 [163.76732]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  0.  3.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 14. 11. 22.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -5.271199703216553
desired expected reward: 158.63491821289062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 11. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11. 22.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 11. 22.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 11. 22.  1.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [10.  8.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[171.41548]
 [170.44531]
 [170.30797]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  6.  0.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 10 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0
 29 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 1. 29.  0. 23.  8.] 
adversary cards in discard: [ 0.  0. 14. 11. 22.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.090680122375488
desired expected reward: 158.67666625976562



action possibilites: [-1] 
expected returns: [[174.50111]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  6  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29
 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 1. 29.  0. 23.  8.] 
adversary cards in discard: [ 0.  0. 14. 11. 22.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 2
Learning step: -4.337710857391357
desired expected reward: 165.94200134277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[171.74284]
 [171.99669]
 [171.9762 ]
 [172.97969]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  6  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29
 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 1. 29.  0. 23.  8.] 
adversary cards in discard: [ 0.  0. 14. 11. 22.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -4.593671798706055
desired expected reward: 169.90744018554688






         -------------------- Turn: 72 -------------------- 
Player: 1 
cards in hand: [ 1. 29.  0. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 23.  8.] 
cards in discard: [ 0.  0. 14. 11. 22.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29
 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 36 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  8.  0.] 
cards in discard: [ 0.  0. 14. 11. 22.  1.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29
 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 36 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.] 
cards in discard: [ 0.  0. 14. 11. 22.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
action values: 1 
buys: 1 
player value: 2 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29
 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 36 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14.] 
cards in discard: [ 0.  0. 14. 11. 22.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  6  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29
 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 36 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[165.08499]
 [163.97746]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.  8.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  6  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29
 11  0  0  3  6 10  6 14  3 11  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [25.  1.  3.  0.  1.] 
adversary cards in discard: [ 0.  0. 14. 11. 22.  1.  1. 29. 23.  0.  8.  0. 14.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.691897392272949
desired expected reward: 167.2877960205078



action possibilites: [-1] 
expected returns: [[168.96472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.  8.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3
  6 10  6 14  3 11  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [25.  1.  3.  0.  1.] 
adversary cards in discard: [ 0.  0. 14. 11. 22.  1.  1. 29. 23.  0.  8.  0. 14.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.5971667766571045
desired expected reward: 160.3802947998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[167.355  ]
 [167.58836]
 [168.59184]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 11.  0. 14.  0. 11. 11.  6.  0.  0.  6. 10.  6. 11.  0.  3. 29.  3.
  1.  6.  3.  3. 14. 10.  0.  0.  3.  8.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3
  6 10  6 14  3 11  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [25.  1.  3.  0.  1.] 
adversary cards in discard: [ 0.  0. 14. 11. 22.  1.  1. 29. 23.  0.  8.  0. 14.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -3.864797592163086
desired expected reward: 165.0999298095703






         -------------------- Turn: 73 -------------------- 
Player: 1 
cards in hand: [25.  1.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3.  0.  1.] 
cards in discard: [ 0.  0. 14. 11. 22.  1.  1. 29. 23.  0.  8.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  4. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 14. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3
  6 10  6 14  3 11  3  3] -> size -> 32 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  1.  0. 10.] 
cards in discard: [ 0.  0. 14. 11. 22.  1.  1. 29. 23.  0.  8.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 14. 11. 10.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3
  6 10  6 14  3 11  3  3  6] -> size -> 33 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  1.  0. 10.] 
cards in discard: [ 0.  0. 14. 11. 22.  1.  1. 29. 23.  0.  8.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  2.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 14. 11. 10.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3
  6 10  6 14  3 11  3  3  6] -> size -> 33 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  1.  0. 10.] 
cards in discard: [ 0.  0. 14. 11. 22.  1.  1. 29. 23.  0.  8.  0. 14. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 14. 11. 10.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3
  6 10  6 14  3 11  3  3  6] -> size -> 33 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0. 14. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.  8.] 
expected returns: [[169.61191]
 [168.77405]
 [168.79454]
 [168.64177]
 [168.50438]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11. 10.  8.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3
  6 10  6 14  3 11  3  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 22. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -10    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -315 

action type: buy - action -1.0
Learning step: -20.384567260742188
desired expected reward: 148.207275390625



action possibilites: [-1] 
expected returns: [[161.971]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 22. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 2
Learning step: -4.039872646331787
desired expected reward: 154.64453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[161.93173]
 [162.15251]
 [163.11174]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 22. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -4.187967300415039
desired expected reward: 157.78302001953125






         -------------------- Turn: 74 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 11. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22. 11.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 22. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [14.  0.  0.  3.  6.] 
adversary cards in discard: [ 6.  8.  0. 14. 10.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 11.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [14.  0.  0.  3.  6.] 
adversary cards in discard: [ 6.  8.  0. 14. 10.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11. 11.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 24. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [14.  0.  0.  3.  6.] 
adversary cards in discard: [ 6.  8.  0. 14. 10.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11. 11.  0. 29.  3.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [14.  0.  0.  3.  6.] 
adversary cards in discard: [ 6.  8.  0. 14. 10.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [14.  0.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[158.63281]
 [157.83167]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  6.] 
cards in discard: [ 6.  8.  0. 14. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 8. 10. 14. 14.  1.] 
adversary cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.341647148132324
desired expected reward: 157.7700958251953



action possibilites: [-1] 
expected returns: [[161.46565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 6.  8.  0. 14. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 8. 14. 14.] 
adversary cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 14.0
Learning step: -4.008607387542725
desired expected reward: 153.8230743408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[161.89847]
 [162.00856]
 [162.1395 ]
 [162.11925]
 [162.00641]
 [162.29758]
 [162.43683]
 [162.27734]
 [162.1513 ]
 [162.42361]
 [163.07848]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 6.  8.  0. 14. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  9.] 
adversary cards in hand: [ 8. 14. 14.] 
adversary cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -4.164869785308838
desired expected reward: 157.30078125



buy possibilites: [-1] 
expected returns: [[165.83757]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 6.  8.  0. 14. 10. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 8. 14. 14.] 
adversary cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 37 

action type: buy - action 15.0
Learning step: -2.5398354530334473
desired expected reward: 159.88377380371094






         -------------------- Turn: 75 -------------------- 
Player: 1 
cards in hand: [ 8. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 14.] 
cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 10.  1.  0.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.] 
cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.] 
cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[141.94669]
 [141.0195 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [23.  1.  0.  0.  0.] 
adversary cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1. 14.  8. 14.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[   -5     0     0   -10     0     0     0   -90     0     0     0     0
     0 -1800    58     0] 
sum of rewards: -1847 

action type: discard_down_to_3_cards - action 5
Learning step: -96.88157653808594
desired expected reward: 57.503265380859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[141.0042 ]
 [141.24521]
 [141.225  ]
 [142.18422]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [23.  1.  0.  0.  0.] 
adversary cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1. 14.  8. 14.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -4.6583685874938965
desired expected reward: 137.28831481933594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 76 -------------------- 
Player: 1 
cards in hand: [23.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  0.  0.  0.] 
cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1. 14.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  0.  0.  0.] 
cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1. 14.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  0.  0.  0.] 
cards in discard: [ 1. 22.  1.  0. 11. 11.  0. 29.  3. 10.  1. 14.  8. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[136.42426]
 [135.64334]
 [135.36617]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  3.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0] -> size -> 23 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -4.797773838043213
desired expected reward: 137.38644409179688



action possibilites: [-1] 
expected returns: [[148.90942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  3.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0] -> size -> 23 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: gain_card_n - action 6
Learning step: -2.3727893829345703
desired expected reward: 133.0922393798828





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[148.30923]
 [148.28902]
 [149.24825]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  3.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0] -> size -> 23 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -3.845755100250244
desired expected reward: 145.0636749267578






         -------------------- Turn: 77 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  8.  3. 10.  1.  0.  8.  7.  3.  9.  5.  9.  8.] 
adversary cards in hand: [11.  6.  0.  3.  6.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14] -> size -> 34 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  8.] 
adversary cards in hand: [11.  6.  0.  3.  6.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 23. 30. 16. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  8.] 
adversary cards in hand: [11.  6.  0.  3.  6.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 8. 0.] 
cards in discard: [15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 16. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [11.  6.  0.  3.  6.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [11.  6.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[148.95149]
 [148.17058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  3.  6.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 14.  0. 22.] 
adversary cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15] -> size -> 24 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -326 

action type: buy - action -1.0
Learning step: -20.416168212890625
desired expected reward: 128.83206176757812





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[147.93645]
 [148.89569]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  3.  6.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 16. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 14.  0. 22.] 
adversary cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15] -> size -> 24 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -5.403765678405762
desired expected reward: 143.5477294921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 78 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 14.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0. 22.] 
cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  3.  3. 29. 11.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0.  1.  0. 23.] 
cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  3.  3. 29. 11.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.  1.  0. 23.] 
cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0. 23. 30. 16. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  3.  3. 29. 11.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.  1.  0. 23.] 
cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0. 23. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  3.  3. 29. 11.] 
adversary cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 6.  3.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[154.87929]
 [154.23763]
 [154.09836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 29. 11.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6. 11.  6.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [10.  1. 11. 11. 14.] 
adversary cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.  3. 22.  0.  1. 14.  0.  1.  0. 23.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -5.766273021697998
desired expected reward: 143.12942504882812





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[145.54622]
 [146.46144]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 29. 11.] 
cards in discard: [ 6.  8.  0. 14. 10. 15. 14.  0.  0.  3.  6.  1.  0.  0. 10.  0. 14. 11.
  0.  0.  8.  3.  6. 11.  6.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [10.  1. 11. 11. 14.] 
adversary cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.  3. 22.  0.  1. 14.  0.  1.  0. 23.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -5.840427398681641
desired expected reward: 140.7547149658203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 79 -------------------- 
Player: 1 
cards in hand: [10.  1. 11. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 11. 11. 14.] 
cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.  3. 22.  0.  1. 14.  0.  1.  0. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [29.  6. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 11. 11.] 
cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.  3. 22.  0.  1. 14.  0.  1.  0. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [15.  6.  3.] 
adversary cards in discard: [29.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 11. 11.] 
cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.  3. 22.  0.  1. 14.  0.  1.  0. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [15.  6.  3.] 
adversary cards in discard: [29.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 11. 11.] 
cards in discard: [15. 25.  3.  0.  0.  1.  8.  0.  3. 22.  0.  1. 14.  0.  1.  0. 23.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 22. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [15.  6.  3.] 
adversary cards in discard: [29.  6.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [15.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[158.2346 ]
 [157.60966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.] 
cards in discard: [29.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [15.  0.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[   -5     0    -1   -30     0     0     0   -60     0     0     0     0
     0 -2100    54     0] 
sum of rewards: -2142 

action type: discard_down_to_3_cards - action 1
Learning step: -110.0636215209961
desired expected reward: 20.33155059814453





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[157.27669]
 [158.19193]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.] 
cards in discard: [29.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  2. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [15.  0.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -6.158464431762695
desired expected reward: 152.0761260986328



buy possibilites: [-1] 
expected returns: [[155.9363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.] 
cards in discard: [29.  6.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [15.  0.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -40    0    0    0    0    0    0    0   -1    0 -300
    0    0] 
sum of rewards: -348 

action type: buy - action 6.0
Learning step: -21.755268096923828
desired expected reward: 135.52142333984375






         -------------------- Turn: 80 -------------------- 
Player: 1 
cards in hand: [15.  0.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  0. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [11.  3. 14. 11. 10.] 
adversary cards in discard: [29.  6.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  1.] 
cards in discard: [0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [11.  3. 14. 11. 10.] 
adversary cards in discard: [29.  6.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [11.  3. 14. 11. 10.] 
adversary cards in discard: [29.  6.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  9.  7.] 
adversary cards in hand: [11.  3. 14. 11. 10.] 
adversary cards in discard: [29.  6.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0. 22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [11.  3. 14. 11. 10.] 
adversary cards in discard: [29.  6.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 2 





Player: 0 
cards in hand: [11.  3. 14. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 11. 10.] 
expected returns: [[151.2323 ]
 [150.48775]
 [150.46794]
 [150.48775]
 [150.34834]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 14. 11. 10.] 
cards in discard: [29.  6.  6. 15.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [1. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0. 22. 29. 15.  1.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -6.752388000488281
desired expected reward: 149.18389892578125



action possibilites: [-1] 
expected returns: [[145.25607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11. 10.] 
cards in discard: [29.  6.  6. 15.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  0. 22. 29. 15.  1.  1.  1.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 14.0
Learning step: -5.605136394500732
desired expected reward: 144.86282348632812





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[144.96286]
 [144.94307]
 [145.8583 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11. 10.] 
cards in discard: [29.  6.  6. 15.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  0. 22. 29. 15.  1.  1.  1.  1.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -5.338975429534912
desired expected reward: 139.91709899902344






         -------------------- Turn: 81 -------------------- 
Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0. 22. 29. 15.  1.  1.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [29.  6.  6. 15.  6.  3. 14. 11.  3. 11. 10.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0. 22. 29. 15.  1.  1.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [29.  6.  6. 15.  6.  3. 14. 11.  3. 11. 10.] 
adversary owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [14.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[141.2998 ]
 [140.53546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [29.  6.  6. 15.  6.  3. 14. 11.  3. 11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [ 1.  3. 11.  1. 23.] 
adversary cards in discard: [ 0.  0. 22. 29. 15.  1.  1.  1.  1.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -6.468724727630615
desired expected reward: 139.38958740234375





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
expected returns: [[140.89171]
 [141.01616]
 [140.99638]
 [141.16707]
 [141.02766]
 [141.91162]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [29.  6.  6. 15.  6.  3. 14. 11.  3. 11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  1.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [ 1.  3. 11.  1. 23.] 
adversary cards in discard: [ 0.  0. 22. 29. 15.  1.  1.  1.  1.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -6.231809139251709
desired expected reward: 135.0679931640625



Player 1 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 1 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 6 
Chapel: 1 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [29.  6.  6. 15.  6.  3. 14. 11.  3. 11. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 14  6 10  6  8  0  0  1  8  3  6  0  0 29 11  0  0  3  6
 10  6 14  3 11  3  3  6 15 14  6  6 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 15. 30.  8.  1. 10.  0.  0.  8.  7.  3.  9.  5.  8.  7.] 
adversary cards in hand: [ 1.  3. 11.  1. 23.] 
adversary cards in discard: [ 0.  0. 22. 29. 15.  1.  1.  1.  1.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0  1  1 22 29  0  0 23 25  1 11 14  3 14  1 10  0 11  1  0 15
  3  1 22] -> size -> 27 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -40    0    0    0    0    0    0    0   -2    0    0
    9    0] 
sum of rewards: -540 

action type: buy - action 11.0
Learning step: -34.058353424072266
desired expected reward: 107.10871887207031



