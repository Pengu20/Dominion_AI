 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.660545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -16.31222915649414
desired expected reward: 22.42876434326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.720987]
 [24.735111]
 [24.743204]
 [24.74041 ]
 [24.757734]
 [24.735516]
 [24.74361 ]
 [24.811003]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6362749934196472
desired expected reward: 24.239229202270508



buy possibilites: [-1] 
expected returns: [[24.90409]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.5708032250404358
desired expected reward: 24.17240333557129






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.32156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6289252042770386
desired expected reward: 24.275165557861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.480173]
 [25.494295]
 [25.502388]
 [25.499596]
 [25.492111]
 [25.516918]
 [25.4947  ]
 [25.532093]
 [25.514126]
 [25.50279 ]
 [25.528248]
 [25.570187]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6482917666435242
desired expected reward: 24.894325256347656



buy possibilites: [-1] 
expected returns: [[26.4377]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 14.0
Learning step: 0.3221721649169922
desired expected reward: 25.83629608154297






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.878826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6690548062324524
desired expected reward: 25.768646240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.923748]
 [25.937872]
 [25.945969]
 [25.943172]
 [25.960495]
 [25.938278]
 [25.946367]
 [26.013765]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6604558229446411
desired expected reward: 25.442041397094727



buy possibilites: [-1] 
expected returns: [[26.396843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.651128768920898
desired expected reward: 16.29204559326172






Player: 1 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[27.040363]
 [26.984303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [6. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.65584796667099
desired expected reward: 25.740995407104492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.145277]
 [27.159399]
 [27.167494]
 [27.1647  ]
 [27.182024]
 [27.159805]
 [27.167898]
 [27.23529 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [6. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6825343370437622
desired expected reward: 26.583444595336914



buy possibilites: [-1] 
expected returns: [[27.290623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [6. 3. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.6184733510017395
desired expected reward: 26.549022674560547






Player: 1 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 0.  0. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 0.  0. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 0.  0. 10.  0.  3. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.152325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.681275486946106
desired expected reward: 26.609346389770508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.233002]
 [27.247124]
 [27.255215]
 [27.252422]
 [27.269745]
 [27.247524]
 [27.25562 ]
 [27.323013]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6849000453948975
desired expected reward: 26.690641403198242



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [23.  0.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  1.  3.  0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.816925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29. 23.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6647416353225708
desired expected reward: 26.65827178955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.885292]
 [28.90751 ]
 [28.904715]
 [28.899818]
 [28.975302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29. 23.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7175519466400146
desired expected reward: 28.325183868408203



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29. 23.  0.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29. 23.  0.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29. 23.  0.  1.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[29.176712]
 [29.12065 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7107964158058167
desired expected reward: 28.264507293701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.686405]
 [27.707642]
 [27.704908]
 [27.700272]
 [27.772263]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6943216323852539
desired expected reward: 27.153793334960938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [ 3.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10. 10. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [ 3.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [ 3.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.423191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [ 3.  3. 14.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  0. 29.  0.] 
adversary cards in discard: [ 8.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6826258897781372
desired expected reward: 27.089635848999023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.477129]
 [28.498367]
 [28.495628]
 [28.490997]
 [28.562984]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [ 3.  3. 14.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  0. 29.  0.] 
adversary cards in discard: [ 8.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7092667818069458
desired expected reward: 27.913776397705078



buy possibilites: [-1] 
expected returns: [[29.21788]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [ 3.  3. 14.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  0. 29.  0.] 
adversary cards in discard: [ 8.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.698081016540527
desired expected reward: 18.79754638671875






Player: 1 
cards in hand: [23.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0. 29.  0.] 
cards in discard: [ 8.  3.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.  0.  3.] 
cards in discard: [ 8.  3.  3. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.  0.  3.] 
cards in discard: [ 8.  3.  3. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.61271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7343921661376953
desired expected reward: 28.483488082885742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.765818]
 [27.779352]
 [27.78705 ]
 [27.784315]
 [27.777195]
 [27.800915]
 [27.77968 ]
 [27.815405]
 [27.79818 ]
 [27.787376]
 [27.81172 ]
 [27.851671]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.692732036113739
desired expected reward: 27.130521774291992



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [14.  3.  3.  6.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [14.  3.  3.  6.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [14.  3.  3.  6.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [14.  3.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[30.299824]
 [30.24633 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  6.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0. 23.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6655612587928772
desired expected reward: 27.18610954284668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.307878]
 [30.326378]
 [30.393738]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  6.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0. 23.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7461904883384705
desired expected reward: 29.750333786010742



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 29.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0. 23.] 
cards in discard: [29.  0.  3.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0.  0.] 
cards in discard: [29.  0.  3.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8 29] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [29.  0.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 23 29  3  8 29] -> size -> 17 
action values: 1 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  0.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29] -> size -> 14 
action values: 0 
buys: 2 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  3.  1.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 26. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  3.  1.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.026852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7341130375862122
desired expected reward: 29.65962028503418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.107777]
 [31.12901 ]
 [31.126276]
 [31.121641]
 [31.193632]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7592362761497498
desired expected reward: 30.450183868408203



buy possibilites: [-1] 
expected returns: [[31.407364]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 0.  3.  0.  0.  0. 14.  3.  3.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.5140929818153381
desired expected reward: 30.614917755126953






Player: 1 
cards in hand: [29.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.031105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23.  3.  0.  3.  0.] 
adversary cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7746803164482117
desired expected reward: 30.63268280029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.171665]
 [30.185207]
 [30.192905]
 [30.190166]
 [30.206768]
 [30.185532]
 [30.193228]
 [30.257526]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23.  3.  0.  3.  0.] 
adversary cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7400557398796082
desired expected reward: 29.501903533935547



buy possibilites: [-1] 
expected returns: [[30.812069]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  3.  0.  3.  0.] 
adversary cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.19227007031440735
desired expected reward: 30.000957489013672






Player: 1 
cards in hand: [23.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  3.  0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10] -> size -> 17 
action values: 1 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10] -> size -> 17 
action values: 0 
buys: 2 
player value: 5 
card supply: [29. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 10. 29.  0.  3.  3.  3.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10  0 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[33.71831 ]
 [33.664818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [10.  0.  0.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10  0 29] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.718638002872467
desired expected reward: 30.09343147277832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.740887]
 [33.759388]
 [33.82674 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [10.  0.  0.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10. 10.  9. 10.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10  0 29] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8122444152832031
desired expected reward: 33.08763122558594



buy possibilites: [-1] 
expected returns: [[32.737564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [10.  0.  0.  0.  6.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10. 10.  9. 10.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10  0 29] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.770404815673828
desired expected reward: 22.367923736572266






Player: 1 
cards in hand: [ 3.  0. 29.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10  0 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10. 10.  9. 10.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.  6.  3.  6. 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  1. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 10  1 23 29  3  8 29  3  0 10  0 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  7. 10. 10.  9. 10.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.  6.  3.  6. 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  7. 10. 10.  9. 10.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.  6.  3.  6. 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 25. 30.  8.  7. 10. 10.  9. 10.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.  6.  3.  6. 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  7. 10. 10.  9. 10.  7.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.  6.  3.  6. 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.774801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0.  0.  0.  6.  3.  6.  3.  6. 14.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10. 10.  9. 10.  7.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0. 10.] 
adversary cards in discard: [10. 29.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7968802452087402
desired expected reward: 31.940683364868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.851816]
 [31.865013]
 [31.872463]
 [31.869667]
 [31.88593 ]
 [31.86528 ]
 [31.872728]
 [31.93505 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0.  0.  0.  6.  3.  6.  3.  6. 14.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 25. 30.  8.  7. 10. 10.  9. 10.  7.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0. 10.] 
adversary cards in discard: [10. 29.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7730152606964111
desired expected reward: 31.155241012573242



buy possibilites: [-1] 
expected returns: [[32.34942]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0.  0.  0.  6.  3.  6.  3.  6. 14.  3.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0. 10.] 
adversary cards in discard: [10. 29.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.22690898180007935
desired expected reward: 31.659019470214844






Player: 1 
cards in hand: [ 3.  3. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0. 10.] 
cards in discard: [10. 29.  8.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0. 10.] 
cards in discard: [10. 29.  8.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[30.549477]
 [30.500355]
 [30.497559]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0. 23.  0.  3.] 
adversary cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7980430722236633
desired expected reward: 31.551376342773438



action possibilites: [-1] 
expected returns: [[30.980167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [29.  0. 23.  0.  3.] 
adversary cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.12508678436279297
desired expected reward: 30.798587799072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.934103]
 [30.947304]
 [30.954754]
 [30.951958]
 [30.968214]
 [30.947569]
 [30.955015]
 [31.017342]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [29.  0. 23.  0.  3.] 
adversary cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.15420855581760406
desired expected reward: 30.825958251953125



buy possibilites: [-1] 
expected returns: [[31.593924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.] 
cards in discard: [10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [29.  0. 23.  0.  3.] 
adversary cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.0869063138961792
desired expected reward: 30.867843627929688






Player: 1 
cards in hand: [29.  0. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 23.  0.  3.] 
cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
action values: 1 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10] -> size -> 18 
action values: 0 
buys: 2 
player value: 4 
card supply: [28. 29. 30. 24. 30.  8.  7. 10.  9.  9. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  7. 10.  9.  8. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [10. 29.  8.  0.  1.  3.  3. 10.  0. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  7. 10.  9.  8. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.907295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  3. 11.  0. 14.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  7. 10.  9.  8. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7506798505783081
desired expected reward: 30.843244552612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.955112]
 [32.975758]
 [32.97296 ]
 [32.968575]
 [33.03835 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  3. 11.  0. 14.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 23. 30.  8.  7. 10.  9.  8. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7953917980194092
desired expected reward: 32.26535415649414



buy possibilites: [-1] 
expected returns: [[32.475616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  3. 11.  0. 14.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.5580633282661438
desired expected reward: 32.41051483154297






Player: 1 
cards in hand: [8. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1 23  3  8 29  3  0 10  0 29 10  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  6.  6.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.  8.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  6.  6.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.  8.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  6.  6.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.  8.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  6.  6.] 
adversary cards in discard: [10.  3. 11.  0. 14.  0.  0.  8.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[32.60173 ]
 [32.539406]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6.  6.] 
cards in discard: [10.  3. 11.  0. 14.  0.  0.  8.  0.  3.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.781385064125061
desired expected reward: 31.694231033325195



action possibilites: [-1.] 
expected returns: [[33.352333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 3.] 
cards in discard: [10.  3. 11.  0. 14.  0.  0.  8.  0.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.17834575474262238
desired expected reward: 32.4398307800293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.226437]
 [33.244293]
 [33.30967 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 3.] 
cards in discard: [10.  3. 11.  0. 14.  0.  0.  8.  0.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.20123450458049774
desired expected reward: 33.151100158691406






Player: 1 
cards in hand: [10. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 23. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.886541]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0  3] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8231655955314636
desired expected reward: 32.486507415771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.520878]
 [30.541584]
 [30.538546]
 [30.534386]
 [30.603989]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 22. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0  3] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7474526166915894
desired expected reward: 29.86332130432129



buy possibilites: [-1] 
expected returns: [[30.965263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0  3] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.501112163066864
desired expected reward: 30.040468215942383






Player: 1 
cards in hand: [23.  0.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  1.  3.  0.] 
cards in discard: [ 0.  8.  0.  3. 10. 10.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  0. 29.] 
cards in discard: [ 0.  8.  0.  3. 10. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0  3] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 8.] 
cards in discard: [ 0.  8.  0.  3. 10. 10.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0 10  1 23  8 29  3  0 10  0 29 10  8  3  0  3] -> size -> 19 
action values: 1 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 0.  8.  0.  3. 10. 10.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 29.  8.] 
owned cards: [ 0  0 10  1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  8.  0.  3. 10. 10.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 29.  8.] 
owned cards: [ 0  0 10  1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 16 
action values: 0 
buys: 2 
player value: 4 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[31.335175]
 [31.286282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [3. 0. 3. 3. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7484310269355774
desired expected reward: 30.216833114624023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.515842]
 [31.529123]
 [31.536547]
 [31.53351 ]
 [31.526844]
 [31.550055]
 [31.529346]
 [31.563889]
 [31.54702 ]
 [31.536774]
 [31.560305]
 [31.598953]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [3. 0. 3. 3. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7636217474937439
desired expected reward: 30.73468780517578



buy possibilites: [-1] 
expected returns: [[32.51102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 3.  0.  3.  3.  6.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.20455655455589294
desired expected reward: 31.764862060546875






Player: 1 
cards in hand: [ 0.  8.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  3.  8.] 
adversary cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15] -> size -> 24 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  3.  8.] 
adversary cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15] -> size -> 24 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  3.  8.] 
adversary cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15] -> size -> 24 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[32.15652 ]
 [32.104595]
 [32.08692 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  3.  8.] 
cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  0. 10.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7865979671478271
desired expected reward: 31.724422454833984



action possibilites: [-1] 
expected returns: [[32.549866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8.] 
cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3. 29. 10.] 
adversary cards in discard: [ 8. 29.  3.  0.] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.1754484474658966
desired expected reward: 32.065284729003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.44916 ]
 [32.462444]
 [32.46987 ]
 [32.466835]
 [32.48338 ]
 [32.462677]
 [32.470097]
 [32.532276]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8.] 
cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 21. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3. 29. 10.] 
adversary cards in discard: [ 8. 29.  3.  0.] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1853916496038437
desired expected reward: 32.36447525024414



buy possibilites: [-1] 
expected returns: [[33.140316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8.] 
cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3. 29. 10.] 
adversary cards in discard: [ 8. 29.  3.  0.] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.11612273752689362
desired expected reward: 32.35374450683594






Player: 1 
cards in hand: [ 3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.] 
cards in discard: [ 8. 29.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  3. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.  3. 14.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 23.] 
cards in discard: [ 8. 29.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  3. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.  3. 14.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  1.] 
cards in discard: [ 8. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  3. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.  3. 14.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  1.] 
cards in discard: [ 8. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  9.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  3. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.  3. 14.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  1.] 
cards in discard: [ 8. 29.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  3. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.  3. 14.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[33.400078]
 [33.3379  ]
 [33.3379  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3. 10.] 
cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.  3. 14.  6.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [10.  0.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7935543656349182
desired expected reward: 32.34675979614258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.39599]
 [33.41366]
 [33.4791 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3. 10.] 
cards in discard: [ 3.  0.  3.  3.  6.  0. 15.  0.  0.  0.  0. 11.  3. 14.  6.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [10.  0.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8017520904541016
desired expected reward: 32.62713623046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.725357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  3. 23.] 
adversary cards in discard: [ 0. 10.  0.  8. 10.  0.] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8299047350883484
desired expected reward: 32.649192810058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.842497]
 [30.855782]
 [30.863203]
 [30.86017 ]
 [30.876715]
 [30.856007]
 [30.86343 ]
 [30.925611]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  3. 23.] 
adversary cards in discard: [ 0. 10.  0.  8. 10.  0.] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7528176307678223
desired expected reward: 30.14891815185547



buy possibilites: [-1] 
expected returns: [[32.052197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  3. 23.] 
adversary cards in discard: [ 0. 10.  0.  8. 10.  0.] 
adversary owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.19935493171215057
desired expected reward: 30.664079666137695






Player: 1 
cards in hand: [ 8.  0. 29.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  3. 23.] 
cards in discard: [ 0. 10.  0.  8. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 23  8 29  0 10  0 29 10  8  3  0  3 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.] 
cards in discard: [ 0. 10.  0.  8. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [ 0. 10.  0.  8. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [ 0. 10.  0.  8. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10. 10.  3. 14.  6.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14.] 
expected returns: [[32.37463 ]
 [32.312454]
 [32.312454]
 [32.3227  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 14.  6.] 
cards in discard: [10.  0.  0.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7703604698181152
desired expected reward: 31.281835556030273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.394764]
 [32.41244 ]
 [32.477875]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 14.  6.] 
cards in discard: [10.  0.  0.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7853286266326904
desired expected reward: 31.745685577392578



buy possibilites: [-1] 
expected returns: [[32.04698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 14.  6.] 
cards in discard: [10.  0.  0.  0.  3.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.7606346607208252
desired expected reward: 30.81029510498047






Player: 1 
cards in hand: [ 0. 11.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.  0.] 
cards in discard: [2.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0  2] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[32.633026]
 [32.596035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  3.] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  8.  3. 10.] 
adversary cards in discard: [ 2. 29. 29.  0. 11.  3.  1.  0.] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0  2] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7682473659515381
desired expected reward: 31.27873420715332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.62337 ]
 [32.640293]
 [32.703476]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.  3.] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  8.  3. 10.] 
adversary cards in discard: [ 2. 29. 29.  0. 11.  3.  1.  0.] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0  2] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7879217863082886
desired expected reward: 31.908981323242188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  3. 10.] 
cards in discard: [ 2. 29. 29.  0. 11.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  3  0  3 11  0  0  2] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  3.  6.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.] 
cards in discard: [ 2. 29. 29.  0. 11.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  3.  6.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.] 
cards in discard: [ 2. 29. 29.  0. 11.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  3.  6.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.] 
cards in discard: [ 2. 29. 29.  0. 11.  3.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  3.  6.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11.  3.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[32.301613]
 [32.254868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  2.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7921335697174072
desired expected reward: 31.911338806152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.246933]
 [32.263855]
 [32.327034]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 29. 20. 30.  8.  7. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  2.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7800156474113464
desired expected reward: 31.521596908569336



buy possibilites: [-1] 
expected returns: [[32.571934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 29. 20. 30.  8.  6. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  2.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0] -> size -> 15 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.775910377502441
desired expected reward: 22.487945556640625






Player: 1 
cards in hand: [29.  2.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  2.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 29. 20. 30.  8.  6. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.  6.
 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  2.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 29. 20. 30.  8.  6. 10.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.  6.
 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  2.  0.  0. 10.] 
cards in discard: [16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.  6.
 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[31.887459]
 [31.820566]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.  6.
 11.  3.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15
  3 10  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  8.  3. 29.  0.] 
adversary cards in discard: [16. 29.  2.  0.  0. 10.] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7926206588745117
desired expected reward: 31.779312133789062



action possibilites: [-1] 
expected returns: [[32.652897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.  6.
 11.  3.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  8.  3. 29.  0.] 
adversary cards in discard: [16. 29.  2.  0.  0. 10.] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: -0.1604333519935608
desired expected reward: 31.61585807800293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.700027]
 [32.71695 ]
 [32.78013 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.  6.
 11.  3.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  8.  3. 29.  0.] 
adversary cards in discard: [16. 29.  2.  0.  0. 10.] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.18579676747322083
desired expected reward: 32.467098236083984



buy possibilites: [-1] 
expected returns: [[33.256207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  0.  0.  0.  3.  6.  0. 10. 10.  3. 14.  6.  0.  3. 15.  3.  3.  6.
 11.  3.  6.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  8.  3. 29.  0.] 
adversary cards in discard: [16. 29.  2.  0.  0. 10.] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.18181057274341583
desired expected reward: 32.518211364746094






Player: 1 
cards in hand: [11.  8.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 29.  0.] 
cards in discard: [16. 29.  2.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 14.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3. 29.  0.] 
cards in discard: [16. 29.  2.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 14.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3. 29.  0.] 
cards in discard: [16. 29.  2.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 14.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8. 14.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
expected returns: [[30.139797]
 [30.072906]
 [30.089825]
 [30.08007 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3.  6. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  1. 10.] 
adversary cards in discard: [16. 29.  2.  0.  0. 10.  0. 11.  8.  3. 29.  0.] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8298654556274414
desired expected reward: 32.42634201049805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.150875]
 [30.167793]
 [30.230976]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  3.  6. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  1. 10.] 
adversary cards in discard: [16. 29.  2.  0.  0. 10.  0. 11.  8.  3. 29.  0.] 
adversary owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7420945167541504
desired expected reward: 29.561861038208008



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  8.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  1. 10.] 
cards in discard: [16. 29.  2.  0.  0. 10.  0. 11.  8.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  1. 16.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  8 29 10  0 29 10  8  0  3 11  0  0  2  0 16  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8. 16.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8. 16.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8. 16.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[31.736103]
 [31.676376]
 [31.689356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  6. 11.] 
cards in discard: [ 8. 14.  3.  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  2. 29.] 
adversary cards in discard: [ 0. 10.  8. 16.] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7223313450813293
desired expected reward: 29.508644104003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.748531]
 [31.765451]
 [31.828632]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6. 11.] 
cards in discard: [ 8. 14.  3.  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 29. 20. 30.  8.  6.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  2. 29.] 
adversary cards in discard: [ 0. 10.  8. 16.] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7730464339256287
desired expected reward: 31.121816635131836



buy possibilites: [-1] 
expected returns: [[30.719236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6. 11.] 
cards in discard: [ 8. 14.  3.  6. 10.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  2. 29.] 
adversary cards in discard: [ 0. 10.  8. 16.] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0  0] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.769207000732422
desired expected reward: 21.996244430541992






Player: 1 
cards in hand: [ 0.  0. 10.  2. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  2. 29.] 
cards in discard: [ 0. 10.  8. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  2. 29.  8.] 
cards in discard: [ 0. 10.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 2. 8. 3.] 
cards in discard: [ 0. 10.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0  2  0 16  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.  8.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.  8.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.517004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7394846677780151
desired expected reward: 29.979751586914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.598925]
 [31.611563]
 [31.618427]
 [31.615015]
 [31.63127 ]
 [31.611769]
 [31.618633]
 [31.675749]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  7. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7666859030723572
desired expected reward: 30.861162185668945



buy possibilites: [-1] 
expected returns: [[31.604212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.7065087556838989
desired expected reward: 30.905258178710938






Player: 1 
cards in hand: [ 8.  0.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.  8.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.  8.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11. 29.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.  8.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[31.83935 ]
 [31.782234]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.  3.] 
cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.  8.  3.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  3. 10. 10. 29.] 
adversary cards in discard: [ 0.  8.  0.  0. 11. 29.] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7638654708862305
desired expected reward: 30.840347290039062



action possibilites: [-1.] 
expected returns: [[31.901758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.  8.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  3. 10. 10. 29.] 
adversary cards in discard: [ 0.  8.  0.  0. 11. 29.] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.16903455555438995
desired expected reward: 31.631065368652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.867525]
 [31.88703 ]
 [31.88361 ]
 [31.880367]
 [31.944347]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [ 8. 14.  3.  6. 10.  6.  3.  0. 10.  6. 11.  8.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  3. 10. 10. 29.] 
adversary cards in discard: [ 0.  8.  0.  0. 11. 29.] 
adversary owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.1720719337463379
desired expected reward: 31.729686737060547






Player: 1 
cards in hand: [ 8.  3. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10. 10. 29.] 
cards in discard: [ 0.  8.  0.  0. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8. 10. 29. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10. 29. 16.] 
cards in discard: [ 0.  8.  0.  0. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29. 16.  0.] 
cards in discard: [ 0.  8.  0.  0. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 8 29 10 29 10  8  3 11  0  0 16  0  0  0] -> size -> 14 
action values: 3 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 20. 30.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [ 0.  8.  0.  0. 11. 29.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 16.] 
owned cards: [ 8 10 29 10  8  3 11  0  0 16  0  0  0  4] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 20. 29.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  8.  0.  0. 11. 29.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 16.  8.] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 20. 29.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8.  0.  0. 11. 29.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 16.  8.] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 29. 29. 20. 29.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8.  0.  0. 11. 29.  4.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 16.  8.] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[28.276428]
 [28.24117 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6
  0  6  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8099073767662048
desired expected reward: 31.134441375732422



action possibilites: [-1] 
expected returns: [[28.555773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.10216712951660156
desired expected reward: 28.297924041748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.400055]
 [28.412697]
 [28.41956 ]
 [28.41614 ]
 [28.432402]
 [28.412897]
 [28.419764]
 [28.47688 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  6. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.10811182111501694
desired expected reward: 28.447660446166992



buy possibilites: [-1] 
expected returns: [[28.86707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  5. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: -0.039282701909542084
desired expected reward: 28.373615264892578






Player: 1 
cards in hand: [ 3. 10. 10. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 16.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  5. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 16.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  5. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.362448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 15.  6.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  5. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [ 3. 10. 10. 16.  0.] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7061647772789001
desired expected reward: 28.160903930664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.476881]
 [29.489517]
 [29.496382]
 [29.492966]
 [29.509224]
 [29.48972 ]
 [29.496584]
 [29.5537  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 15.  6.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 29. 20. 29.  8.  5.  9.  8.  5. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [ 3. 10. 10. 16.  0.] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7254100441932678
desired expected reward: 28.783857345581055



buy possibilites: [-1] 
expected returns: [[30.141275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 29. 20. 29.  8.  4.  9.  8.  5. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [ 3. 10. 10. 16.  0.] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.718305587768555
desired expected reward: 19.774658203125






Player: 1 
cards in hand: [ 0.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  8.] 
cards in discard: [ 3. 10. 10. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 20. 29.  8.  4.  9.  8.  5. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  8.] 
cards in discard: [ 3. 10. 10. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 29. 20. 29.  8.  4.  9.  8.  5. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  8.] 
cards in discard: [ 3. 10. 10. 16.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.558294]
 [30.494314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7329926490783691
desired expected reward: 29.408283233642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.586767]
 [30.606272]
 [30.60285 ]
 [30.599607]
 [30.66359 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7470795512199402
desired expected reward: 29.873332977294922



buy possibilites: [-1] 
expected returns: [[29.389315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.7494503855705261
desired expected reward: 29.837316513061523






Player: 1 
cards in hand: [ 8.  8.  0.  4. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  4. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 29 10  8  3 11  0 16  0  0  0  4  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 11. 10.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29 10  8  3  0 16  0  0  0  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 11. 10.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29 10  8  3  0 16  0  0  0  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 11. 10.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29 10  8  3  0 16  0  0  0  0  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 11. 10.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[29.337276]
 [29.294476]
 [29.282076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 11. 10.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0.  8. 10.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [10 29 10  8  3  0 16  0  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7239123582839966
desired expected reward: 28.665401458740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.303898]
 [29.319267]
 [29.378271]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 11. 10.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 29. 20. 29.  8.  4.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0.  8. 10.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [10 29 10  8  3  0 16  0  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7220198512077332
desired expected reward: 28.61525535583496



buy possibilites: [-1] 
expected returns: [[29.492735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 11. 10.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0.  8. 10.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [10 29 10  8  3  0 16  0  0  0  0  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.719904899597168
desired expected reward: 19.599365234375






Player: 1 
cards in hand: [10.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8. 10.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 29 10  8  3  0 16  0  0  0  0  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  8. 14.  6. 10.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.  6.
  3.  0.  6. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29 10  8  3  0 16  0  0  0  0  8  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  8. 14.  6. 10.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.  6.
  3.  0.  6. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 29 10  8  3 16  0  0  0  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  8. 14.  6. 10.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.  6.
  3.  0.  6. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 29 10  8  3 16  0  0  0  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  8. 14.  6. 10.] 
adversary cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.  6.
  3.  0.  6. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 14.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
expected returns: [[29.809744]
 [29.747952]
 [29.763323]
 [29.754541]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 14.  6. 10.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.  6.
  3.  0.  6. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  3  6  3 10  6 11 10  3  8  3 15  3 10  0  6  0
  6  8  8  6  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10 29 10  8  3 16  0  0  0  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.722122848033905
desired expected reward: 28.770612716674805



action possibilites: [-1] 
expected returns: [[29.417734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.  6.
  3.  0.  6. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10 29 10  8  3 16  0  0  0  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.1312813013792038
desired expected reward: 29.540969848632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.462452]
 [29.477823]
 [29.536823]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.] 
cards in discard: [ 8. 15.  6.  6.  3.  6.  0.  3.  0.  0.  3.  0.  0.  0.  3.  8.  3.  6.
  3.  0.  6. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10 29 10  8  3 16  0  0  0  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1227688416838646
desired expected reward: 29.294965744018555






Player: 1 
cards in hand: [ 8.  0. 16.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  3. 29.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10 29 10  8  3 16  0  0  0  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 29 10  8  3 16  0  0  0  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 29 10  8  3  0  0  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 29 10  8  3  0  0  8  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 29. 20. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 29 10  8  3  0  0  8  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 14.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[26.131056]
 [26.084635]
 [26.075857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  6. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [ 3. 29.  8.  3.  0.] 
adversary owned cards: [10 29 10  8  3  0  0  8  0  3] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7602741718292236
desired expected reward: 28.776546478271484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.132786]
 [26.148157]
 [26.207155]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  6. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [ 3. 29.  8.  3.  0.] 
adversary owned cards: [10 29 10  8  3  0  0  8  0  3] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6640983819961548
desired expected reward: 25.632572174072266



buy possibilites: [-1] 
expected returns: [[26.131071]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  6. 10.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [ 3. 29.  8.  3.  0.] 
adversary owned cards: [10 29 10  8  3  0  0  8  0  3] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6596073508262634
desired expected reward: 25.47317886352539






Player: 1 
cards in hand: [10.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  8.] 
cards in discard: [ 3. 29.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 29 10  8  3  0  0  8  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 6.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3. 29.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  8  3  8  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 6.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 29.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  8  3  8  0  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 6.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 29.  8.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  8  3  8  0  3  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 6.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.76172 ]
 [26.699926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 6.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  8.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  8  3  8  0  3  0] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.651563286781311
desired expected reward: 25.479507446289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.808428]
 [26.827415]
 [26.823797]
 [26.821007]
 [26.8828  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 6.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 29. 19. 29.  8.  3.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  8.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  8  3  8  0  3  0] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6756611466407776
desired expected reward: 26.2413272857666



buy possibilites: [-1] 
expected returns: [[27.08248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 6.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  8.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  8  3  8  0  3  0] -> size -> 8 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.670347213745117
desired expected reward: 17.15345001220703






Player: 1 
cards in hand: [29.  8.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  8  3  8  0  3  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6.  3.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10  8  3  8  0  3  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6.  3.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6.  3.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6.  3.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.178091]
 [27.135292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  6.  3.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.675773024559021
desired expected reward: 26.406705856323242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.196825]
 [27.212198]
 [27.271196]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  6.  3.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6836861371994019
desired expected reward: 26.638322830200195



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 10.  8.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 10.  8.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 10.  8.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 10.  8.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 10.  8.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
expected returns: [[28.12841 ]
 [28.094389]
 [28.07321 ]
 [28.06662 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 10.  8.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8
  8  6  0  6  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6720913648605347
desired expected reward: 26.599105834960938



action possibilites: [-1] 
expected returns: [[26.76054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.07768695801496506
desired expected reward: 26.878067016601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.636007]
 [26.647926]
 [26.654125]
 [26.65033 ]
 [26.66634 ]
 [26.648134]
 [26.654333]
 [26.707071]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07280387729406357
desired expected reward: 26.68773651123047



buy possibilites: [-1] 
expected returns: [[26.687742]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.06885892897844315
desired expected reward: 26.567148208618164






Player: 1 
cards in hand: [ 8.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.  0.
 15.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.  0.
 15.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 29.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  0  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.  0.
 15.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.568554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.  0.
 15.  3. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0  0] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6713834404945374
desired expected reward: 26.016359329223633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.547005]
 [26.561327]
 [26.618069]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.  0.
 15.  3. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 29. 29. 19. 29.  8.  2.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0  0] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6687217950820923
desired expected reward: 25.926401138305664



buy possibilites: [-1] 
expected returns: [[27.16797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [ 0.  3.  0. 14.  6. 10.  6.  6.  0.  8.  0.  6.  0. 11.  6.  6.  3.  0.
 15.  3. 10.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  0  0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.661576271057129
desired expected reward: 16.89975357055664






Player: 1 
cards in hand: [ 8.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8  8  0  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8] -> size -> 2 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8  0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [6. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.5268  ]
 [23.467861]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7165892720222473
desired expected reward: 26.45138168334961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.54372 ]
 [23.558044]
 [23.614784]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6129664778709412
desired expected reward: 23.07249641418457



buy possibilites: [-1] 
expected returns: [[23.068346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 8.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6140939593315125
desired expected reward: 22.92962646484375






Player: 1 
cards in hand: [29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  6.  3. 10.  0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  6.  3. 10.  0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  6.  3. 10.  0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[23.087467]
 [23.046732]
 [23.034725]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 10.  0.] 
cards in discard: [0. 6. 3. 6. 0. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.598219633102417
desired expected reward: 22.47012710571289



action possibilites: [-1. 11. 10.] 
expected returns: [[23.620504]
 [23.57977 ]
 [23.567764]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  0. 10.] 
cards in discard: [0. 6. 3. 6. 0. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.0019285010639578104
desired expected reward: 23.196096420288086



action possibilites: [-1. 10.] 
expected returns: [[25.22463 ]
 [25.171888]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 10.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 7
Learning step: 1.087471604347229
desired expected reward: 24.659652709960938



action possibilites: [-1.  8.] 
expected returns: [[25.546892]
 [25.487957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 1.1628379821777344
desired expected reward: 26.334728240966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.381279]
 [25.395603]
 [25.452345]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 1.1504849195480347
desired expected reward: 26.697378158569336






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29] -> size -> 33 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29] -> size -> 33 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[26.154654]
 [26.110125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6378591656684875
desired expected reward: 24.814483642578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.705496]
 [25.723368]
 [25.719324]
 [25.71759 ]
 [25.775473]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 29. 29. 19. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6536282300949097
desired expected reward: 25.142173767089844



buy possibilites: [-1] 
expected returns: [[25.9377]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.40935519337654114
desired expected reward: 25.31401252746582






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.763914]
 [26.706034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.646840512752533
desired expected reward: 25.29085922241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.794933]
 [26.812813]
 [26.808767]
 [26.807034]
 [26.864916]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6726965308189392
desired expected reward: 26.140018463134766



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.  3.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.  3.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.  3.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [6. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.557673]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.  3.  6.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6770917773246765
desired expected reward: 26.187820434570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.552387]
 [26.570261]
 [26.566217]
 [26.564487]
 [26.622364]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.  3.  6.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 29. 29. 18. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6675919890403748
desired expected reward: 25.89008140563965



buy possibilites: [-1] 
expected returns: [[26.7921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [ 0.  6.  3.  6.  0.  8. 29. 10. 11. 10.  6.  3.  0.  8.  3.  3.  0.  0.
 14.  3.  3.  6.  0.  0.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.4257907569408417
desired expected reward: 26.14447021484375






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  3.  6.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  3.  6.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  3.  6.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[23.586637]
 [23.554647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6.  6. 15.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7045884728431702
desired expected reward: 26.087512969970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.59741 ]
 [23.611242]
 [23.66739 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6.  6. 15.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6141567230224609
desired expected reward: 23.129549026489258



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 8.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 8.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 8.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 8.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[24.167128]
 [24.10925 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 8.] 
cards in discard: [ 6.  3.  6.  6. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6049559116363525
desired expected reward: 23.06243324279785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.187105]
 [24.200937]
 [24.257084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 8.] 
cards in discard: [ 6.  3.  6.  6. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6251075267791748
desired expected reward: 23.690019607543945



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6. 29.  3.  6.  8.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6. 29.  3.  6.  8.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[25.897459]
 [25.86862 ]
 [25.839579]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3.  6.  8.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8
  6  0  6  0  6  0  6  0 29  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6046379804611206
desired expected reward: 23.652446746826172



action possibilites: [-1] 
expected returns: [[25.542583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  6.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.060835473239421844
desired expected reward: 25.906917572021484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.418352]
 [25.432184]
 [25.488329]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  6.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.049003198742866516
desired expected reward: 25.493579864501953






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.761805]
 [25.703924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6434235572814941
desired expected reward: 24.844905853271484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.087143]
 [25.104418]
 [25.100254]
 [25.098907]
 [25.154446]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 29. 29. 17. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6405805945396423
desired expected reward: 24.503446578979492



buy possibilites: [-1] 
expected returns: [[25.069664]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.39990106225013733
desired expected reward: 24.704517364501953






Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.52689 ]
 [25.477142]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6339908242225647
desired expected reward: 24.435672760009766



action possibilites: [-1.] 
expected returns: [[25.672209]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.04554370790719986
desired expected reward: 25.457853317260742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.71629 ]
 [25.72778 ]
 [25.733566]
 [25.729403]
 [25.724955]
 [25.74548 ]
 [25.728054]
 [25.755981]
 [25.74132 ]
 [25.73384 ]
 [25.752954]
 [25.783594]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.04980943724513054
desired expected reward: 25.622400283813477






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 14.  3. 11.  3.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 14.  3. 11.  3.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 14.  3. 11.  3.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 14.  3. 11.  3.] 
adversary cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[25.628777]
 [25.586502]
 [25.590664]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 11.  3.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8. 10.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6546306610107422
desired expected reward: 25.12896156311035



action possibilites: [-1] 
expected returns: [[25.597801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8. 10.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.04881809279322624
desired expected reward: 25.537681579589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.585   ]
 [25.596493]
 [25.60228 ]
 [25.598114]
 [25.614193]
 [25.596766]
 [25.602552]
 [25.652306]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8. 10.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 29. 29. 16. 29.  8.  1.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.04897407442331314
desired expected reward: 25.548826217651367



buy possibilites: [-1] 
expected returns: [[25.891357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [ 6.  3.  6.  6. 15.  3.  6.  6.  0.  8.  8.  6. 29.  6.  3.  3.  0.  3.
  0.  8. 10.  0.  3.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -286.0 

action type: buy - action 6.0
Learning step: -9.07608413696289
desired expected reward: 16.522029876708984






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3  6] -> size -> 36 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3  6] -> size -> 36 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3  6] -> size -> 36 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 8.  6.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[22.586906]
 [22.531372]
 [22.537157]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6882660984992981
desired expected reward: 25.20309066772461



action possibilites: [-1.  8.  8.] 
expected returns: [[22.980728]
 [22.92519 ]
 [22.92519 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 14  3  6  3  6 11 10  3  8  3 15  3 10  0  6  0  6  8  8  6
  0  6  0  6  0  6  0 29  3  3  3  6] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.010280856862664223
desired expected reward: 22.70047378540039



action possibilites: [-1.] 
expected returns: [[22.492546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 13
Learning step: 0.5923401117324829
desired expected reward: 23.720060348510742





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.282764]
 [22.350067]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6096166968345642
desired expected reward: 23.102163314819336






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 3.] 
adversary cards in discard: [10.  8.  6.] 
adversary owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 3.] 
adversary cards in discard: [10.  8.  6.] 
adversary owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 3.] 
adversary cards in discard: [10.  8.  6.] 
adversary owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 3.] 
adversary cards in discard: [10.  8.  6.] 
adversary owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.827824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 6. 3.] 
cards in discard: [10.  8.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5791980028152466
desired expected reward: 21.77086639404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.835184]
 [22.902489]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 6. 3.] 
cards in discard: [10.  8.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5992463231086731
desired expected reward: 22.382080078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  0.  6. 15. 14.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  0.  6. 15. 14.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [11.  0.  6. 15. 14.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [11.  0.  6. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 14.] 
expected returns: [[23.427593]
 [23.391075]
 [23.398172]
 [23.38681 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 15. 14.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0
  6  0  6  0 29  3  3  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5742202997207642
desired expected reward: 21.80512046813965



action possibilites: [-1] 
expected returns: [[23.870148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 14.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.005292491987347603
desired expected reward: 23.52567481994629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[23.730993]
 [23.742174]
 [23.747725]
 [23.759367]
 [23.742453]
 [23.748005]
 [23.795887]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 14.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 29. 29. 16. 29.  8.  0.  9.  8.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.016613159328699112
desired expected reward: 23.853534698486328



buy possibilites: [-1] 
expected returns: [[24.120441]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 14.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 29. 29. 16. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.5304835438728333
desired expected reward: 24.289852142333984






Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 29. 29. 16. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 29. 29. 16. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 29. 29. 16. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.081255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 29. 29. 16. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6197136640548706
desired expected reward: 23.500728607177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[24.12026 ]
 [24.136992]
 [24.131723]
 [24.185154]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 29. 29. 16. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6218326091766357
desired expected reward: 23.559072494506836



buy possibilites: [-1] 
expected returns: [[24.846848]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.3732178807258606
desired expected reward: 23.763774871826172






Player: 1 
cards in hand: [0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.693321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6357500553131104
desired expected reward: 24.211097717285156





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[24.777485]
 [24.772217]
 [24.82565 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6314875483512878
desired expected reward: 24.097593307495117



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10. 29.  3.  8.  6.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [10. 29.  3.  8.  6.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [10. 29.  3.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
expected returns: [[26.622997]
 [26.575115]
 [26.596512]
 [26.569565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  8.  6.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6154963970184326
desired expected reward: 24.210153579711914





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[26.649815]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3.  8.  6.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6688668727874756
desired expected reward: 25.954130172729492



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3. 10. 29.  3.  8.  6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3. 10. 29.  3.  8.  6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3. 10. 29.  3.  8.  6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.461258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3. 10. 29.  3.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6716512441635132
desired expected reward: 25.97816276550293





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[26.477829]
 [26.483376]
 [26.49502 ]
 [26.47811 ]
 [26.483656]
 [26.531538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [10.  8.  6.  6.  6.  6.  6.  3. 11. 15. 11.  6. 14.  3.  3.  0.  3.  3.
  0.  6.  0.  3.  0.  3. 10. 29.  3.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6655921339988708
desired expected reward: 25.795665740966797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6. 29.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6. 29.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6. 29.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[22.70052 ]
 [22.674032]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  6.  3.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.706153929233551
desired expected reward: 25.82538414001465



action possibilites: [-1. 15.] 
expected returns: [[22.914345]
 [22.88644 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 15.] 
cards in discard: [6. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.01066171657294035
desired expected reward: 22.851930618286133





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[22.84143]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 15.] 
cards in discard: [6. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.0024046897888183594
desired expected reward: 22.916749954223633






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [14.  3.  6.  0. 11.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [14.  3.  6.  0. 11.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [14.  3.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[23.415567]
 [23.376638]
 [23.380966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  0. 11.] 
cards in discard: [ 6.  6. 29.  3.  6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5881634950637817
desired expected reward: 22.253267288208008





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[23.500114]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  0. 11.] 
cards in discard: [ 6.  6. 29.  3.  6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6097781658172607
desired expected reward: 22.94120216369629



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.387074]
 [23.341448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6083030104637146
desired expected reward: 22.89181137084961





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[23.448587]
 [23.443579]
 [23.494507]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.608984649181366
desired expected reward: 22.904542922973633



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [3. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.39539]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5977882742881775
desired expected reward: 22.896718978881836





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[24.46618]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6275248527526855
desired expected reward: 23.853134155273438



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6. 11.  8.  8.  3.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6. 11.  8.  8.  3.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 6. 11.  8.  8.  3.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[25.27465 ]
 [25.24005 ]
 [25.223722]
 [25.223722]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8.  8.  3.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  4. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6185191869735718
desired expected reward: 23.8476619720459



action possibilites: [-1] 
expected returns: [[25.667889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 3.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 7
Learning step: 0.23143844306468964
desired expected reward: 25.50058364868164





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[25.700342]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 3.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05018302798271179
desired expected reward: 25.617706298828125






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0. 10. 11.  6.  8.  8.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10] -> size -> 35 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0. 10. 11.  6.  8.  8.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0. 10. 11.  6.  8.  8.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10] -> size -> 35 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.091145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0. 10. 11.  6.  8.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6470532417297363
desired expected reward: 25.05328941345215





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[26.126831]
 [26.132133]
 [26.143452]
 [26.127129]
 [26.13243 ]
 [26.178059]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0. 10. 11.  6.  8.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  7.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6581844091415405
desired expected reward: 25.432960510253906



buy possibilites: [-1] 
expected returns: [[26.210217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  6. 29.  3.  6. 15. 14.  3.  6.  0. 11.  0.  0.  3.  3. 10.  3.  3.
  6.  6.  0. 10. 11.  6.  8.  8.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -1  0  0 18  0] 
sum of rewards: 12 

action type: buy - action 11.0
Learning step: -0.14909625053405762
desired expected reward: 25.994356155395508






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[21.977709]
 [21.932083]
 [21.932083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7042757272720337
desired expected reward: 25.50594139099121





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[22.043941]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5822136402130127
desired expected reward: 21.540287017822266



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [10.  0. 10.  3.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [10.  0. 10.  3.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [6. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.411661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [10.  0. 10.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5626820921897888
desired expected reward: 20.73346519470215





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[21.486427]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [10.  0. 10.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5706846714019775
desired expected reward: 20.972387313842773



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 15.  0.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 15.  0.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[22.208529]
 [22.182648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 15.  0.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5602882504463196
desired expected reward: 20.92613983154297





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[22.270466]
 [22.265747]
 [22.313364]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 15.  0.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  4. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5857152342796326
desired expected reward: 21.739356994628906



buy possibilites: [-1] 
expected returns: [[22.74589]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 15.  0.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: -0.3991405665874481
desired expected reward: 21.866605758666992






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.547283]
 [23.515171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5846908092498779
desired expected reward: 22.16119956970215





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[23.62546 ]
 [23.62074 ]
 [23.668358]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6097947359085083
desired expected reward: 22.992176055908203



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [29.  6. 14. 11.  6.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [29.  6. 14. 11.  6.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [29.  6. 14. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 11.] 
expected returns: [[25.167843]
 [25.144484]
 [25.131453]
 [25.135735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 14. 11.  6.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5959812998771667
desired expected reward: 23.072376251220703





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[25.193264]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 14. 11.  6.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6405060291290283
desired expected reward: 24.52733612060547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [11.  3.  0. 10.  3.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [11.  3.  0. 10.  3.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [11.  3.  0. 10.  3.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[25.365498]
 [25.333387]
 [25.322876]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10.  3.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6396694183349609
desired expected reward: 24.5535945892334



action possibilites: [-1] 
expected returns: [[25.401833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  9  0] 
sum of rewards: 21 

action type: gain_card_n - action 0
Learning step: 0.13749898970127106
desired expected reward: 25.444839477539062





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[25.46211]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.04470279440283775
desired expected reward: 25.35713005065918






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [6. 8. 6. 3. 8.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.  1. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [6. 8. 6. 3. 8.] 
adversary cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.  1. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [6. 8. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[26.112633]
 [26.06502 ]
 [26.06502 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 3. 8.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.  1. 11.  3.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6399472951889038
desired expected reward: 24.822162628173828





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[26.112635]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 3. 8.] 
cards in discard: [10.  0. 10.  3.  3.  6.  3.  3.  6.  0.  8.  6.  3.  0. 15.  0.  0. 11.
  0.  6.  3. 29.  6. 14. 11.  6.  1. 11.  3.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6591963768005371
desired expected reward: 25.45343780517578



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.436562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7068150639533997
desired expected reward: 25.405818939208984





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[20.809029]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5578205585479736
desired expected reward: 20.31935691833496



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [6. 0. 1. 0. 6.] 
adversary cards in discard: [3. 6. 3. 6. 6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [6. 0. 1. 0. 6.] 
adversary cards in discard: [3. 6. 3. 6. 6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [6. 0. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.589085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 6.] 
cards in discard: [3. 6. 3. 6. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5568251013755798
desired expected reward: 20.2522029876709





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.691942]
 [20.696634]
 [20.688944]
 [20.706884]
 [20.692194]
 [20.715002]
 [20.702688]
 [20.696884]
 [20.712692]
 [20.736689]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 6.] 
cards in discard: [3. 6. 3. 6. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  3. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5538125038146973
desired expected reward: 20.15530776977539



buy possibilites: [-1] 
expected returns: [[21.638779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 6.] 
cards in discard: [3. 6. 3. 6. 6. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -4.  0.  0.  2.  0.] 
sum of rewards: -7.0 

action type: buy - action 8.0
Learning step: -0.6035585999488831
desired expected reward: 20.088632583618164






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [15.  3. 10. 10.  3.] 
adversary cards in discard: [3. 6. 3. 6. 6. 8. 6. 0. 1. 0. 6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [15.  3. 10. 10.  3.] 
adversary cards in discard: [3. 6. 3. 6. 6. 8. 6. 0. 1. 0. 6.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [15.  3. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10.] 
expected returns: [[22.366621]
 [22.34262 ]
 [22.326815]
 [22.326815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10. 10.  3.] 
cards in discard: [3. 6. 3. 6. 6. 8. 6. 0. 1. 0. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5636920928955078
desired expected reward: 21.07508659362793





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[22.423569]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10. 10.  3.] 
cards in discard: [3. 6. 3. 6. 6. 8. 6. 0. 1. 0. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5879490971565247
desired expected reward: 21.85860252380371



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  8. 29.] 
adversary cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  8. 29.] 
adversary cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
expected returns: [[24.077553]
 [24.043552]
 [24.033052]
 [24.055864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  8. 29.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5697538256645203
desired expected reward: 21.85381507873535





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[24.126091]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  8. 29.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6200007200241089
desired expected reward: 23.490821838378906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3.  0.] 
adversary cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[24.36639 ]
 [24.321892]
 [24.336586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  3.  0.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6181436777114868
desired expected reward: 23.50794792175293





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[24.394238]
 [24.389797]
 [24.434296]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  3.  0.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6246683597564697
desired expected reward: 23.741722106933594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  3.  0.] 
adversary cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  3.  0.] 
adversary cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.518337]
 [24.48853 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  3.  0.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  3. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6257115602493286
desired expected reward: 23.808584213256836



action possibilites: [-1] 
expected returns: [[25.100212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0  9  0] 
sum of rewards: 19 

action type: gain_card_n - action 7
Learning step: 0.0990295559167862
desired expected reward: 24.583118438720703





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[25.060156]
 [25.055714]
 [25.100212]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.039690855890512466
desired expected reward: 25.060522079467773






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [3. 3. 8. 6. 6.] 
adversary cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0. 10. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [3. 3. 8. 6. 6.] 
adversary cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0. 10. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 78 -------------------- 
Player: 0 
cards in hand: [3. 3. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[24.869144]
 [24.82465 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 6. 6.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0. 10. 11.  6.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6420671939849854
desired expected reward: 24.458145141601562





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[24.869146]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 6. 6.] 
cards in discard: [ 3.  6.  3.  6.  6.  8.  6.  0.  1.  0.  6. 15.  3. 10. 10.  3.  6. 14.
  0.  8. 29.  8. 11.  0.  3.  0. 10. 11.  6.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6349483728408813
desired expected reward: 24.23419761657715



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 79 -------------------- 
Player: 0 
cards in hand: [10.  3. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[20.688623]
 [20.651663]
 [20.651663]
 [20.661104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6484757661819458
desired expected reward: 23.244081497192383





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[20.756187]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5563855171203613
desired expected reward: 20.254465103149414



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [3. 6. 3. 3. 0.] 
adversary cards in discard: [10.  3. 10. 11.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [3. 6. 3. 3. 0.] 
adversary cards in discard: [10.  3. 10. 11.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 80 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.64093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3. 0.] 
cards in discard: [10.  3. 10. 11.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5547567009925842
desired expected reward: 20.201431274414062





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[20.707224]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 0.] 
cards in discard: [10.  3. 10. 11.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5552281737327576
desired expected reward: 20.199907302856445



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 10.  3.] 
adversary cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 10.  3.] 
adversary cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 10.  3.] 
adversary cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 81 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.268585]
 [21.231627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  3.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.547238290309906
desired expected reward: 20.15998649597168





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[21.333536]
 [21.329386]
 [21.37071 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  3.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  2. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5662093162536621
desired expected reward: 20.779855728149414



buy possibilites: [-1] 
expected returns: [[21.636473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  3.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -6  0  0  8  0] 
sum of rewards: -3 

action type: buy - action 8.0
Learning step: -0.5026986002922058
desired expected reward: 20.82668685913086






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 8.  8.  6. 15.  6.] 
adversary cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 41 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 8.  8.  6. 15.  6.] 
adversary cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.] 
adversary owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 41 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 82 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  6. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
expected returns: [[23.107067]
 [23.065744]
 [23.065744]
 [23.08494 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  6. 15.  6.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  6  3  6 11 10  3  3 15  3 10  0  6  0  6  8  8  6  0  6  0  6
  0  6  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5565392971038818
desired expected reward: 21.079933166503906



action possibilites: [-1] 
expected returns: [[22.021208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 14  3  3  6 11 10  3  3  3 10  0  6  0  6  8  8  6  0  6  0  6  0  6
  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: -0.012416152283549309
desired expected reward: 23.108877182006836





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[21.969183]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 14  3  3  6 11 10  3  3  3 10  0  6  0  6  8  8  6  0  6  0  6  0  6
  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.020040148869156837
desired expected reward: 22.041248321533203






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 1. 11.  0.  6.  6.] 
adversary cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.  8.  8.
  6.] 
adversary owned cards: [ 0 14  3  3  6 11 10  3  3  3 10  0  6  0  6  8  8  6  0  6  0  6  0  6
  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 39 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 1. 11.  0.  6.  6.] 
adversary cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.  8.  8.
  6.] 
adversary owned cards: [ 0 14  3  3  6 11 10  3  3  3 10  0  6  0  6  8  8  6  0  6  0  6  0  6
  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 39 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 83 -------------------- 
Player: 0 
cards in hand: [ 1. 11.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.640032]
 [22.612513]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  6.  6.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.  8.  8.
  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  3  3  6 11 10  3  3  3 10  0  6  0  6  8  8  6  0  6  0  6  0  6
  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5714707374572754
desired expected reward: 21.39771270751953



action possibilites: [-1] 
expected returns: [[22.925467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 6.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.  8.  8.
  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  3  6 11 10  3  3  3 10  0  6  0  6  8  8  6  0  6  0  6  0  6
  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  1. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0  9  0] 
sum of rewards: 19 

action type: gain_card_n - action 7
Learning step: 0.13247011601924896
desired expected reward: 22.740713119506836





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[22.983377]
 [22.987741]
 [22.997398]
 [22.983591]
 [22.987957]
 [23.024916]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 6.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.  8.  8.
  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  3  6 11 10  3  3  3 10  0  6  0  6  8  8  6  0  6  0  6  0  6
  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  1. 10.  6.  9.  9.  1. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0037392997182905674
desired expected reward: 22.9292049407959



Player 0 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 0 
Gold: 0 
Estate: 10 
Duchy: 0 
Province: 0 
Curse: 10 

Remodel: 0 
Workshop: 3 
Chapel: 7 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1. 0. 6. 6.] 
cards in discard: [10.  3. 10. 11.  3.  3.  6.  3.  3.  0.  8.  0.  6.  0. 10.  3.  8.  8.
  6. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 14  3  3  6 11 10  3  3  3 10  0  6  0  6  8  8  6  0  6  0  6  0  6
  0 29  3  3  3  6 11  3 10 11  8  1  8 10  8 10  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 29. 15. 29.  8.  0.  9.  6.  0. 10.  6.  9.  9.  1. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5 500   0   0   0   0  20   0   0   0   0  -6   0   0   4   0] 
sum of rewards: 513 

action type: buy - action 8.0
Learning step: 14.700491905212402
desired expected reward: 37.68408203125



