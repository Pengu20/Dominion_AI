 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.39224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -619 

action type: buy - action -1
Learning step: -30.82562255859375
desired expected reward: -33.31319046020508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[252.48509]
 [272.21118]
 [264.8088 ]
 [211.52124]
 [261.05344]
 [283.7174 ]
 [267.12283]
 [267.09708]
 [232.50177]
 [262.60803]
 [253.1032 ]
 [286.1015 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.423731803894043
desired expected reward: 277.1393127441406



buy possibilites: [-1] 
expected returns: [[252.45647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 10.0
Learning step: -7.325131416320801
desired expected reward: 255.28289794921875






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.10797]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.286351203918457
desired expected reward: 246.1701202392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[260.48462]
 [280.44324]
 [271.53314]
 [220.2991 ]
 [289.91483]
 [274.956  ]
 [268.444  ]
 [289.53238]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.252029418945312
desired expected reward: 277.81341552734375



buy possibilites: [-1] 
expected returns: [[279.53665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -20.37537956237793
desired expected reward: 199.92369079589844






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[278.3378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.921448707580566
desired expected reward: 270.6152038574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.4124 ]
 [266.20364]
 [259.88498]
 [223.44846]
 [272.3427 ]
 [262.48257]
 [257.62997]
 [272.66727]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.064265251159668
desired expected reward: 266.7305908203125



buy possibilites: [-1] 
expected returns: [[268.31497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -5 

action type: buy - action 10.0
Learning step: -7.094412326812744
desired expected reward: 250.5355682373047






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10] -> size -> 13 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[266.08817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.599774360656738
desired expected reward: 259.7152099609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[246.1618 ]
 [264.0232 ]
 [257.83292]
 [211.72275]
 [273.59833]
 [257.97812]
 [254.21068]
 [275.25635]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -8.580741882324219
desired expected reward: 256.57366943359375



buy possibilites: [-1] 
expected returns: [[273.00287]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  6.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 8.0
Learning step: -7.806341648101807
desired expected reward: 250.17178344726562






Player: 1 
cards in hand: [ 3.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [15.  3.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[283.3651 ]
 [271.82065]
 [268.10632]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.617793083190918
desired expected reward: 264.38507080078125



action possibilites: [-1.  8. 10.] 
expected returns: [[254.87279]
 [238.22646]
 [234.35841]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -7.919224739074707
desired expected reward: 257.6564636230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[224.85649]
 [234.74734]
 [192.96266]
 [236.59445]
 [253.5378 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -7.6432695388793945
desired expected reward: 247.22952270507812






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[258.0404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  3.  0.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -8.517218589782715
desired expected reward: 245.02052307128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[242.54863]
 [258.11926]
 [250.83841]
 [206.94589]
 [264.07037]
 [253.75404]
 [247.71075]
 [261.0663 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  3.  0.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.908406257629395
desired expected reward: 249.29908752441406



buy possibilites: [-1] 
expected returns: [[202.13249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  3.  0.  8.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -15 

action type: buy - action 11.0
Learning step: -8.474029541015625
desired expected reward: 236.96617126464844






Player: 1 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [3. 0. 3. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[227.59796]
 [207.9058 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -7.32867956161499
desired expected reward: 194.80381774902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[198.21523]
 [217.91382]
 [207.99225]
 [157.2634 ]
 [225.40529]
 [212.46901]
 [204.44856]
 [224.13647]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -8.78052806854248
desired expected reward: 218.20321655273438



buy possibilites: [-1] 
expected returns: [[225.05663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3] -> size -> 16 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -354.0 

action type: buy - action 6.0
Learning step: -20.4993953704834
desired expected reward: 136.7639923095703






Player: 1 
cards in hand: [ 3.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6] -> size -> 16 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6] -> size -> 16 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6] -> size -> 16 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[185.91307]
 [186.10071]
 [175.56906]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  0.] 
cards in discard: [ 6.  0. 10.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -9.92542552947998
desired expected reward: 215.13119506835938



action possibilites: [-1] 
expected returns: [[186.1646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [ 6.  0. 10.  6.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -25 

action type: gain_card_n - action 9
Learning step: -7.4086151123046875
desired expected reward: 199.5377655029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[172.84222]
 [179.00276]
 [150.38432]
 [181.07591]
 [190.80812]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [ 6.  0. 10.  6.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -7.0055131912231445
desired expected reward: 179.15908813476562






Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  0. 10. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10] -> size -> 17 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  0. 10. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10] -> size -> 17 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  0. 10. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10] -> size -> 17 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[175.34868]
 [156.90137]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [ 6.  0. 10.  6.  0.  0. 10. 11.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.  0.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -8.405562400817871
desired expected reward: 182.4025115966797



action possibilites: [-1.] 
expected returns: [[192.90121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.  0.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action 10.0
Learning step: -5.314186096191406
desired expected reward: 153.77508544921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[175.67253]
 [181.93391]
 [156.36935]
 [182.98096]
 [194.11214]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.  0.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -7.266419887542725
desired expected reward: 185.63479614257812



buy possibilites: [-1] 
expected returns: [[171.52393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.  0.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0] -> size -> 18 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -21.20918083190918
desired expected reward: 135.1602020263672






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.  0.  3.  0. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6] -> size -> 18 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.  0.  3.  0. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  9.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6] -> size -> 18 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.  0.  3.  0. 29.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  9.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6] -> size -> 18 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[179.93488]
 [169.44395]
 [164.18861]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  0.] 
cards in discard: [ 6. 10.  3.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  9.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8] -> size -> 19 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -7.986453533172607
desired expected reward: 163.5374755859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[160.74425]
 [176.49309]
 [168.95013]
 [128.23366]
 [184.34921]
 [172.57458]
 [167.09094]
 [183.80333]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  0.] 
cards in discard: [ 6. 10.  3.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  9.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8] -> size -> 19 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -8.279624938964844
desired expected reward: 169.24853515625



buy possibilites: [-1] 
expected returns: [[238.79941]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  0.] 
cards in discard: [ 6. 10.  3.  0.  3.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  8.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8] -> size -> 19 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -47 

action type: buy - action 11.0
Learning step: -6.194474697113037
desired expected reward: 178.15475463867188






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  8.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  6.] 
adversary cards in discard: [ 6. 10.  3.  0.  3.  0.  3. 11.  0.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11] -> size -> 19 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  8.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  6.] 
adversary cards in discard: [ 6. 10.  3.  0.  3.  0.  3. 11.  0.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11] -> size -> 19 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  6.] 
adversary cards in discard: [ 6. 10.  3.  0.  3.  0.  3. 11.  0.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11] -> size -> 19 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[157.53949]
 [158.79164]
 [142.86777]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  6.] 
cards in discard: [ 6. 10.  3.  0.  3.  0.  3. 11.  0.  8. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1] -> size -> 20 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -11.890406608581543
desired expected reward: 226.90899658203125



action possibilites: [-1] 
expected returns: [[113.38205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [ 6. 10.  3.  0.  3.  0.  3. 11.  0.  8. 10.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1] -> size -> 20 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: gain_card_n - action 10
Learning step: -5.394305229187012
desired expected reward: 124.51371765136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 97.363434]
 [105.12701 ]
 [ 67.377785]
 [107.43892 ]
 [115.888565]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [ 6. 10.  3.  0.  3.  0.  3. 11.  0.  8. 10.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1] -> size -> 20 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -5.62504243850708
desired expected reward: 107.75700378417969



buy possibilites: [-1] 
expected returns: [[159.01057]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [ 6. 10.  3.  0.  3.  0.  3. 11.  0.  8. 10.  0.  0. 15.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  6. 10.  8.  8. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1] -> size -> 20 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -70.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -17.59115219116211
desired expected reward: 49.786624908447266






Player: 1 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  6. 10.  8.  8. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6] -> size -> 21 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  6. 10.  8.  8. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6] -> size -> 21 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 27. 30.  8.  6. 10.  8.  8. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6] -> size -> 21 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  6. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6] -> size -> 21 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[155.40291]
 [142.5094 ]
 [142.5094 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  6. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 10. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1 10] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -8.459294319152832
desired expected reward: 150.55128479003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.6888 ]
 [143.35498]
 [113.18051]
 [146.74838]
 [155.07828]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  6. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 10. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1 10] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -8.258797645568848
desired expected reward: 144.9357147216797



buy possibilites: [-1] 
expected returns: [[80.84633]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 10. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1 10] -> size -> 21 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -387.0 

action type: buy - action 6.0
Learning step: -23.189985275268555
desired expected reward: 89.99054718017578






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 10. 29.  0.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 15  0  3  3  0  0  8  1 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 10. 29.  0.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 10. 29.  0.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 10. 29.  0.  3.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[153.95155]
 [130.50601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -4.718852996826172
desired expected reward: 76.12747192382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[130.97939 ]
 [147.03835 ]
 [139.71536 ]
 [ 98.112366]
 [154.55228 ]
 [142.75325 ]
 [137.34839 ]
 [153.40111 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -8.199061393737793
desired expected reward: 142.3108673095703



buy possibilites: [-1] 
expected returns: [[161.28094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -59 

action type: buy - action 1.0
Learning step: -6.673095703125
desired expected reward: 140.36524963378906






Player: 1 
cards in hand: [ 3.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0. 11.  0.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1] -> size -> 23 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0. 11.  0.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1] -> size -> 23 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 27. 30.  8.  5. 10.  8.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0. 11.  0.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1] -> size -> 23 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  5. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0. 11.  0.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1] -> size -> 23 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[103.97892]
 [ 92.69177]
 [104.75272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 11.  0.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  5. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 8. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -9.70514965057373
desired expected reward: 151.57579040527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 82.68347 ]
 [ 91.365654]
 [ 52.47574 ]
 [ 92.46068 ]
 [100.28542 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.  0.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  5. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 8. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -6.945284366607666
desired expected reward: 94.1175308227539



buy possibilites: [-1] 
expected returns: [[90.40382]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.  0.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 8. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8] -> size -> 19 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -388.0 

action type: buy - action 6.0
Learning step: -19.989702224731445
desired expected reward: 32.48603820800781






Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 8. 15.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  6.  6. 11.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.  6.  3. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 8. 15.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  6.  6. 11.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.  6.  3. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 8. 15.  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  6.  6. 11.] 
adversary cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.  6.  3. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[72.90374 ]
 [62.434155]
 [72.61038 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  6.  6. 11.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.  6.  3. 10.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [ 8. 15.  3.  0.  3.  3.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8  3] -> size -> 20 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1
Learning step: -7.8450469970703125
desired expected reward: 82.55876922607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.147217]
 [28.086039]
 [72.63178 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  6.  6. 11.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.  6.  3. 10.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [ 8. 15.  3.  0.  3.  3.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8  3] -> size -> 20 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -7.304851531982422
desired expected reward: 65.598876953125



buy possibilites: [-1] 
expected returns: [[92.43196]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  6.  6. 11.] 
cards in discard: [ 6. 10.  0.  0. 10.  6.  1.  0. 15.  0.  0.  3.  6.  3. 10.  0. 11.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [ 8. 15.  3.  0.  3.  3.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8  3] -> size -> 20 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -128 

action type: buy - action 0.0
Learning step: -6.750114440917969
desired expected reward: 45.397098541259766






Player: 1 
cards in hand: [ 0.  8.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 10.  0.] 
cards in discard: [ 8. 15.  3.  0.  3.  3.  0.  3.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3 15  0  3  3  0  0  8  1 10  0  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0] -> size -> 25 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 8. 15.  3.  0.  3.  3.  0.  3.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0] -> size -> 25 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 8. 15.  3.  0.  3.  3.  0.  3.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0] -> size -> 25 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[74.505775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1
Learning step: -7.959326267242432
desired expected reward: 84.4726333618164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[57.60381 ]
 [67.1833  ]
 [62.43383 ]
 [37.14299 ]
 [70.76558 ]
 [64.34213 ]
 [60.423874]
 [69.850914]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 26. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -6.952969551086426
desired expected reward: 62.481319427490234



buy possibilites: [-1] 
expected returns: [[121.61173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -85.0 

action type: buy - action 3.0
Learning step: -4.635427951812744
desired expected reward: 57.79840850830078






Player: 1 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 3. 0. 6.] 
adversary cards in discard: [3. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 3. 0. 6.] 
adversary cards in discard: [3. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [6. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[97.30779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 0. 6.] 
cards in discard: [3. 0. 0. 6. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [ 3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -8.297073364257812
desired expected reward: 113.31465911865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.8939 ]
 [54.18583]
 [96.39857]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 6.] 
cards in discard: [3. 0. 0. 6. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [ 3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -7.308101177215576
desired expected reward: 87.51470947265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [ 3.  0.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [3. 0. 0. 6. 0. 6. 6. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 3.  0.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [3. 0. 0. 6. 0. 6. 6. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 3.  0.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [3. 0. 0. 6. 0. 6. 6. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 3.  0.  0.  0. 29.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [3. 0. 0. 6. 0. 6. 6. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[123.2474  ]
 [110.43474 ]
 [122.513374]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  3.] 
cards in discard: [3. 0. 0. 6. 0. 6. 6. 6. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 15.  3.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 29.  8. 10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -6.52924108505249
desired expected reward: 89.86933135986328



action possibilites: [-1. 11.] 
expected returns: [[108.42991]
 [109.2581 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [3. 0. 0. 6. 0. 6. 6. 6. 3. 0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 15.  3.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 29.  8. 10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -66 

action type: take_action - action 10.0
Learning step: -6.244691371917725
desired expected reward: 101.664794921875



action possibilites: [-1.] 
expected returns: [[107.92495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6.  6.  6.  3.  0.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8. 15.  3.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 29.  8. 10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   9   0] 
sum of rewards: -38 

action type: gain_card_n - action 9
Learning step: -5.068336486816406
desired expected reward: 106.8646240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 93.31226 ]
 [100.75727 ]
 [ 71.66993 ]
 [101.319954]
 [109.16694 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6.  6.  6.  3.  0.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8. 15.  3.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 29.  8. 10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -5.542956829071045
desired expected reward: 102.38199615478516






Player: 1 
cards in hand: [ 8. 15.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  8.  0.] 
cards in discard: [ 3.  0.  0.  0. 29.  8. 10.  0.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11.  1.  6.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  6.  6.  6.  3.  0.  6. 10. 10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10] -> size -> 27 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3.  8.  0.] 
cards in discard: [ 3.  0.  0.  0. 29.  8. 10.  0.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11.  1.  6.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  6.  6.  6.  3.  0.  6. 10. 10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10] -> size -> 27 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  1.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[53.48346 ]
 [55.494095]
 [49.456074]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  6.  8.  0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6.  6.  6.  3.  0.  6. 10. 10. 11.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -8.608480453491211
desired expected reward: 100.55846405029297



action possibilites: [-1] 
expected returns: [[94.63468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 8. 0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6.  6.  6.  3.  0.  6. 10. 10. 11.  0.  3.  3.  0.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -58 

action type: gain_card_n - action 9
Learning step: -3.748070478439331
desired expected reward: 55.798954010009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[82.66947 ]
 [89.96034 ]
 [87.16158 ]
 [66.885216]
 [94.34287 ]
 [87.77582 ]
 [86.30601 ]
 [95.96999 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 8. 0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6.  6.  6.  3.  0.  6. 10. 10. 11.  0.  3.  3.  0.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -6.096594333648682
desired expected reward: 88.5380859375






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10. 10. 10.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10 10] -> size -> 28 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10. 10. 10.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10 10] -> size -> 28 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10. 10. 10.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10 10] -> size -> 28 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 15.] 
expected returns: [[99.03225]
 [89.62251]
 [89.62251]
 [89.62251]
 [85.82   ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0. 15.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -7.2078857421875
desired expected reward: 88.7621078491211



action possibilites: [-1. 10. 10. 15.] 
expected returns: [[46.83091]
 [36.80802]
 [36.80802]
 [32.69178]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 10.0
Learning step: -6.439591884613037
desired expected reward: 77.28335571289062



action possibilites: [-1. 10. 15.] 
expected returns: [[81.12517 ]
 [71.01327 ]
 [66.684555]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  3.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6
  0  3 10 10] -> size -> 28 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 10.0
Learning step: -2.513796091079712
desired expected reward: 34.294219970703125



action possibilites: [-1. 10.] 
expected returns: [[19.469303]
 [17.724678]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10] -> size -> 27 
action values: 2 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 15.0
Learning step: -4.262019157409668
desired expected reward: 62.42253494262695



action possibilites: [-1.] 
expected returns: [[21.072857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 10. 15. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10] -> size -> 27 
action values: 3 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 10.0
Learning step: -0.7620940804481506
desired expected reward: 16.96257209777832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.948586]
 [22.315582]
 [16.972382]
 [-9.593688]
 [25.049175]
 [19.765167]
 [14.954894]
 [22.736816]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 10. 15. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10] -> size -> 27 
action values: 3 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: -1.0109412670135498
desired expected reward: 20.06191635131836



buy possibilites: [-1] 
expected returns: [[19.853512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 10. 15. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
action values: 3 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -5.0 

action type: buy - action 8.0
Learning step: -0.7915549278259277
desired expected reward: 18.973623275756836






Player: 1 
cards in hand: [ 0.  8. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  0.  3.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  3.  8.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  3.  8.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  3.  8.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [0. 0. 0. 3. 3. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  3.  8.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[17.098972]
 [17.250713]
 [13.554378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  8.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 15. 10.  8.  8.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  0.  3.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0  3] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -4.990206241607666
desired expected reward: 14.863306045532227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.012004]
 [ 4.050988]
 [16.34261 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3.  8.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 15. 10.  8.  8.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  0.  3.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0  3] -> size -> 20 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -4.922659397125244
desired expected reward: 11.628854751586914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 15. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  8.  8.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  3.  8.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15  0  3  3  0  0  8 10  0  8  3  8  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  3.  8.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  3.  8.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  3.  8.  0. 29.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[48.32348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -3.579852342605591
desired expected reward: 12.762761116027832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[31.737926]
 [41.86863 ]
 [38.883587]
 [22.490635]
 [16.939125]
 [35.454338]
 [48.734932]
 [37.128872]
 [57.100143]
 [36.93645 ]
 [25.910595]
 [30.482044]
 [35.735943]
 [21.05909 ]
 [32.092377]
 [48.966064]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -5.381267070770264
desired expected reward: 42.94221115112305



buy possibilites: [-1] 
expected returns: [[31.06881]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  5.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: -27 

action type: buy - action 25.0
Learning step: -3.505958318710327
desired expected reward: 53.59416961669922






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  5.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0. 11. 10.  3.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25] -> size -> 29 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  5.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0. 11. 10.  3.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25] -> size -> 29 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0. 11. 10.  3.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25] -> size -> 29 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[-14.457275]
 [-14.969912]
 [-14.444127]
 [-14.969912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  3.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -5.733270168304443
desired expected reward: 25.335538864135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-16.511932]
 [-13.551595]
 [-15.07467 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.  3.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  8.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -3.459203004837036
desired expected reward: -17.916473388671875



buy possibilites: [-1] 
expected returns: [[53.4964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.  3.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  8.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -107.0 

action type: buy - action 0.0
Learning step: -3.3207340240478516
desired expected reward: -19.832674026489258






Player: 1 
cards in hand: [ 0.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  8.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.  0. 10.  0. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  8.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.  0. 10.  0. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.  0. 10.  0. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.58007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.  0. 10.  0. 11. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  8.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 11.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8 11] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -5.971768379211426
desired expected reward: 47.52463150024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.6516  ]
 [20.649948]
 [ 8.859931]
 [21.14861 ]
 [23.790207]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 8. 10. 10. 15. 10.  3.  6.  6.  0. 11.  3.  3.  8. 25.  0.  1.  0.  6.
  0.  0. 10.  0. 11. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  8.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 11.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8 11] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.641303062438965
desired expected reward: 19.938766479492188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  8.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 11.  0.  0.  0. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3 15  0  3  3  0  0  8  0  8  3  8  0  3  0  8 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 11.  0.  0.  0. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  3 15  0  3  3  0  0  0  8  3  8  0  3  0  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 11.  0.  0.  0. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  3 15  0  3  3  0  0  0  8  3  8  0  3  0  8 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 11.  0.  0.  0. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  3 15  0  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[33.59575 ]
 [26.265831]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  3 15  0  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -4.451664924621582
desired expected reward: 19.338542938232422



action possibilites: [-1.] 
expected returns: [[76.704094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  3 15  0  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action 10.0
Learning step: -2.035377025604248
desired expected reward: 16.189002990722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[68.82235 ]
 [72.43942 ]
 [58.492027]
 [72.333534]
 [79.35249 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  3 15  0  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -5.064481258392334
desired expected reward: 71.63961029052734






Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3 15  0  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [15. 10.  6. 10.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 15  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [15. 10.  6. 10.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 15  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [15. 10.  6. 10.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [15. 10.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10.] 
expected returns: [[22.996479]
 [ 9.240776]
 [13.722867]
 [13.722867]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  6. 10.  0.] 
cards in discard: [10.  0.  0.  6.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0
  3 10 10  8 25  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [29  3 15  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 17 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -7.508407115936279
desired expected reward: 71.84408569335938



action possibilites: [-1] 
expected returns: [[0.27859902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10.] 
cards in discard: [10.  0.  0.  6.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [29  3 15  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 17 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action 15.0
Learning step: -3.190753698348999
desired expected reward: 3.749687433242798





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -6.473241 ]
 [ -1.1224303]
 [ -2.5340126]
 [-37.248676 ]
 [  1.6714222]
 [ -3.6047235]
 [ -4.3657975]
 [  1.4285905]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 10.] 
cards in discard: [10.  0.  0.  6.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [29  3 15  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 17 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -2.975368022918701
desired expected reward: -2.6967689990997314



buy possibilites: [-1] 
expected returns: [[43.419445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 10.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [29  3 15  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 17 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -87.0 

action type: buy - action 0.0
Learning step: -3.0494000911712646
desired expected reward: -9.522647857666016






Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 15  3  3  0  0  0  8  3  8  0  3  0  8 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[  1.454901 ]
 [-15.083557 ]
 [  3.0521858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [8. 3. 0. 8. 3.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -5.607150554656982
desired expected reward: 37.812294006347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.431118 ]
 [ -7.7002172]
 [-13.430185 ]
 [-17.681557 ]
 [  1.2945521]
 [-11.953723 ]
 [-14.11699  ]
 [ -0.9875984]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  4.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [8. 3. 0. 8. 3.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.4947831630706787
desired expected reward: -4.07603645324707



buy possibilites: [-1] 
expected returns: [[13.961507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [8. 3. 0. 8. 3.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -65.0 

action type: buy - action 8.0
Learning step: -2.3381786346435547
desired expected reward: -14.291927337646484






Player: 1 
cards in hand: [ 0.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  0.] 
cards in discard: [8. 3. 0. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 8.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 15.  0.] 
cards in discard: [8. 3. 0. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 8.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 15.  0.] 
cards in discard: [ 8.  3.  0.  8.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 8.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 1. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[48.681423]
 [45.79201 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 3. 8.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [ 8.  3.  0.  8.  3. 10.  0.  0.  3. 15.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -2.978994607925415
desired expected reward: 10.982512474060059





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[44.495495]
 [50.704338]
 [46.96459 ]
 [32.375965]
 [52.409416]
 [49.05326 ]
 [45.82357 ]
 [51.520798]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 8.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 24. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [ 8.  3.  0.  8.  3. 10.  0.  0.  3. 15.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.709176540374756
desired expected reward: 43.972251892089844



buy possibilites: [-1] 
expected returns: [[9.014257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 8.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 23. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [ 8.  3.  0.  8.  3. 10.  0.  0.  3. 15.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -54.0 

action type: buy - action 3.0
Learning step: -4.845408916473389
desired expected reward: 42.11918258666992






Player: 1 
cards in hand: [ 8.  3.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 29. 11.] 
cards in discard: [ 8.  3.  0.  8.  3. 10.  0.  0.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 11.  3. 25.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.  3.
  0.  1.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3] -> size -> 32 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 29. 11.] 
cards in discard: [ 8.  3.  0.  8.  3. 10.  0.  0.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 23. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 11.  3. 25.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.  3.
  0.  1.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3] -> size -> 32 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[1.2397988]
 [3.54825  ]
 [8.865919 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3. 25.  0.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.  3.
  0.  1.  6.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  4. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -3.1296284198760986
desired expected reward: 5.884629249572754



action possibilites: [-1] 
expected returns: [[3.8019211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0.  8.  3.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.  3.
  0.  1.  6.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  3. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 25.0
Learning step: -2.1577529907226562
desired expected reward: 6.708169937133789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -2.354025]
 [-24.226397]
 [  3.690203]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.  8.  3.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.  3.
  0.  1.  6.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 23. 30.  8.  3. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -2.112762928009033
desired expected reward: 1.6891582012176514



buy possibilites: [-1] 
expected returns: [[-4.21731]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.  8.  3.] 
cards in discard: [10.  0.  0.  6.  3.  6.  0. 15. 10.  6. 10.  8. 10.  0.  0. 11.  0.  3.
  0.  1.  6.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -347.0 

action type: buy - action 6.0
Learning step: -16.194974899291992
desired expected reward: -40.42136764526367






Player: 1 
cards in hand: [29.  8.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  8.  0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  8.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0.  8.  0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  8.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[4.8626814 ]
 [0.4167111 ]
 [0.30639505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3.  6. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  0. 15.  3.  3.] 
adversary cards in discard: [ 6. 29.  8.  0.  8.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -2.5718657970428467
desired expected reward: -6.789175987243652





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -1.5871518]
 [-16.278515 ]
 [  5.255867 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  3.  6. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  0. 15.  3.  3.] 
adversary cards in discard: [ 6. 29.  8.  0.  8.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -3.1568658351898193
desired expected reward: 1.9080250263214111



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15.  3.  3.] 
cards in discard: [ 6. 29.  8.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  3.  3. 25.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15.  3.  3.] 
cards in discard: [ 6. 29.  8.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  3.  3. 25.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15.  3.  3.] 
cards in discard: [ 6. 29.  8.  0.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  3.  3. 25.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[3.0592573]
 [6.946272 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 25.  0.] 
cards in discard: [ 6.  8.  3.  6. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 30.  8.  2. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 29.  8.  0.  8.  0.  0. 11.  0. 15.  3.  3.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -3.0086114406585693
desired expected reward: 2.2472527027130127



action possibilites: [-1] 
expected returns: [[28.49131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 6. 0.] 
cards in discard: [ 6.  8.  3.  6. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 30.  8.  1. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 29.  8.  0.  8.  0.  0. 11.  0. 15.  3.  3.  6.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -36 

action type: take_action - action 25.0
Learning step: -1.4675219058990479
desired expected reward: 4.704005241394043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 7.147088 ]
 [10.907307 ]
 [ 1.9889929]
 [ 9.451358 ]
 [15.549102 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6. 0.] 
cards in discard: [ 6.  8.  3.  6. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 23. 30.  8.  1. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 29.  8.  0.  8.  0.  0. 11.  0. 15.  3.  3.  6.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -3.0435526371002197
desired expected reward: 25.447757720947266



buy possibilites: [-1] 
expected returns: [[11.092469]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6. 0.] 
cards in discard: [ 6.  8.  3.  6. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  1. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 29.  8.  0.  8.  0.  0. 11.  0. 15.  3.  3.  6.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -18 

action type: buy - action 3.0
Learning step: -1.1957849264144897
desired expected reward: 9.711525917053223






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 6. 29.  8.  0.  8.  0.  0. 11.  0. 15.  3.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  1. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  8.  3. 10.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 6. 29.  8.  0.  8.  0.  0. 11.  0. 15.  3.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 22. 30.  8.  1. 10.  7.  3.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  8.  3. 10.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 6. 29.  8.  0.  8.  0.  0. 11.  0. 15.  3.  3.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  1. 10.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  8.  3. 10.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11.  8.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
expected returns: [[12.755456 ]
 [15.5465555]
 [13.578532 ]
 [10.191744 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 10.  0.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  1. 10.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 11. 29.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8] -> size -> 20 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -2.0507700443267822
desired expected reward: 9.041699409484863





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.0622425]
 [ 2.6882513]
 [15.876344 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3. 10.  0.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 22. 30.  8.  1. 10.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 11. 29.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8] -> size -> 20 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -2.183535099029541
desired expected reward: 10.571916580200195



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  3. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  1. 10.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  6. 10.  0. 15.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 30.  8.  1.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  6. 10.  0. 15.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 22. 30.  8.  1.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  6. 10.  0. 15.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10.] 
cards in discard: [16.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8 16  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 22. 30.  8.  1.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  6. 10.  0. 15.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-11.8471  ]
 [-12.108417]
 [-11.882528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  0. 15.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 30.  8.  1.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  8.  3. 15.  0.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8 16  0] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -2.8621747493743896
desired expected reward: 13.014174461364746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.78896 ]
 [-12.011182]
 [-12.250341]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  0. 15.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 22. 30.  8.  1.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  8.  3. 15.  0.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8 16  0] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -1.4840561151504517
desired expected reward: -13.331156730651855



buy possibilites: [-1] 
expected returns: [[-8.765674]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  0. 15.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  8.  3. 15.  0.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8 16  0] -> size -> 22 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -347.0 

action type: buy - action 6.0
Learning step: -16.94666862487793
desired expected reward: -28.957847595214844






Player: 1 
cards in hand: [ 6.  8.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 15.  0.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  6  0  6  8 16  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0.  0.  8. 11.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0.  0.  8. 11.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6] -> size -> 35 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0.  0.  8. 11.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6] -> size -> 35 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0.  0.  8. 11.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6] -> size -> 35 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[-11.302388]
 [ -8.577978]
 [ -9.364525]
 [-10.242477]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8. 11.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -2.6282310485839844
desired expected reward: -11.393904685974121



action possibilites: [-1.  8. 11.] 
expected returns: [[-15.396844]
 [-15.238127]
 [-13.563474]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  6.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 10.0
Learning step: -1.747527003288269
desired expected reward: -10.325504302978516



action possibilites: [-1.  8.] 
expected returns: [[-11.167986]
 [-13.347954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  40 -30   0   0   0  -1   0   0   0   0] 
sum of rewards: -48 

action type: gain_card_n - action 0
Learning step: -2.0527801513671875
desired expected reward: -14.418885231018066





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-12.667335]
 [-10.779801]
 [-12.950221]
 [ -9.713621]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  2.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: -0.5431211590766907
desired expected reward: -11.711101531982422



buy possibilites: [-1] 
expected returns: [[-16.958609]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.] 
adversary owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  40   0   0   0   0  -2   0   0   8   0] 
sum of rewards: -11 

action type: buy - action 8.0
Learning step: -0.26007771492004395
desired expected reward: -13.689897537231445






Player: 1 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  0  8  3  8  0  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10.  3.  1.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.  8. 10. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8] -> size -> 37 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  8  3  8  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10.  3.  1.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.  8. 10. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8] -> size -> 37 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  8  3  8  3  0  8 11  0  0 10  0  6  8 16  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10.  3.  1.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.  8. 10. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8] -> size -> 37 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  3  8  3  8  3  0  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10.  3.  1.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.  8. 10. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8] -> size -> 37 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  3.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-13.375105]
 [-12.702981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  0.  0.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.  8. 10. 11.  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.  0.  8.  3.  8.] 
adversary owned cards: [29 15  3  3  8  3  8  3  0  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -2.2939929962158203
desired expected reward: -19.252601623535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-13.515349]
 [-15.139307]
 [-12.136264]
 [-14.481912]
 [-14.135289]
 [-15.874917]
 [-15.322502]
 [-10.406594]
 [-12.702981]
 [-11.474268]
 [-13.375104]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.  0.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.  8. 10. 11.  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.  0.  8.  3.  8.] 
adversary owned cards: [29 15  3  3  8  3  8  3  0  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -2.4717090129852295
desired expected reward: -15.846808433532715



buy possibilites: [-1] 
expected returns: [[-10.173706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.  0.] 
cards in discard: [ 6.  8.  3.  6. 10.  3. 25.  6.  3.  3.  0.  6.  0. 11.  8.  3. 10.  0.
  6.  6.  6. 10.  0. 15.  0.  8. 10. 11.  0.  0.  8.  6. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.  0.  8.  3.  8.] 
adversary owned cards: [29 15  3  3  8  3  8  3  0  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0  -3   0   0  32   0] 
sum of rewards: -28 

action type: buy - action 14.0
Learning step: -1.1085785627365112
desired expected reward: -11.515174865722656






Player: 1 
cards in hand: [0. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 0.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  3  8  3  8  3  0  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 15. 11.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14] -> size -> 38 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 15. 11.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14] -> size -> 38 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [16.  0. 11.  0. 29.  3. 10.  0.  8.  3. 15.  0.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 15. 11.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14] -> size -> 38 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 6. 15. 11.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[ -8.826705]
 [-13.871419]
 [-10.567992]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 11.  6.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -2.0782887935638428
desired expected reward: -12.251995086669922



action possibilites: [-1] 
expected returns: [[-8.855867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  3.] 
cards in discard: [29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0  -4   0   0  16   0] 
sum of rewards: -15 

action type: gain_card_n - action 6
Learning step: -0.5153441429138184
desired expected reward: -9.193601608276367





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.235385 ]
 [ -7.9132795]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.  3.] 
cards in discard: [29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -1.1426937580108643
desired expected reward: -9.998560905456543



buy possibilites: [-1] 
expected returns: [[13.855927]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.  3.] 
cards in discard: [29.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20 -30   0   0   0  -5   0   0   0   0] 
sum of rewards: -62 

action type: buy - action 0.0
Learning step: -2.076472043991089
desired expected reward: -16.311864852905273






Player: 1 
cards in hand: [ 3.  8.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0 10  0  6  8 16  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0] -> size -> 40 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  0  6  8 16  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0] -> size -> 40 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  0  6  8 16  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0] -> size -> 40 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  0  6  8 16  0  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0] -> size -> 40 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-0.6589129]
 [-2.331153 ]
 [-2.331153 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [15.  0. 16. 11.  0.] 
adversary cards in discard: [0. 8. 3. 3. 8.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  0  6  8 16  0  0  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -3.077878952026367
desired expected reward: 10.778048515319824



action possibilites: [-1. 10.  8.] 
expected returns: [[ 2.7811615 ]
 [ 0.00914884]
 [-0.10623193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [15.  0. 16. 11.  0.] 
adversary cards in discard: [0. 8. 3. 3. 8.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  0  6  8 16  0  0  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 10.0
Learning step: -1.2051442861557007
desired expected reward: -3.5363011360168457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[1.5783231]
 [4.474457 ]
 [3.6257584]
 [5.4430895]
 [3.0602663]
 [2.3967655]
 [5.343111 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 22. 30.  8.  0.  9.  7.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [15.  0. 16. 11.  0.] 
adversary cards in discard: [0. 8. 3. 3. 8.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  0  6  8 16  0  0  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -1.3982056379318237
desired expected reward: 1.3829659223556519



buy possibilites: [-1] 
expected returns: [[-0.54229116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 30.  8.  0.  9.  6.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [15.  0. 16. 11.  0.] 
adversary cards in discard: [0. 8. 3. 3. 8.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  0  6  8 16  0  0  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0  -6   0   0  18   0] 
sum of rewards: -15 

action type: buy - action 11.0
Learning step: -1.0343563556671143
desired expected reward: 4.40873908996582






Player: 1 
cards in hand: [15.  0. 16. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 16. 11.  0.] 
cards in discard: [0. 8. 3. 3. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  0  6  8 16  0  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 22. 30.  8.  0.  9.  6.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [14.  6.  3.  3.  6.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11] -> size -> 41 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.] 
cards in discard: [0. 8. 3. 3. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 28. 30. 22. 30.  8.  0.  9.  6.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [14.  6.  3.  3.  6.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11] -> size -> 41 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  0.] 
cards in discard: [0. 8. 3. 3. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 28. 30. 22. 30.  8.  0.  9.  6.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [14.  6.  3.  3.  6.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11] -> size -> 41 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  0.] 
cards in discard: [0. 8. 3. 3. 8. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [14.  6.  3.  3.  6.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11] -> size -> 41 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [14.  6.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-19.187735]
 [-25.426805]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3.  3.  6.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [29.  0.  6.  8.  8.] 
adversary cards in discard: [ 0.  8.  3.  3.  8.  1. 15. 16. 11.  0.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -2.811293363571167
desired expected reward: -3.3535845279693604



action possibilites: [-1] 
expected returns: [[9.82782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [29.  6.  8.] 
adversary cards in discard: [ 0.  8.  3.  3.  8.  1. 15. 16. 11.  0.  0.  8.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 14.0
Learning step: 0.14246626198291779
desired expected reward: -25.284339904785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 8.100173]
 [ 9.490111]
 [ 9.120652]
 [11.162132]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  1.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [29.  6.  8.] 
adversary cards in discard: [ 0.  8.  3.  3.  8.  1. 15. 16. 11.  0.  0.  8.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -1.6210216283798218
desired expected reward: 8.206798553466797



buy possibilites: [-1] 
expected returns: [[-6.978982]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [29.  6.  8.] 
adversary cards in discard: [ 0.  8.  3.  3.  8.  1. 15. 16. 11.  0.  0.  8.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0  -7   0   0   8   0] 
sum of rewards: -26 

action type: buy - action 8.0
Learning step: -1.868272066116333
desired expected reward: 6.356629371643066






Player: 1 
cards in hand: [29.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  8.] 
cards in discard: [ 0.  8.  3.  3.  8.  1. 15. 16. 11.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  8.  3.  3.  8.  1. 15. 16. 11.  0.  0.  8.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8.  3.  3.  8.  1. 15. 16. 11.  0.  0.  8.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-19.071545]
 [-20.079182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  3.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -2.4393155574798584
desired expected reward: -9.41829776763916





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-21.056316]
 [-20.48698 ]
 [-19.5937  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  3.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -1.8515509366989136
desired expected reward: -20.92308807373047



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [10.  6.  0.  8.  6.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 27. 30. 22. 30.  8.  0.  9.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [10.  6.  0.  8.  6.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [10.  6.  0.  8.  6.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [10.  6.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-16.603111]
 [-17.772732]
 [-18.727028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  8.  6.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 29. 15.  8.  1.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -1.7638334035873413
desired expected reward: -21.357534408569336





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.412893]
 [-17.027462]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  8.  6.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 29. 15.  8.  1.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -1.9155492782592773
desired expected reward: -18.518665313720703



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 29. 15.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 15.  8.  1.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  3  8  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-11.790705]
 [-15.495566]
 [-15.495566]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 8.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  6 10  8 11  6 10  6 11 15  6  6  1  6  0  3
 10 10  8 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.  0.  8.  1.] 
adversary owned cards: [ 3  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -1.8087977170944214
desired expected reward: -18.83625602722168



action possibilites: [-1] 
expected returns: [[-7.695308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.  0.  8.  1.] 
adversary owned cards: [ 3  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.7189871668815613
desired expected reward: -16.80213165283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.497136 ]
 [-7.6602488]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.  0.  8.  1.] 
adversary owned cards: [ 3  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -1.1542788743972778
desired expected reward: -8.849587440490723






Player: 1 
cards in hand: [0. 8. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 8.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [25.  1.  3.  0.  3.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 39 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [25.  1.  3.  0.  3.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 39 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [25.  1.  3.  0.  3.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 39 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.  8.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [25.  1.  3.  0.  3.] 
adversary cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 39 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [25.  1.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-16.351322]
 [-19.995567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3.  0.  3.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  0. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -2.368001699447632
desired expected reward: -10.02824592590332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-15.625074]
 [-16.842745]
 [-13.918089]
 [-16.283321]
 [-14.548091]
 [-16.351322]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.  0.  3.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 22. 30.  8.  0.  8.  6.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  0. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -1.8760572671890259
desired expected reward: -18.227378845214844



buy possibilites: [-1] 
expected returns: [[-11.516228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.  0.  3.] 
cards in discard: [29.  0. 11.  6. 15.  6.  3. 11. 10.  0.  0. 10.  0.  8.  8. 14.  6.  3.
  3.  6.  0.  6. 11.  0.  3. 10.  6.  0.  8.  6.  8.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  8.  5.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  0. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0  -5   0   0  18   0] 
sum of rewards: -34 

action type: buy - action 11.0
Learning step: -1.144949197769165
desired expected reward: -17.42827033996582






Player: 1 
cards in hand: [ 1.  0. 16. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16. 11.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  8.  5.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [15.  1.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11] -> size -> 40 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16.  3.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [15.  1.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11] -> size -> 40 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16.  3.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [15.  1.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11] -> size -> 40 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16.  3.] 
cards in discard: [11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0 11  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [15.  1.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11] -> size -> 40 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [15.  1.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10.] 
expected returns: [[-7.2231483]
 [-4.976475 ]
 [-6.0961857]
 [-6.0961857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 6.] 
adversary cards in discard: [11.  1. 11.  1.  0. 16.  3.] 
adversary owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0 11  1] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -1.9065380096435547
desired expected reward: -13.422765731811523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-6.2957163]
 [-7.43655  ]
 [-5.4188375]
 [-6.768467 ]
 [-5.6928635]
 [-5.9053254]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 6.] 
adversary cards in discard: [11.  1. 11.  1.  0. 16.  3.] 
adversary owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0 11  1] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -2.1259233951568604
desired expected reward: -9.349065780639648



buy possibilites: [-1] 
expected returns: [[-14.899347]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0. 10. 10.] 
cards in discard: [0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 6.] 
adversary cards in discard: [11.  1. 11.  1.  0. 16.  3.] 
adversary owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0 11  1] -> size -> 20 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -40.   0.   0.   0. -30.   0.   0.   0.  -6.   0.   0.
   0.   0.] 
sum of rewards: -83.0 

action type: buy - action 0.0
Learning step: -4.170449733734131
desired expected reward: -10.466161727905273






Player: 1 
cards in hand: [8. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 6.] 
cards in discard: [11.  1. 11.  1.  0. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  0  0  6  8 16  0  0  0  0  1 16  0  0 11  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  0.  8. 11. 10.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [11.  1. 11.  1.  0. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  0.  8. 11. 10.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [11.  1. 11.  1.  0. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  0.  8. 11. 10.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [11.  1. 11.  1.  0. 16.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  0.  8. 11. 10.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[-16.386715]
 [-17.89883 ]
 [-14.463029]
 [-15.5964  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 11. 10.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10 11  6 10  6 11 15  6  6  1  6  0  3 10 10  8
 25  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  1. 11.  1.  0. 16.  3.  0.  8.  8.  0.] 
adversary owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -2.4599456787109375
desired expected reward: -17.35929298400879



action possibilites: [-1] 
expected returns: [[-16.985544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  1. 11.  1.  0. 16.  3.  0.  8.  8.  0.] 
adversary owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.3754642009735107
desired expected reward: -18.509674072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.438082]
 [-15.266408]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  1. 11.  1.  0. 16.  3.  0.  8.  8.  0.] 
adversary owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -1.333105206489563
desired expected reward: -18.318649291992188



buy possibilites: [-1] 
expected returns: [[-9.597734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  1. 11.  1.  0. 16.  3.  0.  8.  8.  0.] 
adversary owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.  20. -30.   0.   0.   0.  -6.   0.   0.
   0.   0.] 
sum of rewards: -73.0 

action type: buy - action 0.0
Learning step: -3.144045114517212
desired expected reward: -17.582122802734375






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  1. 11.  1.  0. 16.  3.  0.  8.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  1. 11.  1.  0. 16.  3.  0.  8.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [6. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-11.201602]
 [-12.344683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [11.  1.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -2.6325345039367676
desired expected reward: -12.230268478393555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-11.267854]
 [-10.434811]
 [-12.221311]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [11.  1.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -2.54056978225708
desired expected reward: -13.742166519165039



buy possibilites: [-1] 
expected returns: [[-1.6130462]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [11.  1.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.   0. -30.   0.   0.   0.  -7.   0.   0.
   0.   0.] 
sum of rewards: -94.0 

action type: buy - action 0.0
Learning step: -4.172900676727295
desired expected reward: -15.440757751464844






Player: 1 
cards in hand: [11.  1.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  0  8 16  0  0  0  0  1 16  0  0 11  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 22. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 42 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 42 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  4.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 42 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [ 3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 42 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[9.408943]
 [7.412528]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25
  0  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 11. 16. 11.  1.  0.] 
adversary owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -3.075784683227539
desired expected reward: -4.688830852508545



action possibilites: [-1] 
expected returns: [[17.701193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 11. 16. 11.  1.  0.] 
adversary owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.4692673683166504
desired expected reward: 7.8816142082214355





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.754763]
 [17.366758]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 11. 16. 11.  1.  0.] 
adversary owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -2.9043796062469482
desired expected reward: 14.796813011169434






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 11. 16. 11.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [25.  6. 11.  0. 29.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 11. 16. 11.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  9. 10.  3. 10.  8.] 
adversary cards in hand: [25.  6. 11.  0. 29.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 11. 16. 11.  1.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  6. 11.  0. 29.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [25.  6. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[-12.448242 ]
 [ -7.4956956]
 [-10.90251  ]
 [-15.198312 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 11.  0. 29.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [3. 1. 8. 0. 8.] 
adversary cards in discard: [ 3. 11. 16. 11.  1.  0. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11 14] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -4.459955215454102
desired expected reward: 12.906806945800781



action possibilites: [-1] 
expected returns: [[-26.135101]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 29.  6.  0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [3. 1. 8. 0. 8.] 
adversary cards in discard: [ 3. 11. 16. 11.  1.  0. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11 14] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -46 

action type: take_action - action 25.0
Learning step: -2.5132548809051514
desired expected reward: -10.008950233459473





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-25.22735 ]
 [-19.307858]
 [-20.682314]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 29.  6.  0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 21. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [3. 1. 8. 0. 8.] 
adversary cards in discard: [ 3. 11. 16. 11.  1.  0. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11 14] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -1.5218502283096313
desired expected reward: -27.656951904296875



buy possibilites: [-1] 
expected returns: [[8.058642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 29.  6.  0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [3. 1. 8. 0. 8.] 
adversary cards in discard: [ 3. 11. 16. 11.  1.  0. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11 14] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0  -7   0   0   8   0] 
sum of rewards: -35 

action type: buy - action 3.0
Learning step: -0.6032878756523132
desired expected reward: -19.911142349243164






Player: 1 
cards in hand: [3. 1. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8. 0. 8.] 
cards in discard: [ 3. 11. 16. 11.  1.  0. 14.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 11  8 16  0  0  0  0  1 16  0  0 11  1  0  3 11 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 6.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 3. 11. 16. 11.  1.  0. 14.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 6.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3. 11. 16. 11.  1.  0. 14.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 6.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3. 11. 16. 11.  1.  0. 14.  3.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 6.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [3. 8. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-22.390799]
 [-25.241566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 3. 6.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [11.  3. 11.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -3.7326247692108154
desired expected reward: 4.326017379760742





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-24.924627]
 [-23.54805 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 3. 6.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [11.  3. 11.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.164935350418091
desired expected reward: -25.712984085083008



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3. 11.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  8.  0.  8.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  3. 10.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 16.] 
cards in discard: [16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  3. 10.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 16.] 
cards in discard: [16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  3. 10.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 16.] 
cards in discard: [16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 26. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  3. 10.] 
adversary cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 10.] 
expected returns: [[ 3.9317098]
 [ 1.5394664]
 [-4.0961466]
 [ 1.5394664]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14.  3. 10.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -1.5923361778259277
desired expected reward: -25.140384674072266



action possibilites: [-1. 14. 10.] 
expected returns: [[ 0.39668703]
 [-9.260571  ]
 [-3.0388088 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3. 10.  0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -1.8973489999771118
desired expected reward: -0.35788071155548096



action possibilites: [-1. 14. 11.] 
expected returns: [[-5.8680706]
 [-9.879494 ]
 [-4.875579 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  0. 11.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3] -> size -> 42 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action 10.0
Learning step: -0.794079601764679
desired expected reward: -3.8328869342803955



action possibilites: [-1. 14.] 
expected returns: [[-14.613432]
 [ -9.093868]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  60   0   0   0   0  -8   0   0  16   0] 
sum of rewards: 12 

action type: gain_card_n - action 3
Learning step: 0.7436836361885071
desired expected reward: -7.225167751312256



action possibilites: [-1.] 
expected returns: [[-11.420284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 11. 14.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16] -> size -> 43 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 5. 26. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 24 

action type: take_action - action 14.0
Learning step: 1.3977370262145996
desired expected reward: -7.696131229400635





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ -9.028516]
 [ -9.847551]
 [ -8.831409]
 [-10.005364]
 [ -9.255865]
 [-11.420284]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 11. 14.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 26. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 24 

action type: take_action - action -1.0
Learning step: 1.5559524297714233
desired expected reward: -9.86433219909668



buy possibilites: [-1] 
expected returns: [[-14.398777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 15.  1.  0. 10. 10.  0.  8.  6.  0. 10.  0.  6.  6.  8.  0.  0.  8.
  3.  6.  3.  3. 25.  6. 11.  0. 29.  6.  0.  3.  8.  6.  3.  6. 16.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 11. 14.] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  80   0   0   0   0  -9   0   0  18   0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 1.8184047937393188
desired expected reward: -8.02914047241211






Player: 1 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1] -> size -> 44 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1] -> size -> 44 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1] -> size -> 44 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-13.660227]
 [-14.899265]
 [-13.927053]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  6 10  6 10  6 11 15  6  6  1  6  0  3 10 10  8 25  0
  0  8  3  6  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14.  0. 11.  8.  3.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3. 15.  0.  0.  1.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.3965370655059814
desired expected reward: -16.79531478881836



action possibilites: [-1] 
expected returns: [[-18.790812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14.  0. 11.  8.  3.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3. 15.  0.  0.  1.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 6
Learning step: -1.8853105306625366
desired expected reward: -8.63496208190918





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.199051]
 [-18.766909]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14.  0. 11.  8.  3.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3. 15.  0.  0.  1.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.2348531484603882
desired expected reward: -20.025665283203125



buy possibilites: [-1] 
expected returns: [[-11.405907]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14.  0. 11.  8.  3.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3. 15.  0.  0.  1.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0  -6   0   0   0   0] 
sum of rewards: -72 

action type: buy - action 0.0
Learning step: -3.0966804027557373
desired expected reward: -18.295730590820312






Player: 1 
cards in hand: [14.  0. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 11.  8.  3.] 
cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3. 15.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [10.  3. 16.  3.  6.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  3.] 
cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3. 15.  0.  0.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [10.  3. 16.  3.  6.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  8.  3.] 
cards in discard: [16.  0. 11.  3. 11.  0. 16.  3.  3. 15.  0.  0.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [10.  3. 16.  3.  6.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [10.  3. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[-17.541792]
 [-14.427982]
 [-15.854385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 16.  3.  6.] 
cards in discard: [0. 8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [11.  0. 16.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15 11] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.581833600997925
desired expected reward: -13.987740516662598





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.191553]
 [-18.545404]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 16.  3.  6.] 
cards in discard: [0. 8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [11.  0. 16.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15 11] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.2951908111572266
desired expected reward: -19.836986541748047



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0. 16.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0  0  1 16  0  0 11  1  0  3 11 14  3 16  0 15 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  8. 15.  3. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.] 
adversary owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8 16  0  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6.  8. 15.  3. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.] 
adversary owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8 16  0  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6.  8. 15.  3. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.] 
adversary owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[-15.213432]
 [-13.841068]
 [-11.41144 ]
 [-12.583727]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15.  3. 10.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10  6 10  6 10  6 15  6  6  1  6  3 10 10  8 25  0  0  8  3  6
  3  6  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [14.  8.  3.  0.  3.] 
adversary cards in discard: [10. 16. 11.  0.  0.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -2.115865707397461
desired expected reward: -21.606367111206055



action possibilites: [-1] 
expected returns: [[-13.35968]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [14.  8.  3.  0.  3.] 
adversary cards in discard: [10. 16. 11.  0.  0.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 6
Learning step: -1.5170046091079712
desired expected reward: -13.188769340515137





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.49583 ]
 [-13.597858]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [14.  8.  3.  0.  3.] 
adversary cards in discard: [10. 16. 11.  0.  0.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.3963550329208374
desired expected reward: -14.756034851074219



buy possibilites: [-1] 
expected returns: [[-8.412833]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [14.  8.  3.  0.  3.] 
adversary cards in discard: [10. 16. 11.  0.  0.] 
adversary owned cards: [ 3  3 11  8 16  0  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0  -5   0   0   0   0] 
sum of rewards: -71 

action type: buy - action 0.0
Learning step: -3.2144973278045654
desired expected reward: -13.710320472717285






Player: 1 
cards in hand: [14.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0.  3.] 
cards in discard: [10. 16. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.] 
adversary owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.] 
cards in discard: [10. 16. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.] 
adversary owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.] 
cards in discard: [10. 16. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.] 
adversary owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-12.208157]
 [-12.590122]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [16.  1.  3.  3.  0.] 
adversary cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.6575121879577637
desired expected reward: -11.070344924926758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-13.137489 ]
 [-11.4578285]
 [-11.936935 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [16.  1.  3.  3.  0.] 
adversary cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.4604685306549072
desired expected reward: -14.668628692626953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  1.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  3.  3.  0.] 
cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  1  0  3 11 14  3 16  0 15 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  2. 10.  7.] 
adversary cards in hand: [8. 3. 6. 8. 6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.] 
adversary owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 6. 8. 6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.] 
adversary owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 6. 8. 6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.] 
adversary owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [8. 3. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-18.695717]
 [-16.692501]
 [-16.692501]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 8. 6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  6 10  6 10  6  6  6  1  6  3 10 10  8 25  0  0  8  3  6  3  6
  0  8 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  7.] 
adversary cards in hand: [16.  0. 11.  0. 11.] 
adversary cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10. 16.  3.  3.  0.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -2.590867757797241
desired expected reward: -14.527803421020508



action possibilites: [-1] 
expected returns: [[-12.693979]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  7.] 
adversary cards in hand: [16.  0. 11.  0. 11.] 
adversary cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10. 16.  3.  3.  0.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10] -> size -> 22 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: trash_cards_n_from_hand - action 3
Learning step: -1.8093236684799194
desired expected reward: -18.335142135620117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.050679]
 [-13.177912]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  7.] 
adversary cards in hand: [16.  0. 11.  0. 11.] 
adversary cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10. 16.  3.  3.  0.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10] -> size -> 22 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -1.9832680225372314
desired expected reward: -14.677247047424316






Player: 1 
cards in hand: [16.  0. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  0. 11.] 
cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10. 16.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  1. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10. 16.  3.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  1. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10. 16.  3.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  1. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [10. 16. 11.  0.  0.  8. 14.  3.  3. 10. 16.  3.  3.  0. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  1. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 38 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-10.167374]
 [-15.881372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  1. 10.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 15.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -2.971783399581909
desired expected reward: -16.149702072143555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-20.032448]
 [-15.298895]
 [-13.212217]
 [-18.89775 ]
 [-11.839188]
 [-19.347454]
 [-20.362879]
 [-16.696125]
 [-17.471558]
 [-11.937445]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  1. 10.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 25. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 15.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.1928775310516357
desired expected reward: -13.360243797302246



buy possibilites: [-1] 
expected returns: [[-20.166325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  1. 10.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 19. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 15.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -60.    0.    0.    0.    0.    0.    0.    0.   -4.
   0.    0.    4.5   0. ] 
sum of rewards: -66.5 

action type: buy - action 11.0
Learning step: -3.1867825984954834
desired expected reward: -15.02597427368164






Player: 1 
cards in hand: [ 0. 15.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 15. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 19. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [29.  6.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11] -> size -> 39 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 15. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 19. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [29.  6.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11] -> size -> 39 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 15. 11.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 25. 30. 19. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [29.  6.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11] -> size -> 39 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [29.  6.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-7.5744786]
 [-5.657233 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  0.  6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 19. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  0. 15.  0. 15. 11.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -2.4863901138305664
desired expected reward: -22.652713775634766



action possibilites: [-1.] 
expected returns: [[-18.014137]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 19. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  0. 15.  0. 15. 11.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: discard_n_cards - action 1
Learning step: -2.3706727027893066
desired expected reward: -10.063580513000488





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-11.445051]
 [-11.745455]
 [-16.195202]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30. 19. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  0. 15.  0. 15. 11.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -1.7373974323272705
desired expected reward: -19.751535415649414



buy possibilites: [-1] 
expected returns: [[-9.427778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  0. 15.  0. 15. 11.] 
adversary owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0  -5   0   0   8   0] 
sum of rewards: -33 

action type: buy - action 3.0
Learning step: -1.2748525142669678
desired expected reward: -13.020303726196289






Player: 1 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 0.  0. 15.  0. 15. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [14. 11.  1.  3. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.  0.  3.  3. 29.  6.  0.  6.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 16.] 
cards in discard: [ 0.  0. 15.  0. 15. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [14. 11.  1.  3. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.  0.  3.  3. 29.  6.  0.  6.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0. 15.  0. 15. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0  0
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [14. 11.  1.  3. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.  0.  3.  3. 29.  6.  0.  6.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0. 15.  0. 15. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0  0
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 24. 30. 18. 30.  8.  0.  6.  1.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [14. 11.  1.  3. 10.] 
adversary cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.  0.  3.  3. 29.  6.  0.  6.] 
adversary owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 3 


Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 2 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 0 
Workshop: 5 
Chapel: 5 
Witch: 1 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [14. 11.  1.  3. 10.] 
cards in discard: [ 0.  8. 10.  3. 16.  3.  6.  0.  8.  6.  3.  6. 10.  0.  0.  6.  8.  6.
  6. 11.  3.  0.  0.  1. 10.  0.  3.  3. 29.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  6 10  6 10  6  6  6  1  6  3 10 10 25  0  0  8  3  6  3  6  0  8
 14 29  0 11  8 11  0  0  0  3 16  1  0  0 11  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  0.  6.  0.  0.  9.  8.  8. 10.  1. 10.  6.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  0. 15.  0. 15. 11.  1. 11.] 
adversary owned cards: [ 3 11  8 16  0  0 16  0  0 11  0  3 11 14  3 16  0 15 11 10 10 15  0  0
  1 11] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -40    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -546 

action type: buy - action -1
Learning step: -26.828611373901367
desired expected reward: -36.25638961791992



