 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.80989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000025 

action type: buy - action 0.0
Learning step: 120001.0
desired expected reward: 120000.9765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[98.104744]
 [98.14118 ]
 [98.10409 ]
 [98.145386]
 [98.135994]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.7542724609375



buy possibilites: [-1] 
expected returns: [[103.62868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 98.14539337158203






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[100.092865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.62867736816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[98.72113 ]
 [98.746414]
 [98.75758 ]
 [98.720474]
 [98.720474]
 [98.73503 ]
 [98.80579 ]
 [98.761795]
 [98.81303 ]
 [98.759895]
 [98.73523 ]
 [98.73392 ]
 [98.773224]
 [98.72492 ]
 [98.75223 ]
 [98.752396]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.59452819824219



buy possibilites: [-1] 
expected returns: [[89.10752]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 98.81301879882812






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  8.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  8.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  8.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[105.7854  ]
 [105.84603 ]
 [105.794815]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.1075210571289



action possibilites: [-1] 
expected returns: [[64.8522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 1. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.72856140136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[68.17704 ]
 [68.20232 ]
 [68.213486]
 [68.17638 ]
 [68.26169 ]
 [68.2177  ]
 [68.22912 ]
 [68.20829 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 1. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.85220336914062



buy possibilites: [-1] 
expected returns: [[52.956264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 1. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 68.26168823242188






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 3. 1. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11. 25.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 3. 1. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11. 25.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[53.73869]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11. 25.  8.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.95626449584961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.696434]
 [55.72171 ]
 [55.732876]
 [55.695766]
 [55.71032 ]
 [55.781086]
 [55.73709 ]
 [55.735188]
 [55.710518]
 [55.748512]
 [55.72752 ]
 [55.727684]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11. 25.  8.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.30299758911133



buy possibilites: [-1] 
expected returns: [[59.559986]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11. 25.  8.  3.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 38.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 55.78108215332031






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [1. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[98.79804]
 [98.85144]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.55998611450195



action possibilites: [-1] 
expected returns: [[96.59662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.2551040649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[97.33675 ]
 [97.36202 ]
 [97.373184]
 [97.336075]
 [97.35063 ]
 [97.42139 ]
 [97.377396]
 [97.375496]
 [97.35083 ]
 [97.38881 ]
 [97.36782 ]
 [97.36798 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.59661865234375



buy possibilites: [-1] 
expected returns: [[97.02024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 58.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 97.42138671875






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 1. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 1. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 1 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  1.  0.  0.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[93.2849  ]
 [93.338295]
 [93.294304]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  8.] 
cards in discard: [10. 11. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.0202407836914



action possibilites: [-1] 
expected returns: [[94.00032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [10. 11. 11.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.9504165649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[92.77236]
 [92.80879]
 [92.77169]
 [92.81301]
 [92.80361]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [10. 11. 11.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  9.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.00032043457031



buy possibilites: [-1] 
expected returns: [[78.09369]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [10. 11. 11.  0.  0.  0.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  8.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 92.81301879882812






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  8.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  8.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[112.18213]
 [112.24275]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [8. 0. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.09368896484375



action possibilites: [-1] 
expected returns: [[89.132484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  7.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [8. 0. 6. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.91035461425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[89.04428 ]
 [89.069565]
 [89.08072 ]
 [89.04361 ]
 [89.12893 ]
 [89.08494 ]
 [89.09635 ]
 [89.07553 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  7.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [8. 0. 6. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.13248443603516



buy possibilites: [-1] 
expected returns: [[77.18186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [8. 0. 6. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 89.1289291381836






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [8. 0. 6. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [11. 25.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [8. 0. 6. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [11. 25.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 8.  0.  6.  0.  3.  3.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [11. 25.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  8.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[75.49343]
 [75.50284]
 [75.51426]
 [75.50284]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  8.] 
cards in discard: [11. 25.  0.  3.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  1.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  3.  6. 14.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.1818618774414



action possibilites: [-1.  8.  8.] 
expected returns: [[82.605354]
 [82.61475 ]
 [82.61475 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 0.] 
cards in discard: [11. 25.  0.  3.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 11 10 11 10  8 11] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  1.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  3.  6. 14.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 75.27800750732422



action possibilites: [-1.] 
expected returns: [[98.65886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11. 25.  0.  3.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  1.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  3.  6. 14.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: trash_cards_n_from_hand - action 8
Learning step: 0
desired expected reward: 82.50658416748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[99.065445]
 [99.06479 ]
 [99.0967  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 25.  0.  3.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  1.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  3.  6. 14.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.65885925292969






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  1.] 
cards in discard: [ 8.  0.  6.  0.  3.  3.  6. 14.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 11. 11. 11.  0.] 
adversary cards in discard: [11. 25.  0.  3.  3.  0.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  1.] 
cards in discard: [ 8.  0.  6.  0.  3.  3.  6. 14.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 11. 11. 11.  0.] 
adversary cards in discard: [11. 25.  0.  3.  3.  0.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  1.] 
cards in discard: [ 8.  0.  6.  0.  3.  3.  6. 14.  0.  0.  0.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 11. 11. 11.  0.] 
adversary cards in discard: [11. 25.  0.  3.  3.  0.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 11. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[78.975365]
 [78.996185]
 [79.02876 ]
 [79.02876 ]
 [79.02876 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 11.  0.] 
cards in discard: [11. 25.  0.  3.  3.  0.  0.  3. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.09669494628906



action possibilites: [-1] 
expected returns: [[113.174126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.] 
cards in discard: [11. 25.  0.  3.  3.  0.  0.  3. 10.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.02056884765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.25075]
 [114.25008]
 [114.282  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  0.] 
cards in discard: [11. 25.  0.  3.  3.  0.  0.  3. 10.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.17412567138672






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11. 11.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11. 11.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [23.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 8. 11. 11.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[89.970825]
 [89.98023 ]
 [90.02423 ]
 [90.02423 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.] 
cards in discard: [3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8.  9.  7. 10. 10.] 
adversary cards in hand: [14.  1.  6.  3.  0.] 
adversary cards in discard: [23. 14.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_down_to_3_cards - action 3
Learning step: 0
desired expected reward: 134.92616271972656



action possibilites: [-1] 
expected returns: [[119.719475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.] 
cards in discard: [ 3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [14.  1.  6.  3.  0.] 
adversary cards in discard: [23. 14.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 90.45237731933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.04947]
 [119.0488 ]
 [119.08072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.] 
cards in discard: [ 3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [14.  1.  6.  3.  0.] 
adversary cards in discard: [23. 14.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.71947479248047






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [14.  1.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  6.  3.  0.] 
cards in discard: [23. 14.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [10. 25. 11.  3.  3.] 
adversary cards in discard: [ 3.  0. 10. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  6.  3.  0.] 
cards in discard: [23. 14.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [10. 25. 11.  3.  3.] 
adversary cards in discard: [ 3.  0. 10. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 25. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[89.32909 ]
 [89.34991 ]
 [89.38971 ]
 [89.382484]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 11.  3.  3.] 
cards in discard: [ 3.  0. 10. 11.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [23. 14.  0.  0.  0.  1. 14.  1.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.0807113647461



action possibilites: [-1] 
expected returns: [[114.32579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  3. 10.  0.] 
cards in discard: [ 3.  0. 10. 11.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [23. 14.  0.  0.  0.  1. 14.  1.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 89.4328842163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.89491]
 [115.89424]
 [115.92615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3. 10.  0.] 
cards in discard: [ 3.  0. 10. 11.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [23. 14.  0.  0.  0.  1. 14.  1.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.32579040527344






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [23. 14.  0.  0.  0.  1. 14.  1.  6.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [23. 14.  0.  0.  0.  1. 14.  1.  6.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [23. 14.  0.  0.  0.  1. 14.  1.  6.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[110.36534]
 [110.38617]
 [110.41875]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  7.  9. 10.  8.  9.  6. 10. 10.] 
adversary cards in hand: [8. 6. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 115.9261474609375



action possibilites: [-1] 
expected returns: [[111.77418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  7.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [8. 6. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 110.84689331054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[110.98581 ]
 [111.022255]
 [110.98514 ]
 [111.026474]
 [111.01705 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  7.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [8. 6. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.77417755126953



buy possibilites: [-1] 
expected returns: [[80.22764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [8. 6. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 111.02645874023438






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [8. 6. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1  1  6 14  8  6 14  1 23  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 25. 11. 11.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 25. 11. 11.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 25. 11. 11.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 10. 25. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11. 11.] 
expected returns: [[73.16435]
 [73.18518]
 [73.22498]
 [73.21775]
 [73.21775]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25. 11. 11.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.2276382446289



action possibilites: [-1] 
expected returns: [[63.412426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11.  0. 11.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.3181381225586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[65.62402 ]
 [65.62335 ]
 [65.655266]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 11.  0. 11.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.41242599487305






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  0. 10.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 25.  3. 10. 11. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  0. 10.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 25.  3. 10. 11. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [8. 3. 6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  0. 10.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 25.  3. 10. 11. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 8.  3. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[92.50386]
 [92.51326]
 [92.52469]
 [92.52469]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  0. 10.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 25.  3. 10. 11. 11.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  1. 14.] 
adversary cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.65526580810547



action possibilites: [-1.  8. 10. 11.] 
expected returns: [[93.92926 ]
 [93.93867 ]
 [93.95009 ]
 [93.982666]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  1. 14.] 
adversary cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 92.63069152832031



action possibilites: [-1.  8. 10.] 
expected returns: [[88.46753 ]
 [88.476944]
 [88.48836 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  1. 14.] 
adversary cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.93360900878906



action possibilites: [-1.  8. 11.] 
expected returns: [[97.16063 ]
 [97.17003 ]
 [97.214035]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  1. 14.] 
adversary cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 88.48835754394531



action possibilites: [-1.  8.] 
expected returns: [[101.80629]
 [101.81569]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11. 10. 11.] 
owned cards: [ 0  0  0  0  3  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  1. 14.] 
adversary cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.22257995605469



action possibilites: [-1] 
expected returns: [[78.49681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11. 10. 11.  8.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  1. 14.] 
adversary cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 101.44917297363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.30922 ]
 [80.308556]
 [80.34047 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11. 10. 11.  8.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  1. 14.] 
adversary cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.49681091308594






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  1. 14.] 
cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 14.] 
cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 14.] 
cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 14.] 
cards in discard: [8. 3. 6. 3. 3. 6. 3. 0. 0. 4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  6. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[88.72212]
 [88.78275]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  6. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [14.  6. 23.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 430   0] 
sum of rewards: 365 

action type: discard_down_to_3_cards - action 3
Learning step: 0
desired expected reward: 96.48275756835938



action possibilites: [-1] 
expected returns: [[78.217064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [14.  6. 23.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.79553985595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.98928]
 [79.02571]
 [78.98861]
 [79.02993]
 [79.02052]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  6.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [14.  6. 23.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.2170639038086



buy possibilites: [-1] 
expected returns: [[97.91797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  5.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [14.  6. 23.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 79.0299301147461






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [14.  6. 23.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 23.  1.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  5.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  8. 11. 10.] 
adversary cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.  8. 25.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 23.  1.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  5.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  8. 11. 10.] 
adversary cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.  8. 25.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 23.  1.  0.] 
cards in discard: [6. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  8. 11. 10.] 
adversary cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.  8. 25.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 10.] 
expected returns: [[71.324394]
 [71.3778  ]
 [71.33381 ]
 [71.3778  ]
 [71.34523 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8. 11. 10.] 
cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.  8. 25.  0.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  3. 10. 10.] 
adversary cards in hand: [4. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  8. 14.  6. 23.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.91796875



action possibilites: [-1] 
expected returns: [[79.13283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 10.] 
cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.  8. 25.  0.  0. 10. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  2. 10. 10.] 
adversary cards in hand: [4. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  8. 14.  6. 23.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.6700210571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[79.31288]
 [79.31222]
 [79.34413]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 10.] 
cards in discard: [10. 10. 10. 11. 10. 11.  8.  0.  0.  3.  8. 25.  0.  0. 10. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  2. 10. 10.] 
adversary cards in hand: [4. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  8. 14.  6. 23.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.13282775878906






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [4. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 6. 0. 3. 6.] 
cards in discard: [ 6.  8. 14.  6. 23.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  2. 10. 10.] 
adversary cards in hand: [11.  0. 10.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 0. 3. 6.] 
cards in discard: [ 6.  8. 14.  6. 23.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  2. 10. 10.] 
adversary cards in hand: [11.  0. 10.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 0. 3. 6.] 
cards in discard: [ 6.  8. 14.  6. 23.  1.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  2. 10. 10.] 
adversary cards in hand: [11.  0. 10.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 10.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 11.] 
expected returns: [[48.628624]
 [48.682026]
 [48.649452]
 [48.638027]
 [48.682026]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  8. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  8.  3.] 
adversary cards in discard: [ 6.  8. 14.  6. 23.  1.  0.  0.  4.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.3441390991211



action possibilites: [-1] 
expected returns: [[42.77298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  8.  3.] 
adversary cards in discard: [ 6.  8. 14.  6. 23.  1.  0.  0.  4.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.6738395690918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.417503]
 [43.416836]
 [43.448753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  8.  3.] 
adversary cards in discard: [ 6.  8. 14.  6. 23.  1.  0.  0.  4.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.772979736328125






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  3.] 
cards in discard: [ 6.  8. 14.  6. 23.  1.  0.  0.  4.  6.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10. 10. 10. 10.] 
adversary cards in discard: [10. 11.  0. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.] 
cards in discard: [ 6.  8. 14.  6. 23.  1.  0.  0.  4.  6.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10. 10. 10. 10.] 
adversary cards in discard: [10. 11.  0. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.] 
cards in discard: [ 6.  8. 14.  6. 23.  1.  0.  0.  4.  6.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10. 10. 10. 10.] 
adversary cards in discard: [10. 11.  0. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [10. 10. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10. 10.] 
expected returns: [[61.989918]
 [62.010742]
 [62.010742]
 [62.010742]
 [62.010742]
 [62.010742]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10. 10.] 
cards in discard: [10. 11.  0. 10.  8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.44874954223633



action possibilites: [-1. 10. 10. 10. 10.] 
expected returns: [[76.033714]
 [76.05454 ]
 [76.05454 ]
 [76.05454 ]
 [76.05454 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10.  0.] 
cards in discard: [10. 11.  0. 10.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 61.962196350097656



action possibilites: [-1. 10. 10. 10.  8.] 
expected returns: [[79.67472 ]
 [79.695564]
 [79.695564]
 [79.695564]
 [79.684135]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.  8.] 
cards in discard: [10. 11.  0. 10.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 76.0545425415039



action possibilites: [-1. 10. 10.  8. 11.] 
expected returns: [[70.58647]
 [70.60731]
 [70.60731]
 [70.59589]
 [70.63987]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8. 11.] 
cards in discard: [10. 11.  0. 10.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10] -> size -> 23 
action values: 4 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  1. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 79.695556640625



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[75.71445]
 [75.73528]
 [75.73528]
 [75.72386]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8.] 
cards in discard: [10. 11.  0. 10.  8. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10. 11.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 70.64960479736328



action possibilites: [-1. 10.  8.] 
expected returns: [[83.29126]
 [83.31209]
 [83.30066]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3.] 
cards in discard: [10. 11.  0. 10.  8. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 24 
action values: 4 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 75.73528289794922



action possibilites: [-1.  8. 25.] 
expected returns: [[77.145035]
 [77.154434]
 [77.20566 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 25.] 
cards in discard: [10. 11.  0. 10.  8. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10. 10. 11. 10. 10.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 24 
action values: 5 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  5. 10.  6.  4.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 83.31208038330078



action possibilites: [-1.  8.] 
expected returns: [[69.41415]
 [69.42355]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [10. 11.  0. 10.  8. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 10. 10. 11. 10. 10. 25.] 
owned cards: [ 0  0  0  0  3  3 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 24 
action values: 4 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  4.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.20565795898438



action possibilites: [-1.] 
expected returns: [[69.34894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 11.  0. 10.  8. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 10. 10. 11. 10. 10. 25.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 20 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  4.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 69.20669555664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.791954]
 [68.79129 ]
 [68.823204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11.  0. 10.  8. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 10. 10. 11. 10. 10. 25.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 20 
action values: 3 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  4.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 69.34893798828125






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  4.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10.  8. 11. 10. 10. 10. 10. 11. 10. 10. 25.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 20 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  4.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10.  8. 11. 10. 10. 10. 10. 11. 10. 10. 25.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 20 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [6. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  3.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10.  8. 11. 10. 10. 10. 10. 11. 10. 10. 25.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 20 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [10. 11.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 10.] 
expected returns: [[60.031353]
 [60.05218 ]
 [60.08475 ]
 [60.040756]
 [60.05218 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8. 10.  0.] 
cards in discard: [10. 11.  0. 10.  8. 11. 10. 10. 10. 10. 11. 10. 10. 25.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  3.  9. 10.  8.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  1. 14.  0.  4.] 
adversary cards in discard: [6. 8. 6. 0. 3. 1. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 68.82320404052734



action possibilites: [-1] 
expected returns: [[84.41365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [10. 11.  0. 10.  8. 11. 10. 10. 10. 10. 11. 10. 10. 25.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  3.  9. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  4.] 
adversary cards in discard: [6. 8. 6. 0. 3. 1. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 60.37697982788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.59852]
 [84.59785]
 [84.62976]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [10. 11.  0. 10.  8. 11. 10. 10. 10. 10. 11. 10. 10. 25.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  3.  9. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  4.] 
adversary cards in discard: [6. 8. 6. 0. 3. 1. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.41365051269531






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 14.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0.  4.] 
cards in discard: [6. 8. 6. 0. 3. 1. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  3.  9. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.  4.] 
cards in discard: [6. 8. 6. 0. 3. 1. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  6.  3.  9. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.  4.] 
cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [10. 10. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10.] 
expected returns: [[55.819508]
 [55.84033 ]
 [55.84033 ]
 [55.84033 ]
 [55.84033 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 84.6297607421875



action possibilites: [-1. 10. 10. 10.  8.] 
expected returns: [[53.952095]
 [53.972916]
 [53.972916]
 [53.972916]
 [53.961494]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 55.60407638549805



action possibilites: [-1. 10. 10.  8. 11.] 
expected returns: [[53.331367]
 [53.352192]
 [53.352192]
 [53.34078 ]
 [53.384773]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15] -> size -> 21 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 53.97291946411133



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[47.923405]
 [47.944233]
 [47.944233]
 [47.932808]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 59 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.323333740234375



action possibilites: [-1. 10.  8. 11.] 
expected returns: [[65.21213 ]
 [65.232956]
 [65.221535]
 [65.265526]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 47.94423294067383



action possibilites: [-1. 10.  8.] 
expected returns: [[51.749187]
 [51.770016]
 [51.758595]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.] 
cards in discard: [15. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10. 11. 10. 11.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15 15] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0 100   0   0   0   0   0   0   0  64   0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.25182342529297



action possibilites: [-1.  8. 15.] 
expected returns: [[35.74238]
 [35.75178]
 [35.74221]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.] 
cards in discard: [15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11. 10. 11. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15 15] -> size -> 23 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 51.770015716552734



action possibilites: [-1.] 
expected returns: [[32.01292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11. 10. 11. 10.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 75 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 35.25684356689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.124462]
 [33.123795]
 [33.155712]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11. 10. 11. 10.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  6.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.01292037963867






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6.  0. 14.] 
cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [25. 10. 11.  0. 11.] 
adversary cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  6.  0. 14.] 
cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [25. 10. 11.  0. 11.] 
adversary cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  6.  0. 14.] 
cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [25. 10. 11.  0. 11.] 
adversary cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [25. 10. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 11.] 
expected returns: [[40.005672]
 [40.0663  ]
 [40.026493]
 [40.059067]
 [40.059067]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11.  0. 11.] 
cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  4.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [8. 3. 0. 6. 6.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.  0.  8.  3.  6.  0.
 14.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0] -> size -> 25 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.15571212768555



action possibilites: [-1] 
expected returns: [[27.53034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 11. 10. 10.] 
cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [8. 3. 0. 6. 6.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.  0.  8.  3.  6.  0.
 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.2645149230957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.17382 ]
 [31.173153]
 [31.205069]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 11. 10. 10.] 
cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [8. 3. 0. 6. 6.] 
adversary cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.  0.  8.  3.  6.  0.
 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.53034019470215






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 6.] 
cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.  0.  8.  3.  6.  0.
 14.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 10.  8. 10. 10.] 
adversary cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0. 25. 10. 11.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 6.] 
cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.  0.  8.  3.  6.  0.
 14.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 10.  8. 10. 10.] 
adversary cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0. 25. 10. 11.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 6.] 
cards in discard: [ 6.  8.  6.  0.  3.  1.  3. 16.  0.  1. 14.  0.  4.  0.  8.  3.  6.  0.
 14.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 10.  8. 10. 10.] 
adversary cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0. 25. 10. 11.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 8. 10.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 10. 10.] 
expected returns: [[39.712265]
 [39.721676]
 [39.733097]
 [39.721676]
 [39.733097]
 [39.733097]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8. 10. 10.] 
cards in discard: [15. 15. 10. 10. 11. 10. 11. 10.  8.  0. 25. 10. 11.  0. 11. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.205068588256836



action possibilites: [-1.  8.  8. 10. 10. 10.] 
expected returns: [[45.001057]
 [45.010456]
 [45.010456]
 [45.021877]
 [45.021877]
 [45.021877]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 39.73309326171875



action possibilites: [-1.  8.  8. 10. 10. 10.] 
expected returns: [[47.669094]
 [47.6785  ]
 [47.6785  ]
 [47.689922]
 [47.689922]
 [47.689922]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 45.02187728881836



action possibilites: [-1.  8.  8. 10. 10. 10.] 
expected returns: [[43.39942]
 [43.40882]
 [43.40882]
 [43.42024]
 [43.42024]
 [43.42024]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 4 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 47.689918518066406



action possibilites: [-1.  8.  8. 10. 10. 11.] 
expected returns: [[53.355045]
 [53.36445 ]
 [53.36445 ]
 [53.375874]
 [53.375874]
 [53.408443]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 10. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15] -> size -> 22 
action values: 5 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  7.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 43.42024230957031



action possibilites: [-1.  8.  8. 10. 10.] 
expected returns: [[45.35636 ]
 [45.365765]
 [45.365765]
 [45.37719 ]
 [45.37719 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 10.] 
cards in discard: [15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10. 10. 10. 11.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15 15] -> size -> 23 
action values: 4 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  6.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0  64   0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.41817092895508



action possibilites: [-1.  8.  8. 10. 25.] 
expected returns: [[30.684195]
 [30.693598]
 [30.693598]
 [30.705017]
 [30.744822]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 25.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 10. 10. 11. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15 15] -> size -> 23 
action values: 5 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  3.  9.  6.  3.  9. 10.  8.  9.  0. 10.  6.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 45.3771858215332



action possibilites: [-1.  8.  8. 10.  8. 11.] 
expected returns: [[73.88435]
 [73.89377]
 [73.89377]
 [73.90518]
 [73.89377]
 [73.93776]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  8. 11.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 10. 10. 11. 10. 25.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15 15] -> size -> 23 
action values: 4 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  6.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.744823455810547



action possibilites: [-1.  8.  8. 10.  8.] 
expected returns: [[54.16538 ]
 [54.17478 ]
 [54.17478 ]
 [54.186203]
 [54.17478 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  8.] 
cards in discard: [15. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 10. 10. 11. 10. 25. 11.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15 15 15] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  5.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0 160   0   0   0   0   0   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 73.88801574707031



action possibilites: [-1.  8.  8.  8. 11.] 
expected returns: [[69.26125]
 [69.27065]
 [69.27065]
 [69.27065]
 [69.31465]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 11.] 
cards in discard: [15. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10. 10. 11. 10. 25. 11. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15 15 15] -> size -> 24 
action values: 4 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  5.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0 180   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 54.18620300292969



action possibilites: [-1.  8.  8.  8.] 
expected returns: [[84.45556]
 [84.46495]
 [84.46495]
 [84.46495]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [15. 15. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10. 10. 11. 10. 25. 11. 10. 11.] 
owned cards: [ 0  0 25 11 11 10 11 10  8 11 10 10 10  8 10 10  8 10 10 10 15 15 15 15
 15] -> size -> 25 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  4.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0 200   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 69.30322265625



action possibilites: [-1.] 
expected returns: [[21.69837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 15. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10. 10. 11. 10. 25. 11. 10. 11.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  4.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0 220   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 84.52251434326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.583935]
 [26.583265]
 [26.615183]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 15. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10. 10. 11. 10. 25. 11. 10. 11.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15] -> size -> 23 
action values: 2 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  4.] 
adversary cards in hand: [14.  3.  3.  0. 23.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0 220   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.6983699798584






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [14.  3.  3.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0. 23.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10. 10. 10. 15.] 
adversary cards in discard: [15. 15. 15. 10. 10. 10. 10. 11. 10. 25. 11. 10. 11.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15] -> size -> 23 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0. 23.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10. 10. 10. 15.] 
adversary cards in discard: [15. 15. 15. 10. 10. 10. 10. 11. 10. 25. 11. 10. 11.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15] -> size -> 23 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0. 23.] 
cards in discard: [6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10. 10. 10. 15.] 
adversary cards in discard: [15. 15. 15. 10. 10. 10. 10. 11. 10. 25. 11. 10. 11.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15] -> size -> 23 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [11. 10. 10. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10. 15.] 
expected returns: [[42.261093]
 [42.314487]
 [42.281918]
 [42.281918]
 [42.281918]
 [42.26093 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 10. 15.] 
cards in discard: [15. 15. 15. 10. 10. 10. 10. 11. 10. 25. 11. 10. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0.  8. 14.  6.  1.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.61518096923828



action possibilites: [-1] 
expected returns: [[27.526522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 15.] 
cards in discard: [15. 15. 15. 10. 10. 10. 10. 11. 10. 25. 11. 10. 11.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  3.] 
adversary cards in hand: [ 0.  8. 14.  6.  1.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.303070068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.706585]
 [27.705915]
 [27.73783 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 15.] 
cards in discard: [15. 15. 15. 10. 10. 10. 10. 11. 10. 25. 11. 10. 11.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  3.] 
adversary cards in hand: [ 0.  8. 14.  6.  1.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.] 
adversary owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.526521682739258






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  6.  1.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  1 14  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16
  0  6  0  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  3.] 
adversary cards in hand: [11. 15. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  3.] 
adversary cards in hand: [11. 15. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  3.] 
adversary cards in hand: [11. 15. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [11. 15. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
expected returns: [[46.293667]
 [46.347065]
 [46.293503]
 [46.314495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  3.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.737829208374023



action possibilites: [-1] 
expected returns: [[45.317883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.28481674194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[45.73537 ]
 [45.77181 ]
 [45.734703]
 [45.776028]
 [45.766613]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  3.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.3178825378418



buy possibilites: [-1] 
expected returns: [[57.80313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [15.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 45.77602005004883






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 6.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [10. 15. 10. 15. 15.] 
adversary cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 6.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [10. 15. 10. 15. 15.] 
adversary cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 15. 10. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 15. 15.] 
expected returns: [[36.20638 ]
 [36.227203]
 [36.20621 ]
 [36.227203]
 [36.20621 ]
 [36.20621 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 15. 15.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.803131103515625



action possibilites: [-1. 15. 10. 15. 15. 15.] 
expected returns: [[26.423609]
 [26.423443]
 [26.444439]
 [26.423443]
 [26.423443]
 [26.423443]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15. 15. 15.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 36.227203369140625



action possibilites: [-1. 15. 15. 15. 15. 25.] 
expected returns: [[43.52934]
 [43.52917]
 [43.52917]
 [43.52917]
 [43.52917]
 [43.58997]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15. 25.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  2.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 26.444435119628906



action possibilites: [-1. 15. 15. 15. 15. 10. 10.] 
expected returns: [[43.929676]
 [43.929512]
 [43.929512]
 [43.929512]
 [43.929512]
 [43.95051 ]
 [43.95051 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15. 10. 10.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 25.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.589969635009766



action possibilites: [-1. 15. 15. 15. 15. 10. 10.] 
expected returns: [[47.42984 ]
 [47.429676]
 [47.429676]
 [47.429676]
 [47.429676]
 [47.450672]
 [47.450672]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15. 10. 10.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 25. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 43.95050811767578



action possibilites: [-1. 15. 15. 15. 15. 10. 10.] 
expected returns: [[58.240757]
 [58.24058 ]
 [58.24058 ]
 [58.24058 ]
 [58.24058 ]
 [58.26158 ]
 [58.26158 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15. 10. 10.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 4 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 47.4506721496582



action possibilites: [-1. 15. 15. 15. 15. 10.  8.] 
expected returns: [[48.010334]
 [48.010174]
 [48.010174]
 [48.010174]
 [48.010174]
 [48.031162]
 [48.01974 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15. 10.  8.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 5 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 58.2615852355957



action possibilites: [-1. 15. 15. 15. 15.  8. 11.] 
expected returns: [[42.68319 ]
 [42.68302 ]
 [42.68302 ]
 [42.68302 ]
 [42.68302 ]
 [42.692593]
 [42.73659 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15.  8. 11.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8] -> size -> 26 
action values: 6 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 48.031166076660156



action possibilites: [-1. 15. 15. 15. 15.  8.] 
expected returns: [[66.785576]
 [66.7854  ]
 [66.7854  ]
 [66.7854  ]
 [66.7854  ]
 [66.79498 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15.  8.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10. 10. 10. 11.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15 15 15 15
 15  8 15] -> size -> 27 
action values: 5 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  1.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0 160   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.72517013549805



action possibilites: [-1.] 
expected returns: [[53.507336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  8. 11. 15. 10.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10. 10. 10. 11.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15] -> size -> 23 
action values: 4 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  1.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: trash_cards_n_from_hand - action 3
Learning step: 0
desired expected reward: 67.29835510253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.41733 ]
 [54.41666 ]
 [54.448578]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  8. 11. 15. 10.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10. 10. 10. 11.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15] -> size -> 23 
action values: 4 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  1.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0 180   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.5073356628418






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 6.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  1.] 
adversary cards in hand: [11. 10. 15. 10. 11.] 
adversary cards in discard: [15.  8. 11. 15. 10.  0.  0. 15. 10. 10. 25. 10. 10. 10. 10. 11.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15] -> size -> 23 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  1.] 
adversary cards in hand: [11. 10. 15. 10. 11.] 
adversary cards in discard: [15.  8. 11. 15. 10.  0.  0. 15. 10. 10. 25. 10. 10. 10. 10. 11.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15] -> size -> 23 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  1.] 
adversary cards in hand: [11. 10. 15. 10. 11.] 
adversary cards in discard: [15.  8. 11. 15. 10.  0.  0. 15. 10. 10. 25. 10. 10. 10. 10. 11.  8.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15] -> size -> 23 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [11. 10. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 10. 11.] 
expected returns: [[59.630157]
 [59.68355 ]
 [59.65098 ]
 [59.629982]
 [59.65098 ]
 [59.68355 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15. 10. 11.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0. 15. 10. 10. 25. 10. 10. 10. 10. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  1.] 
adversary cards in hand: [3. 0. 0. 1. 8.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.  8.  3.  0.
  6.] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6] -> size -> 26 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.44858169555664



action possibilites: [-1] 
expected returns: [[29.37586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 11.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0. 15. 10. 10. 25. 10. 10. 10. 10. 11.  8. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [3. 0. 0. 1. 8.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.  8.  3.  0.
  6.] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6] -> size -> 26 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 59.6721305847168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.469332]
 [29.468662]
 [29.500578]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10. 11.] 
cards in discard: [15.  8. 11. 15. 10.  0.  0. 15. 10. 10. 25. 10. 10. 10. 10. 11.  8. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [3. 0. 0. 1. 8.] 
adversary cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.  8.  3.  0.
  6.] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6] -> size -> 26 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.3758602142334






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 8.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.  8.  3.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [15. 10.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 8.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.  8.  3.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [15. 10.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 8.] 
cards in discard: [ 6.  0. 14.  3.  3.  0. 23.  8.  6.  6.  0.  6.  6.  6.  6.  8.  3.  0.
  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [15. 10.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [15. 10.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8. 10. 10.] 
expected returns: [[28.678915]
 [28.678747]
 [28.69974 ]
 [28.688322]
 [28.69974 ]
 [28.69974 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.500577926635742



action possibilites: [-1. 15.  8. 10. 10. 10.] 
expected returns: [[27.812725]
 [27.81256 ]
 [27.82213 ]
 [27.833551]
 [27.833551]
 [27.833551]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 28.805757522583008



action possibilites: [-1. 15.  8. 10. 10. 15.] 
expected returns: [[21.257103]
 [21.256937]
 [21.266512]
 [21.27793 ]
 [21.27793 ]
 [21.256937]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10. 10. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 27.833553314208984



action possibilites: [-1. 15.  8. 10. 15. 10.] 
expected returns: [[19.668406]
 [19.668238]
 [19.67781 ]
 [19.689232]
 [19.668238]
 [19.689232]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10. 15. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 4 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 21.277929306030273



action possibilites: [-1. 15.  8. 15. 10. 15.] 
expected returns: [[18.646238]
 [18.64614 ]
 [18.65564 ]
 [18.64614 ]
 [18.66692 ]
 [18.64614 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 15. 10. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 5 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 19.689231872558594



action possibilites: [-1. 15.  8. 15. 15. 10.] 
expected returns: [[28.39621 ]
 [28.396044]
 [28.405615]
 [28.396044]
 [28.396044]
 [28.417036]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 15. 15. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10. 10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 6 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 18.666921615600586



action possibilites: [-1. 15.  8. 15. 15. 10.] 
expected returns: [[34.634144]
 [34.633976]
 [34.64355 ]
 [34.633976]
 [34.633976]
 [34.65497 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 15. 15. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10. 10. 10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 7 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  30   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 28.417036056518555



action possibilites: [-1. 15.  8. 15. 15.] 
expected returns: [[28.649012]
 [28.648848]
 [28.658419]
 [28.648848]
 [28.648848]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 15. 15.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 10. 10. 10. 10. 10.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15 15 15  8 15 15] -> size -> 24 
action values: 8 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  30   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 34.65496826171875



action possibilites: [-1. 15.] 
expected returns: [[21.139444]
 [21.139277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 10. 10. 10. 10. 10.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15  8 15 15] -> size -> 22 
action values: 7 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  30   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: trash_cards_n_from_hand - action 3
Learning step: 0
desired expected reward: 28.300302505493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.521933]
 [24.521263]
 [24.55318 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 10. 10. 10. 10. 10.  8.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15  8 15 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  30   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.13944435119629






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 16.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  4.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  4  6  8  0  6  8 16  0  6  0  6
  0  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 25. 15. 11. 10.] 
adversary cards in discard: [10. 10. 10. 10. 10. 10. 10.  8. 15.  0.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15  8 15 15] -> size -> 22 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  6  8  0  6  8 16  0  6  0  6  0
  6  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 25. 15. 11. 10.] 
adversary cards in discard: [10. 10. 10. 10. 10. 10. 10.  8. 15.  0.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15  8 15 15] -> size -> 22 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  6  8  0  6  8 16  0  6  0  6  0
  6  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 28. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 25. 15. 11. 10.] 
adversary cards in discard: [10. 10. 10. 10. 10. 10. 10.  8. 15.  0.] 
adversary owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15  8 15 15] -> size -> 22 
adversary victory points: 0
player victory points: -3 





Player: 0 
cards in hand: [10. 25. 15. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 15. 11. 10.] 
expected returns: [[16.828154]
 [16.848265]
 [16.88673 ]
 [16.827997]
 [16.879755]
 [16.848265]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 15. 11. 10.] 
cards in discard: [10. 10. 10. 10. 10. 10. 10.  8. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15  8 15 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  1.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 6.  1.  3.  0. 14.] 
adversary cards in discard: [ 3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  6  8  0  6  8 16  0  6  0  6  0
  6  0  3] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.553178787231445



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 4 
Chapel: 5 
Witch: 1 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10. 15. 11. 10. 11. 11.] 
cards in discard: [10. 10. 10. 10. 10. 10. 10.  8. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 11 10 11 10 11 10 10 10 10 10  8 10 10 10 15  8 15 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  0.  9.  6.  2.  9. 10.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 6.  1.  3.  0. 14.] 
adversary cards in discard: [ 3. 16.  0.  3.  3.  6.] 
adversary owned cards: [ 0  3  3  3  0  8  6 14  1 23  6  6  3  6  8  0  6  8 16  0  6  0  6  0
  6  0  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000105 

action type: take_action - action 25.0
Learning step: 120003.515625
desired expected reward: 120020.40625



