 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[334.50647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   3  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 538 

action type: buy - action -1.0
Learning step: 14.349753379821777
desired expected reward: 265.3547058105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[311.98193]
 [321.24677]
 [319.56927]
 [299.94888]
 [316.32114]
 [331.02863]
 [322.70798]
 [328.80072]
 [311.78043]
 [321.22827]
 [322.07816]
 [337.81863]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.670578002929688
desired expected reward: 327.66473388671875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[376.2718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.493023872375488
desired expected reward: 329.3255920410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[344.81323]
 [353.98062]
 [352.4633 ]
 [332.61877]
 [364.3696 ]
 [355.40594]
 [354.09042]
 [372.43283]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.930514335632324
desired expected reward: 366.7542419433594



buy possibilites: [-1] 
expected returns: [[351.7827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -10.925551414489746
desired expected reward: 333.8876953125






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[329.04202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.264928817749023
desired expected reward: 341.5177917480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[312.34555]
 [319.19446]
 [317.56976]
 [303.05856]
 [315.48648]
 [326.37524]
 [320.3919 ]
 [324.74713]
 [311.86392]
 [318.8838 ]
 [319.35538]
 [331.42355]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.368888854980469
desired expected reward: 320.59588623046875



buy possibilites: [-1] 
expected returns: [[304.03775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -7.433476448059082
desired expected reward: 308.05303955078125






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0. 10.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.8173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.723259925842285
desired expected reward: 296.3144836425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[312.6064 ]
 [321.96945]
 [320.47232]
 [300.32773]
 [332.63577]
 [323.3902 ]
 [322.10504]
 [340.949  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.604462623596191
desired expected reward: 327.22344970703125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[329.37576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  8.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.175909996032715
desired expected reward: 330.7730407714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[298.901  ]
 [307.33752]
 [305.83353]
 [287.74567]
 [318.3467 ]
 [308.73526]
 [307.50583]
 [327.20932]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  8.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.182013511657715
desired expected reward: 321.8863525390625



buy possibilites: [-1] 
expected returns: [[324.1338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  8.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 8.0
Learning step: -8.643754959106445
desired expected reward: 300.0915222167969






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  8.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [3. 3. 0. 0. 3. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [3. 3. 0. 0. 3. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [3. 3. 0. 0. 3. 0. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [16.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[350.98285]
 [323.14883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.660677909851074
desired expected reward: 315.4731140136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[323.521  ]
 [333.7653 ]
 [331.98947]
 [310.10333]
 [345.54395]
 [335.3884 ]
 [333.82532]
 [354.76654]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.018755912780762
desired expected reward: 340.6100158691406



buy possibilites: [-1] 
expected returns: [[328.67392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [ 8.  0.  3.  3.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -9.082035064697266
desired expected reward: 336.4619140625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 10.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[325.1588]
 [308.735 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.346479415893555
desired expected reward: 319.32745361328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[288.02438]
 [297.56552]
 [295.61414]
 [275.71152]
 [307.91132]
 [299.0853 ]
 [297.28577]
 [315.40976]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.085206031799316
desired expected reward: 306.1473083496094



buy possibilites: [-1] 
expected returns: [[307.6448]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -7.673558235168457
desired expected reward: 300.2377624511719






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [ 8.  0.  0.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 11 10  3  6  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [11.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8.  0.  0.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [11.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  0.  0.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [11.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  0.  0.  3. 10. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [11.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[345.73373]
 [325.84222]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [11.  3.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 10. 10.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.865890026092529
desired expected reward: 299.7789306640625



action possibilites: [-1] 
expected returns: [[322.8839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  3.  8.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 10. 10.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 33 

action type: gain_card_n - action 1
Learning step: -6.400249004364014
desired expected reward: 299.9024963378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[300.9409 ]
 [289.36508]
 [327.2973 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  3.  8.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 10. 10.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -7.704390048980713
desired expected reward: 315.1795349121094






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 10. 10.  0.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 10. 10.  0.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 10. 10.  0.  8.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[293.3312]
 [286.4253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -9.852633476257324
desired expected reward: 317.4446716308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[267.05557]
 [276.06982]
 [274.34174]
 [255.68564]
 [285.40637]
 [277.47897]
 [275.9318 ]
 [292.13425]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.48211669921875
desired expected reward: 285.8130187988281



buy possibilites: [-1] 
expected returns: [[294.74054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -8.27111530303955
desired expected reward: 258.784423828125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 10 11 10  3  6  0  8  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  8.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  8.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  8.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[286.8764 ]
 [265.95892]
 [271.5865 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  8.] 
cards in discard: [ 0.  3. 11.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  8 11 11  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -8.080347061157227
desired expected reward: 286.6601867675781



action possibilites: [-1] 
expected returns: [[319.17847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  3. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: gain_card_n - action 0
Learning step: -7.6300201416015625
desired expected reward: 287.6007080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[293.0911 ]
 [282.70575]
 [319.25027]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  3. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -7.690946102142334
desired expected reward: 311.4875183105469






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [10. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [8. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [8. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[286.69485]
 [280.33823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 0.  3. 11.  0.  0.  0.  0. 16.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 8.  3.  3. 10. 10.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -9.565503120422363
desired expected reward: 309.6847839355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[263.45645]
 [270.78134]
 [269.46066]
 [254.69165]
 [279.0211 ]
 [271.9585 ]
 [270.80258]
 [285.3044 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 0.  3. 11.  0.  0.  0.  0. 16.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 8.  3.  3. 10. 10.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.256059646606445
desired expected reward: 279.143798828125



buy possibilites: [-1] 
expected returns: [[259.73154]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 0.  3. 11.  0.  0.  0.  0. 16.  3.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 8.  3.  3. 10. 10.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 17 

action type: buy - action 1.0
Learning step: -6.845109462738037
desired expected reward: 263.9362487792969






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [ 8.  3.  3. 10. 10.  3.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 10 10  3  6  0  8  0  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1] -> size -> 17 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 8.  3.  3. 10. 10.  3.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  8 10 10  3  6  0  8  0  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1] -> size -> 17 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 8.  3.  3. 10. 10.  3.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  8 10 10  3  6  0  8  0  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1] -> size -> 17 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 8.  3.  3. 10. 10.  3.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  8 10 10  3  6  0  8  0  3  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1] -> size -> 17 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[276.0759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 10 10  3  6  0  8  0  3  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -6.807176113128662
desired expected reward: 252.9243621826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[252.30359]
 [260.06915]
 [258.7651 ]
 [242.15665]
 [255.93784]
 [268.96295]
 [261.26   ]
 [266.7927 ]
 [252.14447]
 [260.13284]
 [260.84988]
 [275.72723]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 26. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 10 10  3  6  0  8  0  3  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -7.971141338348389
desired expected reward: 268.89111328125



buy possibilites: [-1] 
expected returns: [[277.15692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 10 10  3  6  0  8  0  3  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 12.0 

action type: buy - action 3.0
Learning step: -6.102224826812744
desired expected reward: 252.6628875732422






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10 10  3  6  0  8  0  3  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  8 10 10  3  6  0  8  0  3  3  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 10 10  3  6  8  0  3  3  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 10 10  3  6  8  0  3  3  0] -> size -> 11 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[322.3103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  3.  3.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: -5.6055006980896
desired expected reward: 271.5514221191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[297.93872]
 [307.37146]
 [305.70258]
 [285.3458 ]
 [319.02115]
 [308.8664 ]
 [307.3583 ]
 [328.0843 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  3.  3.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -8.09472370147705
desired expected reward: 314.23175048828125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  3.  3.] 
cards in discard: [ 0. 10.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 16. 11.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3. 0.] 
cards in discard: [ 0. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 16. 11.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 0.] 
cards in discard: [ 0. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 16. 11.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 1. 16. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
expected returns: [[324.06708]
 [305.75906]
 [318.21173]
 [318.21173]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 11.  0. 11.] 
cards in discard: [3. 3. 0. 0. 0. 0. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  9.  9.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1.0
Learning step: -8.18089771270752
desired expected reward: 319.90338134765625



action possibilites: [-1] 
expected returns: [[280.81348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0. 11.] 
cards in discard: [ 3.  3.  0.  0.  0.  0.  3.  0.  0.  3.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 56 

action type: gain_card_n - action 4
Learning step: -5.747523784637451
desired expected reward: 291.5690002441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[261.6439 ]
 [269.8716 ]
 [268.1225 ]
 [250.15553]
 [278.85455]
 [271.2157 ]
 [269.69653]
 [285.61053]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0. 11.] 
cards in discard: [ 3.  3.  0.  0.  0.  0.  3.  0.  0.  3.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 25. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1
Learning step: -5.897706031799316
desired expected reward: 274.915771484375



buy possibilites: [-1] 
expected returns: [[246.04565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0. 11.] 
cards in discard: [ 3.  3.  0.  0.  0.  0.  3.  0.  0.  3.  0. 16.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 58 

action type: buy - action 1.0
Learning step: -5.057552337646484
desired expected reward: 264.81402587890625






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10 10  3  6  8  0  3  3  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1] -> size -> 20 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 10  3  6  8  3  3  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1] -> size -> 20 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 10  3  6  8  3  3  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 25. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1] -> size -> 20 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 25. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1] -> size -> 20 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 0.  1. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[258.86188]
 [251.68109]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3.  6. 10.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: -5.481307506561279
desired expected reward: 240.56434631347656



action possibilites: [-1] 
expected returns: [[255.26294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3.  6. 10.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 49 

action type: gain_card_n - action 5
Learning step: -3.6123039722442627
desired expected reward: 232.50209045410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[233.38031]
 [241.12096]
 [239.78867]
 [223.16068]
 [237.02525]
 [250.10562]
 [242.30188]
 [247.81656]
 [233.16743]
 [241.13892]
 [241.82394]
 [257.61606]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3.  6. 10.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1
Learning step: -5.262249946594238
desired expected reward: 250.0006866455078






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 10.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [11. 11.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 3. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [11. 11.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 3. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 2 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [11. 11.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[240.76276]
 [235.97813]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [11. 11.  0.  1.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1.0
Learning step: -6.2097601890563965
desired expected reward: 245.222900390625



action possibilites: [-1] 
expected returns: [[272.78333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: gain_card_n - action 0
Learning step: -4.4790191650390625
desired expected reward: 217.85386657714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[248.69823]
 [257.23862]
 [255.58087]
 [237.41919]
 [266.61487]
 [258.63593]
 [257.16788]
 [273.68774]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1
Learning step: -5.7748236656188965
desired expected reward: 267.0085144042969



buy possibilites: [-1] 
expected returns: [[273.55078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 58 

action type: buy - action 10.0
Learning step: -3.803501844406128
desired expected reward: 253.3643798828125






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0.  0.] 
adversary cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10] -> size -> 23 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0.  0.] 
adversary cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10] -> size -> 23 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[195.76593]
 [177.47182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0.  0.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  8.  3.] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: -8.501006126403809
desired expected reward: 265.0497741699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[175.6486 ]
 [183.01529]
 [181.6436 ]
 [166.95306]
 [191.46797]
 [184.1982 ]
 [182.99023]
 [197.90341]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0.  0.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 25. 30.  8.  9.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  8.  3.] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -4.442587852478027
desired expected reward: 188.25047302246094



buy possibilites: [-1] 
expected returns: [[180.20685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0.  0.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  8.  3.] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -291.0 

action type: buy - action 6.0
Learning step: -18.843000411987305
desired expected reward: 148.1100616455078






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [6. 8. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 3. 3.] 
cards in discard: [ 0.  0. 10.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 16.  3.  3.  0.] 
adversary cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.  6. 16.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6] -> size -> 24 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 3. 3.] 
cards in discard: [ 0.  0. 10.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 16.  3.  3.  0.] 
adversary cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.  6. 16.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6] -> size -> 24 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 16.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[230.54317]
 [205.55267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  3.  3.  0.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.  6. 16.  0.  3.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -3.693016767501831
desired expected reward: 176.51382446289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[200.0208 ]
 [209.16933]
 [207.77887]
 [189.1265 ]
 [219.89586]
 [210.53897]
 [209.36697]
 [228.5334 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.  3.  0.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.  6. 16.  0.  3.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.042327880859375
desired expected reward: 219.92527770996094



buy possibilites: [-1] 
expected returns: [[241.56708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.  3.  0.] 
cards in discard: [11. 11.  0.  1.  3.  0.  0. 10. 11.  0.  0.  0.  3.  6. 16.  0.  3.  0.
  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 27 

action type: buy - action 1.0
Learning step: -3.673207998275757
desired expected reward: 205.4961395263672






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1] -> size -> 25 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1] -> size -> 25 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 10  3  6  8  3  3  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1] -> size -> 25 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 10  3  6  8  3  3  0] -> size -> 9 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1] -> size -> 25 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1] -> size -> 25 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [16. 11.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 10.] 
expected returns: [[203.80804]
 [187.42218]
 [198.19196]
 [190.81094]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  1. 10.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.236808776855469
desired expected reward: 234.33026123046875



action possibilites: [-1] 
expected returns: [[241.37225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1. 10.  0.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 38 

action type: gain_card_n - action 1
Learning step: -2.121811628341675
desired expected reward: 186.9319305419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[219.43109]
 [227.38936]
 [225.97496]
 [208.91293]
 [236.57481]
 [228.59793]
 [227.34723]
 [244.78381]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1. 10.  0.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -5.4150896072387695
desired expected reward: 235.95716857910156



buy possibilites: [-1] 
expected returns: [[247.11386]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1. 10.  0.] 
cards in discard: [1. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: -5.295766830444336
desired expected reward: 214.13534545898438






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  8.  6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10  3  6  8  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  3.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 6 8 3 3 0 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  3.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 6 8 3 3 0 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  3.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[171.21396]
 [153.95895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  3.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 8.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [8 3 6 8 3 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -7.7349066734313965
desired expected reward: 239.3789520263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[149.94968]
 [140.88264]
 [170.92935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  3.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 8.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [8 3 6 8 3 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -3.9952971935272217
desired expected reward: 165.88583374023438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 8.] 
cards in discard: [8. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 6 8 3 3 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 8.] 
cards in discard: [8. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 6 8 3 3 0 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 8.] 
cards in discard: [8. 0. 6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 6 8 3 3 0 0 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[141.32886]
 [137.75992]
 [137.75992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 6 8 3 3 0 0 0] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -4.506531715393066
desired expected reward: 166.42282104492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[123.93969]
 [127.46256]
 [118.10212]
 [128.99323]
 [136.97708]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  8.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 6 8 3 3 0 0 0] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -3.0995566844940186
desired expected reward: 136.07835388183594



buy possibilites: [-1] 
expected returns: [[116.43314]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 6 8 3 3 0 0 0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -292.0 

action type: buy - action 6.0
Learning step: -17.885360717773438
desired expected reward: 100.21675872802734






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 6 8 3 3 0 0 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 0 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[147.29456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -1.6449463367462158
desired expected reward: 114.78820037841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[138.2645 ]
 [142.72887]
 [141.71751]
 [132.47577]
 [147.46864]
 [143.47414]
 [142.54242]
 [150.9973 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -3.133314847946167
desired expected reward: 142.498291015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.
  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.
  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.
  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [1. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[157.06387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.
  3.  0.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 3] -> size -> 6 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -3.6581249237060547
desired expected reward: 147.3391876220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[130.8259 ]
 [136.14645]
 [129.24403]
 [135.08296]
 [125.77532]
 [123.71625]
 [133.31743]
 [141.8785 ]
 [136.98041]
 [146.30959]
 [140.44815]
 [130.51181]
 [132.6914 ]
 [136.0185 ]
 [126.83137]
 [136.37184]
 [146.54945]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [ 1.  0. 11. 16.  1. 10.  0.  3.  3. 16.  0.  3.  6.  3.  0. 11. 11.  0.
  3.  0.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 7 
card supply: [18. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 3] -> size -> 6 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -4.270310401916504
desired expected reward: 150.9181671142578



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 3 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[184.72372]
 [179.4013 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -2.850611448287964
desired expected reward: 143.69882202148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[166.70003]
 [172.95514]
 [171.81635]
 [158.37086]
 [179.89441]
 [173.91705]
 [172.91469]
 [185.18866]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -4.8159403800964355
desired expected reward: 178.48097229003906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [8. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 3 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[197.21039]
 [192.08945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  3.] 
cards in discard: [11.  3.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -3.486898899078369
desired expected reward: 181.7017364501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[178.07104]
 [183.29648]
 [169.3526 ]
 [185.82672]
 [196.98407]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  3.] 
cards in discard: [11.  3.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -4.233444690704346
desired expected reward: 192.08946228027344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 24. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[197.88043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -4.50999641418457
desired expected reward: 192.47409057617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[179.796  ]
 [187.38557]
 [186.0182 ]
 [172.60359]
 [169.69382]
 [183.36021]
 [195.82108]
 [188.55086]
 [201.60487]
 [193.75201]
 [179.49672]
 [182.74904]
 [187.34953]
 [174.27753]
 [187.96825]
 [202.23576]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 26. 30. 23. 30.  8.  7.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -4.701891899108887
desired expected reward: 192.59625244140625



buy possibilites: [-1] 
expected returns: [[237.19992]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  7.  8.  6.  7.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 68 

action type: buy - action 25.0
Learning step: -1.217187523841858
desired expected reward: 200.38766479492188






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  7.  8.  6.  7.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  1.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 23. 30.  8.  7.  8.  6.  7.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  1.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25] -> size -> 29 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  7.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  1.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25] -> size -> 29 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[226.00952]
 [216.59177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  7.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -6.430764198303223
desired expected reward: 230.76914978027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[206.58997]
 [211.54884]
 [209.84143]
 [199.8266 ]
 [208.67316]
 [216.94069]
 [212.59474]
 [215.84392]
 [205.89037]
 [210.9707 ]
 [211.25955]
 [220.38844]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  7.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -6.166130542755127
desired expected reward: 221.0033416748047



buy possibilites: [-1] 
expected returns: [[178.25502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  6.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 10.0 

action type: buy - action 8.0
Learning step: -6.119000434875488
desired expected reward: 206.4757537841797






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  6.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  1. 16.  1.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.  8. 10.
  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  6.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  1. 16.  1.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.  8. 10.
  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8] -> size -> 30 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 3 8] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  1. 16.  1.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.  8. 10.
  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8] -> size -> 30 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3. 16.  1. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[184.8526 ]
 [168.58505]
 [168.58505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  1. 16.  1.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.  8. 10.
  3.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 3 8] -> size -> 6 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -4.571027755737305
desired expected reward: 173.68399047851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[149.39919]
 [156.50418]
 [155.0519 ]
 [139.9553 ]
 [152.71362]
 [164.14163]
 [157.6096 ]
 [162.25002]
 [148.92677]
 [156.2968 ]
 [156.77158]
 [169.7242 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  1. 16.  1.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.  8. 10.
  3.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 3 8] -> size -> 6 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -5.205135822296143
desired expected reward: 178.4008026123047



buy possibilites: [-1] 
expected returns: [[138.2963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  1. 16.  1.] 
cards in discard: [11.  3.  0.  0.  0.  0.  6. 11.  0.  3. 25.  0.  1.  3.  0.  0.  8. 10.
  3.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 3 8] -> size -> 6 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: -5.458291530609131
desired expected reward: 143.94085693359375






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 3 8] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0] -> size -> 31 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0] -> size -> 31 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0] -> size -> 31 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[170.14352]
 [165.249  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8] -> size -> 3 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -2.245342254638672
desired expected reward: 136.0509490966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[159.64682]
 [165.81958]
 [164.57257]
 [151.48611]
 [172.45395]
 [166.79097]
 [165.67084]
 [177.3485 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8] -> size -> 3 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -3.788733720779419
desired expected reward: 165.6436004638672



buy possibilites: [-1] 
expected returns: [[191.24388]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 11.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8] -> size -> 3 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 10.0
Learning step: -2.180553436279297
desired expected reward: 163.49024963378906






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 16.  0. 10.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 16.  0. 10.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 16.  0. 10.  3.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11. 16.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 10.] 
expected returns: [[116.58587 ]
 [109.952034]
 [ 97.76705 ]
 [101.641624]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0. 10.  3.] 
cards in discard: [10.  0.  0.  0.  6. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8] -> size -> 2 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -6.2190165519714355
desired expected reward: 185.02487182617188



action possibilites: [-1] 
expected returns: [[144.60536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  3.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8] -> size -> 2 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 47 

action type: gain_card_n - action 9
Learning step: 0.06488265842199326
desired expected reward: 110.83963775634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.41171]
 [121.47038]
 [148.80191]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  3.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8] -> size -> 2 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -2.2543084621429443
desired expected reward: 142.35105895996094



buy possibilites: [-1] 
expected returns: [[131.3854]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  3.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -273.0 

action type: buy - action 6.0
Learning step: -16.76734733581543
desired expected reward: 104.7030258178711






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 8] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6] -> size -> 34 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6] -> size -> 34 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6] -> size -> 34 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6] -> size -> 34 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[103.969795]
 [ 99.829445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 11.  0.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -3.5126373767852783
desired expected reward: 127.87277221679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 89.59203 ]
 [ 94.34221 ]
 [ 93.529945]
 [ 83.47226 ]
 [ 91.82145 ]
 [ 99.700294]
 [ 95.05559 ]
 [ 98.35252 ]
 [ 89.39342 ]
 [ 94.35127 ]
 [ 94.73378 ]
 [103.84919 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 11.  0.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.9689209461212158
desired expected reward: 97.70589447021484



buy possibilites: [-1] 
expected returns: [[102.23779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 11.  0.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 49 

action type: buy - action 29.0
Learning step: -0.018289947882294655
desired expected reward: 95.3545150756836






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16. 25.  0.  0.  0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29] -> size -> 35 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16. 25.  0.  0.  0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29] -> size -> 35 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[80.78516]
 [64.68552]
 [80.04273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 25.  0.  0.  0.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -2.5964391231536865
desired expected reward: 99.641357421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.109604]
 [66.496925]
 [65.45751 ]
 [51.677135]
 [73.68585 ]
 [67.42098 ]
 [66.52688 ]
 [79.24095 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 25.  0.  0.  0.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 22. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.51164710521698
desired expected reward: 76.86746978759766



buy possibilites: [-1] 
expected returns: [[72.779106]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 25.  0.  0.  0.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 30.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  2.  0.] 
sum of rewards: 29.0 

action type: buy - action 3.0
Learning step: -0.18534545600414276
desired expected reward: 65.27215576171875






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[117.59323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: 0.4068920314311981
desired expected reward: 73.18599700927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.03845 ]
 [105.049995]
 [ 92.018845]
 [106.978264]
 [117.98091 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -2.0621230602264404
desired expected reward: 115.5311050415039



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 0. 8. 6.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 0. 8. 6.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 0. 8. 6.] 
adversary cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [1. 1. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.075583]
 [12.345654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 8. 6.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.  0.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -4.142398357391357
desired expected reward: 113.83853149414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 7.1506233]
 [10.228254 ]
 [ 9.586265 ]
 [ 4.2682304]
 [ 3.0991957]
 [ 8.581846 ]
 [13.626142 ]
 [10.726956 ]
 [16.33343  ]
 [12.757245 ]
 [ 6.940319 ]
 [ 8.186948 ]
 [10.141507 ]
 [ 4.8261023]
 [10.338711 ]
 [16.27698  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 8. 6.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.  0.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 26. 30. 21. 30.  8.  6.  8.  6.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: 0.7455071806907654
desired expected reward: 18.821088790893555



buy possibilites: [-1] 
expected returns: [[4.4381313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 8. 6.] 
cards in discard: [10.  0.  0.  0.  6. 11. 10.  6. 11. 16.  0. 10.  3. 29.  1.  0.  3. 11.
  0.  3. 16. 25.  0.  0.  0.  0.  3.  3.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 21. 30.  8.  6.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  30.   0.   0.   0.   0.   0.   0.   0.  -2.   0.   0.
  4.5  0. ] 
sum of rewards: 30.5 

action type: buy - action 11.0
Learning step: 0.9435505270957947
desired expected reward: 14.569697380065918






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  6.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6. 25.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 21. 30.  8.  6.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6. 25.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11] -> size -> 37 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[153.55399]
 [153.2722 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  6.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: 4.596391677856445
desired expected reward: 9.034523010253906



action possibilites: [-1] 
expected returns: [[126.891235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 1. 1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  4] 
sum of rewards: 52 

action type: take_action - action 25.0
Learning step: -2.133639097213745
desired expected reward: 149.64019775390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[100.37761 ]
 [106.67414 ]
 [ 98.49549 ]
 [105.3049  ]
 [ 94.55927 ]
 [100.09312 ]
 [ 92.19034 ]
 [103.264786]
 [114.66857 ]
 [107.78797 ]
 [120.277245]
 [112.63299 ]
 [ 99.94596 ]
 [102.45374 ]
 [106.559135]
 [ 95.6878  ]
 [107.03506 ]
 [120.64614 ]]
Chosen buy action: 5.0 : ['Province' '5' '8']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 1. 1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 8 
card supply: [13. 26. 30. 21. 30.  8.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -1.5046745538711548
desired expected reward: 125.38655853271484



buy possibilites: [-1] 
expected returns: [[188.18604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 1. 1.] 
cards in discard: [5.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    9   90 1000    1   20    0    0    0    0   -3    0    0
  128    0] 
sum of rewards: 1240 

action type: buy - action 5.0
Learning step: 61.229530334472656
desired expected reward: 161.32266235351562






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6. 10. 11. 10.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6. 10. 11. 10.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
adversary victory points: 9
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16.  6. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 11. 10.] 
expected returns: [[152.95462]
 [137.82613]
 [140.90573]
 [147.62982]
 [140.90573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 10. 11. 10.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   1   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 105 

action type: buy - action -1
Learning step: -0.9486610293388367
desired expected reward: 187.2373809814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[134.03119]
 [126.98422]
 [151.69858]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6. 10. 11. 10.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   1   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0.9477493166923523
desired expected reward: 150.32095336914062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  3.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  3.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  3.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  3.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [ 0.  1.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[63.796787]
 [55.04867 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 16.  3.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: buy - action -1.0
Learning step: -1.4841644763946533
desired expected reward: 150.21441650390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[47.47306 ]
 [50.787956]
 [50.254868]
 [43.095634]
 [49.004257]
 [55.07785 ]
 [51.304173]
 [53.986465]
 [47.40531 ]
 [50.87018 ]
 [51.267857]
 [58.835728]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 16.  3.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 21. 30.  7.  5.  8.  5.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 2.8181326389312744
desired expected reward: 65.11691284179688



buy possibilites: [-1] 
expected returns: [[97.0619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 16.  3.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 21. 30.  7.  5.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5.   0.   9.  90.   0.   1.   0.   0.   0.   0.   0.  -4.   0.   0.
  4.5  0. ] 
sum of rewards: 95.5 

action type: buy - action 11.0
Learning step: 4.2049994468688965
desired expected reward: 59.282859802246094






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  7.  5.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11] -> size -> 39 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 26. 30. 21. 30.  7.  5.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11] -> size -> 39 
adversary victory points: 9
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[141.09491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  7.  5.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: buy - action -1
Learning step: 3.071540594100952
desired expected reward: 100.13343811035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[119.28598 ]
 [124.71493 ]
 [111.179146]
 [126.349785]
 [139.14394 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 26. 30. 21. 30.  7.  5.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0.563776433467865
desired expected reward: 141.65869140625



buy possibilites: [-1] 
expected returns: [[56.875248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 26. 30. 21. 30.  7.  4.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    8.   80.    0.    1.    0.    0.    0.    0.    0.   -5.
    0. -300.    0.    0.] 
sum of rewards: -221.0 

action type: buy - action 6.0
Learning step: -15.329263687133789
desired expected reward: 95.8498764038086






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  7.  4.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 11.  8.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6] -> size -> 40 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 26. 30. 21. 30.  7.  4.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 11.  8.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6] -> size -> 40 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 21. 30.  7.  4.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 11.  8.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6] -> size -> 40 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [ 6. 11.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[56.03185 ]
 [53.198532]
 [53.198532]
 [49.6756  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 11.  8.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  7.  4.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[-5  0  8 80  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: buy - action -1
Learning step: 2.5644431114196777
desired expected reward: 59.43968963623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.014423]
 [39.841755]
 [56.17426 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 11.  8.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 21. 30.  7.  4.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[-5  0  8 80  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action -1.0
Learning step: 2.502227783203125
desired expected reward: 58.53406524658203



buy possibilites: [-1] 
expected returns: [[39.530376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 11.  8.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    7.   70.    0.    1.    0.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -233.0 

action type: buy - action 6.0
Learning step: -12.752654075622559
desired expected reward: 27.089099884033203






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[47.962246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 73 

action type: buy - action -1
Learning step: 2.752631664276123
desired expected reward: 42.28300857543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[39.773113]
 [42.602177]
 [42.093933]
 [36.023754]
 [41.108982]
 [45.705082]
 [43.030968]
 [44.874043]
 [39.618465]
 [42.57873 ]
 [42.744812]
 [47.96223 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 73 

action type: take_action - action -1.0
Learning step: 2.232867956161499
desired expected reward: 50.19511413574219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 10. 29.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 10. 29.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 10. 29.] 
adversary cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[50.39669 ]
 [45.983616]
 [41.499474]
 [44.805164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10. 29.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 73 

action type: buy - action -1.0
Learning step: 2.303257703781128
desired expected reward: 50.2655029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.470882]
 [33.805813]
 [50.39669 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 10. 29.] 
cards in discard: [ 5. 25.  0.  6.  0.  1.  1.  1. 16.  6. 10. 11. 10. 11.  0.  1.  0. 16.
  3.  6.  0.  0.  3.  3.  3.  6.  6. 11.  0. 11.  8.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 73 

action type: take_action - action -1.0
Learning step: 2.092200994491577
desired expected reward: 52.488895416259766



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  6.  5.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  6.  5.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  6.  5.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 3.  3. 25.  6.  5.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[157.85068]
 [157.44325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  6.  5.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 73 

action type: buy - action -1.0
Learning step: 4.563966274261475
desired expected reward: 54.96065902709961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[139.18188]
 [132.2749 ]
 [156.2655 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  6.  5.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 73 

action type: take_action - action -1.0
Learning step: -0.7117996215820312
desired expected reward: 152.05978393554688



buy possibilites: [-1] 
expected returns: [[188.8136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  6.  5.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   7  70   0   1   0 -30   0   0   0  -7   0   0   0   0] 
sum of rewards: 36 

action type: buy - action 0.0
Learning step: -0.910788357257843
desired expected reward: 138.27110290527344






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11. 29.  1. 11.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0] -> size -> 42 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11. 29.  1. 11.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0] -> size -> 42 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11. 29.  1. 11.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0] -> size -> 42 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 1. 11. 29.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[119.88071]
 [115.77787]
 [114.33845]
 [115.77787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.  1. 11.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 73 

action type: buy - action -1
Learning step: -3.1290283203125
desired expected reward: 185.6845703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[109.04292 ]
 [114.29832 ]
 [113.416824]
 [102.1345  ]
 [111.512764]
 [120.27744 ]
 [115.06776 ]
 [118.73886 ]
 [108.84806 ]
 [114.30511 ]
 [114.728294]
 [124.84345 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 29.  1. 11.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 26. 30. 21. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 73 

action type: take_action - action -1.0
Learning step: 0.2663608491420746
desired expected reward: 120.30701446533203



buy possibilites: [-1] 
expected returns: [[131.12627]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 29.  1. 11.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 26. 30. 20. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[-5.  0.  8. 80.  0.  1.  0.  0.  0.  0.  0. -8.  0.  0.  2.  0.] 
sum of rewards: 78.0 

action type: buy - action 3.0
Learning step: 1.1795002222061157
desired expected reward: 114.5963134765625






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1. 16.  0.  6.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3] -> size -> 43 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 26. 30. 20. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1. 16.  0.  6.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3] -> size -> 43 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 0 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1. 16.  0.  6.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3] -> size -> 43 
adversary victory points: 8
player victory points: 1 





Player: 0 
cards in hand: [ 6.  1. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[56.476856]
 [48.328964]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 16.  0.  6.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6
  1  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  5.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 74 

action type: buy - action -1
Learning step: -1.6567577123641968
desired expected reward: 129.46951293945312



action possibilites: [-1] 
expected returns: [[125.487206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1 20  0  0  0  0 -8  0  0  4  0] 
sum of rewards: 90 

action type: gain_card_n - action 3
Learning step: 3.601827383041382
desired expected reward: 78.0345230102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[107.87254 ]
 [112.45519 ]
 [100.553925]
 [114.1927  ]
 [124.29867 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1
Learning step: 1.0053058862686157
desired expected reward: 126.49250793457031






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 0 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8] -> size -> 43 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 0 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8] -> size -> 43 
adversary victory points: 8
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8] -> size -> 43 
adversary victory points: 8
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[59.82131 ]
 [53.08644 ]
 [56.868587]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 74 

action type: buy - action -1.0
Learning step: -1.2253696918487549
desired expected reward: 123.07329559326172



action possibilites: [-1. 11.] 
expected returns: [[55.540703]
 [53.04615 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 95 

action type: take_action - action 10.0
Learning step: 3.3235538005828857
desired expected reward: 56.40998840332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.741714]
 [47.415062]
 [47.009804]
 [41.186714]
 [45.994713]
 [50.536938]
 [47.813316]
 [49.792347]
 [44.708828]
 [47.480145]
 [47.765625]
 [53.0348  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1.0
Learning step: 3.0158843994140625
desired expected reward: 58.55657958984375



buy possibilites: [-1] 
expected returns: [[36.891644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1 20  0  0  0  0 -9  0  0 32  0] 
sum of rewards: 117 

action type: buy - action 15.0
Learning step: 4.291781902313232
desired expected reward: 52.057395935058594






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15] -> size -> 44 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15] -> size -> 44 
adversary victory points: 8
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.555593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 74 

action type: buy - action -1
Learning step: 2.0479185581207275
desired expected reward: 38.9395637512207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[4.2212873]
 [5.329289 ]
 [5.098445 ]
 [2.918353 ]
 [6.8083105]
 [5.512419 ]
 [5.30673  ]
 [8.555593 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 26. 30. 19. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 74 

action type: take_action - action -1.0
Learning step: 3.4107937812805176
desired expected reward: 11.966386795043945



buy possibilites: [-1] 
expected returns: [[69.89676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 26. 30. 18. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5.   0.   9.  80.   0.   1.   0.   0.   0.   0.   0. -10.   0.   0.
   2.   0.] 
sum of rewards: 77.0 

action type: buy - action 3.0
Learning step: 5.167754650115967
desired expected reward: 10.266197204589844






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11. 11.  0. 10.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3] -> size -> 45 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 26. 30. 18. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11. 11.  0. 10.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3] -> size -> 45 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  0  3 29] -> size -> 7 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 26. 30. 18. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11. 11.  0. 10.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3] -> size -> 45 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  0  0  0  0  3 29  1] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 25. 30. 18. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11. 11.  0. 10.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3] -> size -> 45 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [ 8. 11. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 10.] 
expected returns: [[-1.9549036]
 [-2.0160954]
 [-1.8668364]
 [-1.8668364]
 [-2.371309 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  0. 10.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 18. 30.  7.  3.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29  1] -> size -> 8 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-5  0  9 80  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0.7105663418769836
desired expected reward: 70.6073226928711



action possibilites: [-1] 
expected returns: [[21.280151]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 10.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 18. 30.  7.  2.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29  1] -> size -> 8 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[  -5    0    8   70    0    1   20    0    0    0    0  -11    0 -300
    0    0] 
sum of rewards: -217 

action type: gain_card_n - action 3
Learning step: -10.690690994262695
desired expected reward: -4.300806999206543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.176404]
 [12.979068]
 [21.280155]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0. 10.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 25. 30. 18. 30.  7.  2.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29  1] -> size -> 8 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 70  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1
Learning step: 4.030910015106201
desired expected reward: 25.31106185913086






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  3 29  1] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 18. 30.  7.  2.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6] -> size -> 46 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  3 29  1] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 18. 30.  7.  2.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6] -> size -> 46 
adversary victory points: 8
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  8.] 
cards in discard: [3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  3 29  1  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6] -> size -> 46 
adversary victory points: 8
player victory points: 2 





Player: 0 
cards in hand: [ 6.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-2.1113286]
 [-2.955371 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 16.  0.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29  1  3] -> size -> 9 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: buy - action -1.0
Learning step: 2.0811145305633545
desired expected reward: 23.361265182495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-3.0678635]
 [-2.8782954]
 [-3.2868605]
 [-2.7358472]
 [-2.1113286]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 16.  0.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  4.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29  1  3] -> size -> 9 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: take_action - action -1.0
Learning step: 3.2457501888275146
desired expected reward: 1.1344187259674072



buy possibilites: [-1] 
expected returns: [[36.989536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 16.  0.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  3 29  1  3] -> size -> 9 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8  60   0   1   0   0   0   0   0 -12   0   0   8   0] 
sum of rewards: 60 

action type: buy - action 8.0
Learning step: 3.969057083129883
desired expected reward: 1.2332065105438232






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  3 29  1  3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1.  3.  3. 10.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.
  8.  6.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8] -> size -> 47 
adversary victory points: 8
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0  3 29  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1.  3.  3. 10.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.
  8.  6.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8] -> size -> 47 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0  3 29  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1.  3.  3. 10.] 
adversary cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.
  8.  6.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8] -> size -> 47 
adversary victory points: 8
player victory points: 2 





Player: 0 
cards in hand: [ 0.  1.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[13.490705]
 [10.817344]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3. 10.] 
cards in discard: [ 0.  3.  3. 25.  6.  5.  3.  1. 11. 29.  1. 11.  8. 16.  6.  1.  6. 15.
 10.  0.  0. 11.  0.  0.  3.  0.  0.  0.  3.  6.  6. 11.  8. 11.  0. 10.
  8.  6.  0.  3. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  3 29  3] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: buy - action -1
Learning step: 1.630711555480957
desired expected reward: 38.62024688720703



action possibilites: [-1.  8.] 
expected returns: [[128.51048 ]
 [118.858345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  3 29  3] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action 10.0
Learning step: 6.466304779052734
desired expected reward: 17.283649444580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[122.49413]
 [127.55572]
 [126.5933 ]
 [115.7321 ]
 [133.57167]
 [128.3959 ]
 [127.48266]
 [138.01166]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  4.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  3 29  3] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action -1.0
Learning step: 0.6957382559776306
desired expected reward: 129.20623779296875



buy possibilites: [-1] 
expected returns: [[132.771]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 8.] 
cards in discard: [11.] 
cards in deck: 41 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  3 29  3] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8  60   0   1  20   0   0   0   0 -13   0   0  18   0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0.7587646842002869
desired expected reward: 134.33041381835938






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  3 29  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 25.  3.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 48 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  3 29  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 25.  3.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 48 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  3 29  3  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 25.  3.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 48 
adversary victory points: 8
player victory points: 2 





Player: 0 
cards in hand: [ 0.  8.  6. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[57.439625]
 [49.065136]
 [56.801693]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 25.  3.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6 25  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  3 29  3  0] -> size -> 8 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: buy - action -1
Learning step: -2.1986420154571533
desired expected reward: 130.57235717773438



action possibilites: [-1] 
expected returns: [[133.04523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  3 29  3  0] -> size -> 8 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: trash_cards_n_from_hand - action 3
Learning step: 4.62705135345459
desired expected reward: 55.95637512207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[118.57032]
 [113.33393]
 [131.96765]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  3 29  3  0] -> size -> 8 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action -1
Learning step: 0.3304786682128906
desired expected reward: 133.37570190429688






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  3 29  3  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11. 29.  3.  8.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
adversary victory points: 8
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 29  3  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11. 29.  3.  8.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 29  3  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11. 29.  3.  8.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11. 29.  3.  8.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
adversary victory points: 8
player victory points: 2 





Player: 0 
cards in hand: [10. 11. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.  8.] 
expected returns: [[62.650715]
 [52.40808 ]
 [58.22434 ]
 [56.779804]
 [53.185005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.  3.  8.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: buy - action -1.0
Learning step: -2.093583822250366
desired expected reward: 129.8740692138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.108234]
 [39.09682 ]
 [60.524487]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 29.  3.  8.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: take_action - action -1.0
Learning step: 1.214705467224121
desired expected reward: 63.865421295166016



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  0. 15.  6.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  0. 15.  6.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
adversary victory points: 8
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  3.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[21.820103]
 [16.940155]
 [17.093407]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 15.  6.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1
  1  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: buy - action -1.0
Learning step: 0.6087839007377625
desired expected reward: 61.133270263671875



action possibilites: [-1] 
expected returns: [[31.376575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action 15.0
Learning step: 3.972191572189331
desired expected reward: 22.647823333740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.203596]
 [25.288338]
 [24.771212]
 [19.772139]
 [28.896002]
 [25.744587]
 [25.294376]
 [31.634071]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action -1
Learning step: 3.2349090576171875
desired expected reward: 34.61148452758789






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [1. 0. 6. 3. 6.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 46 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [1. 0. 6. 3. 6.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 46 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [1. 0. 6. 3. 6.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 46 
adversary victory points: 8
player victory points: 2 





Player: 0 
cards in hand: [1. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[59.475933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3. 6.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: buy - action -1.0
Learning step: 2.956505060195923
desired expected reward: 34.590572357177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.547646]
 [51.33111 ]
 [50.81687 ]
 [44.840717]
 [54.844208]
 [51.773235]
 [51.29145 ]
 [57.489513]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 6.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: take_action - action -1.0
Learning step: 1.4127520322799683
desired expected reward: 60.8886833190918



buy possibilites: [-1] 
expected returns: [[83.684845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 6.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   8.  60.   0.   1.   0. -30.   0.   0.   0. -12.   0.   0.
   0.   0.] 
sum of rewards: 22.0 

action type: buy - action 0.0
Learning step: 0.5555267333984375
desired expected reward: 49.103172302246094






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 16. 11. 11.  0.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0] -> size -> 47 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 16. 11. 11.  0.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0] -> size -> 47 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  8.] 
cards in discard: [10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0  0 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 16. 11. 11.  0.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0] -> size -> 47 
adversary victory points: 8
player victory points: 2 





Player: 0 
cards in hand: [ 0. 16. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
expected returns: [[35.695576]
 [30.559303]
 [34.20173 ]
 [34.20173 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11. 11.  0.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11 11  3  0  0  1  3 16  1 11  0 10  6  1  1
  0  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: buy - action -1
Learning step: -0.21657410264015198
desired expected reward: 83.46826934814453



action possibilites: [-1] 
expected returns: [[2.3818467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8  60   0   1  20   0   0   0   0 -12   0   0  25   0] 
sum of rewards: 97 

action type: gain_card_n - action 13
Learning step: 2.350407600402832
desired expected reward: 53.414085388183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-3.6929522]
 [-3.1803954]
 [-3.4658656]
 [-2.4700918]
 [ 2.3818386]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action -1
Learning step: 4.056453227996826
desired expected reward: 6.438300132751465






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0  0 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  1.  0.  6. 11.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22] -> size -> 47 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0  0 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 25. 30. 17. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  1.  0.  6. 11.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22] -> size -> 47 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0  0 10  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  1.  0.  6. 11.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22] -> size -> 47 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 6.  1.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[14.463985]
 [12.214981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0.  6. 11.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 10.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0 10  3] -> size -> 10 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 54 

action type: buy - action -1.0
Learning step: 2.886701822280884
desired expected reward: 5.268548488616943





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 6.363405 ]
 [ 9.165207 ]
 [ 8.622817 ]
 [ 2.7066877]
 [12.214981 ]
 [ 9.589786 ]
 [ 9.105006 ]
 [14.463985 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0.  6. 11.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 10.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0 10  3] -> size -> 10 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 54 

action type: take_action - action -1.0
Learning step: 2.2072885036468506
desired expected reward: 16.671274185180664



buy possibilites: [-1] 
expected returns: [[62.91602]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0.  6. 11.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 10.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 29  3  0  0  0 10  3] -> size -> 10 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   8.  50.   0.   1.   0. -30.   0.   0.   0. -13.   0.   0.
   0.   0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: 1.6474401950836182
desired expected reward: 8.010842323303223






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 29  3  0  0  0 10  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  0.  0. 16.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 29  3  0  0  0 10  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  0.  0. 16.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 29  3  0  0  0 10  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  0.  0. 16.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  0.  0. 16.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [11.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[27.477991]
 [25.154737]
 [21.30488 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 16.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8.  3. 10. 29.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0] -> size -> 10 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 54 

action type: buy - action -1
Learning step: 0.12297534942626953
desired expected reward: 63.03899383544922





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[22.19873 ]
 [17.397894]
 [22.769482]
 [27.477991]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0. 16.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8.  3. 10. 29.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0] -> size -> 10 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 54 

action type: take_action - action -1.0
Learning step: 1.856707215309143
desired expected reward: 29.334684371948242



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  8.  3. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 5. 0. 1. 3.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11. 11.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  8.  3. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 25. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 5. 0. 1. 3.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11. 11.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  8.  3. 10. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 5. 0. 1. 3.] 
adversary cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11. 11.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [0. 5. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[67.251915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 5. 0. 1. 3.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11. 11.  3.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1] -> size -> 11 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 54 

action type: buy - action -1.0
Learning step: 2.8392691612243652
desired expected reward: 30.31724739074707





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[59.834408]
 [59.475357]
 [54.32069 ]
 [58.380356]
 [63.09143 ]
 [60.224594]
 [62.289284]
 [57.097435]
 [59.940353]
 [60.248543]
 [66.164734]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 5. 0. 1. 3.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11. 11.  3.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1] -> size -> 11 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 54 

action type: take_action - action -1.0
Learning step: 0.7744640707969666
desired expected reward: 66.93920135498047



buy possibilites: [-1] 
expected returns: [[40.071594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 5. 0. 1. 3.] 
cards in discard: [11. 10.  0.  1.  3.  3.  8.  8.  0.  6.  3. 10. 11. 29.  3.  8. 15. 10.
  3.  6.  0.  1.  0.  6.  3.  6. 22. 16.  0. 11.  0.  0.  6.  1.  0.  6.
 11. 11.  3.  0.  0. 16. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0
 14] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1] -> size -> 11 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8  50   0   1   0   0   0   0   0 -14   0   0  32   0] 
sum of rewards: 72 

action type: buy - action 14.0
Learning step: 1.6467390060424805
desired expected reward: 58.744178771972656






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 15.  1.  5.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0
 14] -> size -> 49 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 15.  1.  5.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0
 14] -> size -> 49 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 15.  1.  5.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0
 14] -> size -> 49 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 29.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 15.  1.  5.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0
 14] -> size -> 49 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 3. 15.  1.  5.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[42.561977]
 [37.489285]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  5.  0.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0
  6  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0
 14] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  1. 29.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1] -> size -> 12 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 54 

action type: buy - action -1
Learning step: 1.6097538471221924
desired expected reward: 41.68134689331055



action possibilites: [-1] 
expected returns: [[95.14609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 5.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 23. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  1. 29.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1] -> size -> 12 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 74 

action type: take_action - action 15.0
Learning step: 3.966322422027588
desired expected reward: 41.45561218261719





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[76.4909  ]
 [74.986855]
 [65.357475]
 [63.087326]
 [73.39187 ]
 [82.02449 ]
 [77.41608 ]
 [86.5246  ]
 [80.564026]
 [70.06922 ]
 [72.08402 ]
 [75.973335]
 [66.066216]
 [76.12039 ]
 [85.489716]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 5.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 23. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  1. 29.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1] -> size -> 12 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  8 50  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 74 

action type: take_action - action -1
Learning step: 0.688912570476532
desired expected reward: 95.83499908447266



buy possibilites: [-1] 
expected returns: [[119.96803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 5.] 
cards in discard: [14.] 
cards in deck: 44 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14
 14] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  1. 29.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1] -> size -> 12 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   8.  50.   0.   1.  20.   0.   0.   0.   0. -14.   0.   0.
   8.   0.] 
sum of rewards: 68.0 

action type: buy - action 14.0
Learning step: 2.595820188522339
desired expected reward: 72.66502380371094






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 1. 10.  0.  3.  0.  1. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8. 14. 10. 10.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14
 14] -> size -> 49 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 1. 10.  0.  3.  0.  1. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 16. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8. 14. 10. 10.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14
 14] -> size -> 49 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 1. 10.  0.  3.  0.  1. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8. 14. 10. 10.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14
 14] -> size -> 49 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [ 8. 14. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10. 10.] 
expected returns: [[109.37829 ]
 [104.894005]
 [101.70302 ]
 [104.297066]
 [104.297066]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 10. 10.  0.] 
cards in discard: [14. 15.  3.  1.  5.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14
 14] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 44 

action type: buy - action -1
Learning step: -1.4153854846954346
desired expected reward: 118.55265045166016



action possibilites: [-1.  8. 14. 10.] 
expected returns: [[109.11588]
 [103.05992]
 [ 99.17967]
 [102.58714]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 10.  0.  6.] 
cards in discard: [14. 15.  3.  1.  5.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14
 14] -> size -> 49 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: take_action - action 10.0
Learning step: 0.34189414978027344
desired expected reward: 104.63890838623047



action possibilites: [-1.  8. 10.] 
expected returns: [[53.91214 ]
 [47.555332]
 [46.87944 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  6.] 
cards in discard: [14. 15.  3.  1.  5.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0 10  6  1  1  0  6
  8  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14
 14] -> size -> 49 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [1. 3. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action 14.0
Learning step: 0.37606698274612427
desired expected reward: 99.55572509765625



action possibilites: [-1] 
expected returns: [[121.65427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [14. 15.  3.  1.  5.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [1. 3. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 104 

action type: trash_cards_n_from_hand - action 2
Learning step: 5.70504903793335
desired expected reward: 50.34847640991211





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[111.76699 ]
 [110.841324]
 [103.659256]
 [116.273125]
 [112.42514 ]
 [111.56406 ]
 [119.39038 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [14. 15.  3.  1.  5.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [1. 3. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 104 

action type: take_action - action -1
Learning step: 1.67924964427948
desired expected reward: 123.3335189819336






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  3.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
adversary victory points: 8
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [3. 0. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  2.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [ 3. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[20.431536]
 [16.027866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  2.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  1.  0.] 
adversary cards in discard: [3. 0. 8. 1. 3. 3.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 44 

action type: buy - action -1.0
Learning step: -3.3482773303985596
desired expected reward: 116.04212188720703





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.272453]
 [18.938938]
 [16.696655]
 [20.610704]
 [19.510792]
 [19.182833]
 [21.446356]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  2.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  1.  0.] 
adversary cards in discard: [3. 0. 8. 1. 3. 3.] 
adversary owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 44 

action type: take_action - action -1.0
Learning step: 1.6248630285263062
desired expected reward: 22.056398391723633



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  1.  0.] 
cards in discard: [3. 0. 8. 1. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0  0  0 10  3  0  1  1  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  2.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 11.  6.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.] 
cards in discard: [3. 0. 8. 1. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  2.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 11.  6.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [3. 0. 8. 1. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  2.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 11.  6.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [ 1.  3.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[31.079123]
 [28.355358]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 11.  6.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  2.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 44 

action type: buy - action -1.0
Learning step: 1.8031692504882812
desired expected reward: 23.24953269958496



action possibilites: [-1] 
expected returns: [[34.128983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  1.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   8  40   0   1  20   0   0   0   0 -14   0   0   4   0] 
sum of rewards: 54 

action type: gain_card_n - action 5
Learning step: 2.273390769958496
desired expected reward: 26.163616180419922





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.751154]
 [19.142933]
 [12.705822]
 [23.676188]
 [20.239464]
 [19.696661]
 [26.881433]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  3.  1.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: take_action - action -1
Learning step: 1.9833869934082031
desired expected reward: 36.112369537353516



buy possibilites: [-1] 
expected returns: [[17.85028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  2.  1.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   8  40   0   1  20   0   0   0   0 -15   0   0  18   0] 
sum of rewards: 67 

action type: buy - action 11.0
Learning step: 2.567821502685547
desired expected reward: 26.2440128326416






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  2.  1.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  6. 16. 11. 11.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11] -> size -> 50 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  2.  1.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  6. 16. 11. 11.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11] -> size -> 50 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  2.  1.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  6. 16. 11. 11.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11] -> size -> 50 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6. 16. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
expected returns: [[12.774435]
 [ 7.200638]
 [10.662607]
 [10.662607]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16. 11. 11.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  2.  1.  9.  8.  8. 10.  4.  9.  9.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [ 1. 29.  3.  3.  3.  0.] 
adversary owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 44 

action type: buy - action -1
Learning step: 1.552119255065918
desired expected reward: 19.402400970458984



action possibilites: [-1] 
expected returns: [[15.969]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16. 11.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [ 1. 29.  3.  3.  3.  0.] 
adversary owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   8  40   0   1  20   0   0   0   0 -16   0   0  16   0] 
sum of rewards: 64 

action type: gain_card_n - action 6
Learning step: 3.3492608070373535
desired expected reward: 7.550096035003662





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[11.339289 ]
 [15.9690075]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16. 11.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 15. 30.  7.  2.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [ 1. 29.  3.  3.  3.  0.] 
adversary owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  8 40  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 64 

action type: take_action - action -1
Learning step: 2.7204110622406006
desired expected reward: 18.689411163330078



buy possibilites: [-1] 
expected returns: [[6.3779526]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16. 11.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [ 1. 29.  3.  3.  3.  0.] 
adversary owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    7.   30.    0.    1.   20.    0.    0.    0.    0.  -17.
    0. -300.    0.    0.] 
sum of rewards: -264.0 

action type: buy - action 6.0
Learning step: -13.62346076965332
desired expected reward: -2.2841758728027344






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  1.] 
cards in discard: [ 1. 29.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [22.  3.  3. 11.  3.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 8.] 
cards in discard: [ 1. 29.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 29  3  0 10  3  0  1  1  3  8] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [22.  3.  3. 11.  3.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8.] 
cards in discard: [ 1. 29.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 29  3 10  3  0  1  1  3  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [22.  3.  3. 11.  3.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [ 1. 29.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 29  3 10  3  0  1  1  3  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [22.  3.  3. 11.  3.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [22.  3.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
expected returns: [[9.495577]
 [4.004163]
 [8.522862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  3. 11.  3.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [1. 3. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  3 10  3  0  1  1  3  8] -> size -> 10 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 43 

action type: buy - action -1
Learning step: 2.0071091651916504
desired expected reward: 8.385061264038086





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[3.163331]
 [9.495577]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  3. 11.  3.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [1. 3. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  3 10  3  0  1  1  3  8] -> size -> 10 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 43 

action type: take_action - action -1.0
Learning step: 1.8335583209991455
desired expected reward: 11.329131126403809



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [1. 3. 8. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3 10  3  0  1  1  3  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3 10  3  0  1  1  3  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 3. 1.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3 10  3  0  1  1  3  8 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [0. 1. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[11.441961 ]
 [ 7.8819475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 3. 0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [14.  1.  3.  8.  3.  1.] 
adversary owned cards: [ 8 29  3 10  3  0  1  1  3  8 14] -> size -> 11 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 43 

action type: buy - action -1.0
Learning step: 1.901567816734314
desired expected reward: 11.397140502929688





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 7.548232 ]
 [ 7.104496 ]
 [ 2.7944193]
 [ 6.424038 ]
 [ 9.82523  ]
 [ 7.8819475]
 [ 9.249724 ]
 [ 5.3296776]
 [ 7.4774265]
 [ 7.621113 ]
 [11.441962 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  8.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [14.  1.  3.  8.  3.  1.] 
adversary owned cards: [ 8 29  3 10  3  0  1  1  3  8 14] -> size -> 11 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 43 

action type: take_action - action -1.0
Learning step: 1.7667934894561768
desired expected reward: 13.20875072479248



buy possibilites: [-1] 
expected returns: [[13.784113]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  7.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [14.  1.  3.  8.  3.  1.] 
adversary owned cards: [ 8 29  3 10  3  0  1  1  3  8 14] -> size -> 11 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7  40   0   1   0   0   0   0   0 -18   0   0  32   0] 
sum of rewards: 57 

action type: buy - action 16.0
Learning step: 2.8389413356781006
desired expected reward: 9.262969017028809






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [29.  3. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0.  8.] 
cards in discard: [14.  1.  3.  8.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3 10  3  0  1  1  3  8 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  7.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16] -> size -> 53 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [14.  1.  3.  8.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  3  0  1  1  3  8 14] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  7.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16] -> size -> 53 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [14.  1.  3.  8.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  3  0  1  1  3  8 14] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  7.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16] -> size -> 53 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[10.920671]
 [ 7.102602]
 [ 9.337976]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.  0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  7.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14] -> size -> 9 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 43 

action type: buy - action -1
Learning step: 1.675058364868164
desired expected reward: 15.459171295166016



action possibilites: [-1] 
expected returns: [[33.200226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  6.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14] -> size -> 9 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7  40   0   1  20   0   0   0   0 -19   0   0  16   0] 
sum of rewards: 60 

action type: gain_card_n - action 3
Learning step: 3.3261544704437256
desired expected reward: 10.126683235168457





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.80119 ]
 [26.531559]
 [20.966057]
 [30.274858]
 [27.183767]
 [27.000439]
 [33.200226]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  6.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14] -> size -> 9 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  1 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 63 

action type: take_action - action -1
Learning step: 2.1360557079315186
desired expected reward: 35.336280822753906






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [3. 3. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 3. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3  0  1  1  3  8 14] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  6.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [1. 6. 6. 8. 0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0. 16. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16] -> size -> 54 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 3. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3  0  1  1  3  8 14] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 15. 30.  7.  1.  6.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [1. 6. 6. 8. 0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0. 16. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16] -> size -> 54 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 3. 8.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 14. 30.  7.  1.  6.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [1. 6. 6. 8. 0.] 
adversary cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0. 16. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16] -> size -> 54 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [1. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.245303]
 [ 8.232733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 8. 0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0. 16. 11.  0. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 14. 30.  7.  1.  6.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 14.  8.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 33 

action type: buy - action -1.0
Learning step: 0.257986843585968
desired expected reward: 33.458213806152344





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 7.7818346]
 [ 7.2278852]
 [ 0.7824645]
 [11.420199 ]
 [ 8.232734 ]
 [ 7.7379866]
 [14.245303 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 8. 0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0. 16. 11.  0. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 14. 30.  7.  1.  6.  2.  1.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 14.  8.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 33 

action type: take_action - action -1.0
Learning step: 1.1527111530303955
desired expected reward: 15.398012161254883



buy possibilites: [-1] 
expected returns: [[24.943012]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 8. 0.] 
cards in discard: [14. 15.  3.  1.  5. 10. 14.  8.  0.  6.  3. 16.  0.  0.  0.  8. 11. 11.
  1.  3.  0.  6. 29.  6. 11.  0.  6. 16. 11. 22.  3.  3. 11.  3. 16.  0.
  1.  8.  3.  0. 16. 11.  0. 10.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16  8] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 14. 30.  7.  1.  6.  2.  0.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 14.  8.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  30.   0.   1.   0.   0.   0.   0.   0. -20.   0.   0.
   2.   0.] 
sum of rewards: 15.0 

action type: buy - action 8.0
Learning step: 0.8995813727378845
desired expected reward: 9.132307052612305






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  8.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.  1.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 14. 30.  7.  1.  6.  2.  0.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 22.  6. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16  8] -> size -> 55 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.  1.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 14. 30.  7.  1.  6.  2.  0.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 22.  6. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16  8] -> size -> 55 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 22.  6. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
expected returns: [[54.889507]
 [40.08614 ]
 [50.0788  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  6. 29.  3.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16  8] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 14. 30.  7.  1.  6.  2.  0.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 3. 1. 8.] 
adversary cards in discard: [ 3. 14.  8.  1.  0.] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 33 

action type: buy - action -1
Learning step: 1.5236412286758423
desired expected reward: 26.46665382385254





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[36.98297 ]
 [54.261852]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  6. 29.  3.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16  8] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 14. 30.  7.  1.  6.  2.  0.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 3. 1. 8.] 
adversary cards in discard: [ 3. 14.  8.  1.  0.] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  1  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 33 

action type: take_action - action -1.0
Learning step: -0.024518204852938652
desired expected reward: 54.864986419677734



Player 0 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 3 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 1 
Curse: 7 

Remodel: 2 
Workshop: 6 
Chapel: 4 
Witch: 1 
Poacher: 1 
Militia: 2 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 22.  6. 29.  3.] 
cards in discard: [6.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 16 11  3  0  0  1  3 16  1 11  0  6  1  1  0  6  8
  0 10 10  6 29  3 11  5 11  6  6  0  3  8 15  3  6  8 11  0 22  0 14 14
  8 11 29  6 16 16  8  6] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 14. 30.  7.  0.  6.  2.  0.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 3. 1. 8.] 
adversary cards in discard: [ 3. 14.  8.  1.  0.] 
adversary owned cards: [ 8  3  3  0  1  1  3  8 14  3] -> size -> 10 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[  -5  500    6   20    0    1    0    0    0    0    0  -21    0 -300
    0    0] 
sum of rewards: 201 

action type: buy - action 6.0
Learning step: 8.200851440429688
desired expected reward: 45.18382263183594



